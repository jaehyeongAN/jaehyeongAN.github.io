<!DOCTYPE html>
<html lang="en">

<head><meta name="generator" content="Hexo 3.9.0">

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>Keras functional api - Multi-input 모델 구축하기</title>
  
  <link rel="sitemap" href="https://jaehyeongan.github.iositemap.xml">
  
  <link rel="canonical" href="https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-모델-구축하기/">
  
  <meta name="description" content="Intro지난 한달간 회사 프로젝트를 위해 공부한 내용을 정리할 겸 오늘은 keras functional api(함수형 api)에 대한 소개와 이것을 어떻게 적용하는지를 LSTM모델과 embedding모델을 통해 간단히 소개하려고 한다.  그동안 keras를 통해 딥러">
  
  
  <meta name="author" content>
  
  <meta property="og:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta property="og:site_name" content="jaehyeong&#39;s ds">
  <meta property="og:type" content="article">
  <meta property="og:title" content="Keras functional api - Multi-input 모델 구축하기">
  
  <meta property="og:description" content="Intro지난 한달간 회사 프로젝트를 위해 공부한 내용을 정리할 겸 오늘은 keras functional api(함수형 api)에 대한 소개와 이것을 어떻게 적용하는지를 LSTM모델과 embedding모델을 통해 간단히 소개하려고 한다.  그동안 keras를 통해 딥러">
  
  <meta property="og:url" content="https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-모델-구축하기/">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Keras functional api - Multi-input 모델 구축하기">
  
  <meta name="twitter:description" content="Intro지난 한달간 회사 프로젝트를 위해 공부한 내용을 정리할 겸 오늘은 keras functional api(함수형 api)에 대한 소개와 이것을 어떻게 적용하는지를 LSTM모델과 embedding모델을 통해 간단히 소개하려고 한다.  그동안 keras를 통해 딥러">
  
  
  <meta name="twitter:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta name="twitter:url" content="https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-모델-구축하기/">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="/css/normalize.css">
  <link rel="stylesheet" href="/css/skeleton.css">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/prism-dark.css">
  <link rel="stylesheet" href="/css/prism-line-numbers.css">
  <!-- User css -->
  
  <link rel="stylesheet" href="/css/user.css">
  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/astronaut.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick="setDarkMode(true)" id="darkBtn">🌑</div>
      <div onclick="setDarkMode(false)" id="lightBtn" class="hidden">☀️</div>
      <script>
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      ⬅ Click this.
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/about" class="ml">About</a>
          
        
        
          
            <a href="mailto:nonamed000000@gmail.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>Keras functional api - Multi-input 모델 구축하기</h2>

  <h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>지난 한달간 회사 프로젝트를 위해 공부한 내용을 정리할 겸 오늘은 keras functional api(함수형 api)에 대한 소개와 이것을 어떻게 적용하는지를 LSTM모델과 embedding모델을 통해 간단히 소개하려고 한다.</p>
<hr>
<p>그동안 keras를 통해 딥러닝 모델을 구축하기 위해서는 Sequential 모델을 이용하였을 것이다.<br>Sequential 모델은 네트워크의 입력과 출력이 하나라고 가정하고 층을 차레대로 쌓아 구성한다. </p>
<p><img src="/image/sequential.PNG" width="300" height="300"></p>
<p>따라서 위와 같은 Sequential 모델에 데이터를 학습하기 위해서는 모든 데이터를 같은 방식으로 전처리하여 모델에 맞게 shape을 구성해주어야 한다.<br>하지만, 위와 같은 구성이 맞지 않는 경우도 존재한다. 예를 들어, 중고 의류 시장 가격을 예측하는 딥러닝 모델을 만든다고 가정해보겠다.</p>
<p>이 모델은 시장 가격 예측을 위해 의류 브랜드, 제작 연도와 같은 정보(메타 데이터), 사용자가 제공한 제품 리뷰(텍스트 데이터), 해당 의류 사진(이미지 데이터)과 같은 데이터를 받는다.<br><img src="/image/cloth_example.PNG" width="400" height="400"></p>
<p>모델은 데이터의 특성에 맞게 적절히 사용되어야 하는데, 해당 데이터가 text인지, image인지, time-series인지에 따라 학습하는 모델도 달라진다.<br>위와 같은 경우,<br><img src="/image/cloth_model.PNG" width="400" height="400"><br>메타 데이터만 있다면 이를 one-hot encoding하여 단순한 DenseNet모델을 구현할 수 있을 것이고,<br>텍스트 데이터의 경우 이를 word2vec 같은 기법을 통해 벡터로 변환하여 Embedding 모델이나 혹은 RNN모델을 구현할 수 있을 것이고,<br>이미지 데이터의 경우 CNN과 같은 ConveNet 모듈을 이용하여 데이터를 학습할 수 있을 것이다.</p>
<h2 id="keras-functional-api"><a href="#keras-functional-api" class="headerlink" title="keras functional api"></a>keras functional api</h2><p>하지만 방금 살펴본 것과 같이 예측에 사용되는 데이터가 여러 형태로 존재한다면 어떤 모델을 사용해야 할까?<br>단순히 텍스트와 이미지를 vectorize하여 예측 변수로 추가하여 사용해야 할까?<br>데이터 특성에 따라 각각 모델을 학습시킬 순 없을까?</p>
<p>이러한 의문을 해결해줄 것이 바로 오늘 살펴볼 <strong>Keras Functional API</strong>이다<br>함수형 api라고 불리며, 말 그대로 모델을 함수처럼 필요할 때 호출하여 사용할 수 있도록 한다. 즉, 모델을 함수로 구현하여 모듈식으로 이용한다는 말이다.</p>
<p>다시 위의 예로 돌아가 함수형 API를 활용하면 아래 그림과 같이 모델별 학습 및 예측이 가능해진다.<br><img src="/image/cloth_model_concat.PNG" width="500" height="500"></p>
<p>위 그림과 같은 모델을 다중입력모델(multi-input model)이라고 하며 이 외에도 다중출력모델(multi-output model)이 존재합니다. </p>
<ul>
<li>다중입력모델: 데이터 특성에 따른 서로 다른 여러개의 모델이 input으로 사용되어 하나의 output을 내는 네트워크<br><img src="/image/multi_input.PNG" width="400" height="400"></li>
<li>다중출력모델: 하나의 output이 아닌 데이터에 있는 여러 속성을 동시에 예측하는 네트워크<br><img src="/image/multi_output.PNG" width="400" height="400"></li>
</ul>
<hr>
<p>함수형 API는 기존 구현방법과 구조적으로 차이가 있다.<br>보통 모델을 구현할 때 Sequential()객체를 생성 후 시퀀스 형태로 순차적으로 layer를 쌓아가지만 함수형 api는 Model()객체를 통해 모델을 구현한다. </p>
<ul>
<li><p>기존 Sequential() 사용 시 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.fit(data, labels)  <span class="comment"># starts training</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>funciontal api() 사용 시</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="comment"># This returns a tensor</span></span><br><span class="line">inputs = Input(shape=(<span class="number">784</span>,))</span><br><span class="line"></span><br><span class="line"><span class="comment"># a layer instance is callable on a tensor, and returns a tensor</span></span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(inputs)</span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">outputs = Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This creates a model that includes</span></span><br><span class="line"><span class="comment"># the Input layer and three Dense layers</span></span><br><span class="line">model = Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>위와 같이 Sequential()객체는 input부터 output까지 순차적으로 이루어지지만, 함수형 api는 각각의 변수에 layer를 받아 모듈별로 구성할 수 있으며, 마지막에는 Model()객체에 input과 output텐서를 지정하여 모델을 생성한다.</p>
<h2 id="적용"><a href="#적용" class="headerlink" title="적용"></a>적용</h2><p>그렇다면 직접 keras를 이용하여 적용하는 과정을 소개하려고 한다.<br>데이터 셋과 전처리 과정은 공개할 순 없으나 해당 데이터는 일반 Sequence 데이터 및 Text 데이터로 이루어져 있고, 고장발생에 대한 여부를 예측하는 문제이다. </p>
<p>functional api를 적용하기 위하여 두개의 모델을 구축하였다.</p>
<ul>
<li>Sequence 데이터를 위해서는 시간 및 순서가 있는 데이터에 효율적인 LSTM(Long Short Term Memory Network)를 이용하였고, </li>
<li>text 데이터는 vectorize 후 Embedding 모델을 이용하였다.</li>
</ul>
<p>개략적인 모델 구성도는 대략 아래 그림과 같다.<br><img src="/image/model_structure_0.PNG" width="400" height="400"></p>
<p></p><p></p><br><strong>1. LSTM 모델 적용을 위한 Sequence 데이터 처리</strong><br>우선 LSTM과 같은 Recurrent 모델은 크기가 (timesteps, input_features)인 2D 텐서로 인코딩된 벡터의 시퀀스를 입력받기 때문에 shape을 맞추어 준다.<br>shape을 맞춰주기 전에 우선 text변수와 target 값을 제외해준 후, 데이터를 normalize해주었다.<p></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## preprocessing for lstm </span></span><br><span class="line">sequence_train = df[:train_size].drop([<span class="string">'text_data'</span>,<span class="string">'target'</span>], axis=<span class="number">1</span>)</span><br><span class="line">sequence_test = df[train_size:].drop([<span class="string">'text_data'</span>,<span class="string">'target'</span>], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalize</span></span><br><span class="line">scaler = StandardScaler().fit(sequence_train)</span><br><span class="line">sequence_train_scale = scaler.transform(sequence_train)</span><br><span class="line">sequence_test_scale = scaler.transform(sequence_test)</span><br><span class="line"></span><br><span class="line">timesteps = <span class="number">1</span></span><br><span class="line">columns_size = len(sequence_train.columns)</span><br><span class="line">sequence_train = sequence_train_scale.reshape((sequence_train_scale.shape[<span class="number">0</span>], timesteps, columns_size))</span><br><span class="line">sequence_test = sequence_test_scale.reshape((sequence_test_scale.shape[<span class="number">0</span>], timesteps, columns_size))</span><br></pre></td></tr></table></figure>
<p></p><p></p><br><strong>2. Embedding 모델 적용을 위한 text 데이터 처리</strong><br>Embedding 모델을 구현하기 위하여 먼저 데이터를 3D 텐서로 변환시켜주어야 한다. 이를 위해 keras의 Tokenizer()객체를 이용하였다. 과정은 아래와 같다.<p></p>
<ul>
<li>fit_on_texts(): 텍스트 데이터를 통해 word index를 구축</li>
<li>texts_to_sequences(): word index를 통해 해당 텍스트를 시퀀스 형태로 변환</li>
<li>pad_sequences(): 3D 텐서로 변환하기 위해 padding을 추가</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## preprocessing for embedding</span></span><br><span class="line">text_embed = df.loc[:, [<span class="string">'text_data'</span>]]</span><br><span class="line">text_embed_train = text_embed[:train_size]</span><br><span class="line">text_embed_test = text_embed[train_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenize</span></span><br><span class="line">max_words = <span class="number">1000</span>	<span class="comment"># 사용할 최대 단어 수 </span></span><br><span class="line">max_len = <span class="number">50</span>		<span class="comment"># 단어의 길이</span></span><br><span class="line">tokenizer = text.Tokenizer(num_words=max_words) 	<span class="comment"># top 1,000 words</span></span><br><span class="line">tokenizer.fit_on_texts(text_embed_train)			<span class="comment"># word_index 구축</span></span><br><span class="line">sequences_text_train = tokenizer.texts_to_sequences(text_embed_train)	<span class="comment"># return sequence</span></span><br><span class="line">sequences_text_test = tokenizer.texts_to_sequences(text_embed_test)		</span><br><span class="line"><span class="comment"># add padding </span></span><br><span class="line">pad_train = sequence.pad_sequences(sequences_text_train, maxlen=max_len)<span class="comment"># return 3D tensor</span></span><br><span class="line">pad_test = sequence.pad_sequences(sequences_text_test, maxlen=max_len)	<span class="comment"># return 3D tensor</span></span><br></pre></td></tr></table></figure>
<p></p><p></p><br><strong>3. multi-input model 구축</strong><br>우선 LSTM모델과 Embedding모델을 만든 후 concatenate(model1, model2)함수를 이용하여 서로 다른 두 개의 모델의 output을 하나의 모델로 통합할 수 있다. <p></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_input_lstm_embedding_model</span><span class="params">(timesteps, columns_size, max_words, max_len)</span>:</span></span><br><span class="line">	<span class="comment"># lstm model</span></span><br><span class="line">	lstm_input = layers.Input(shape=(timesteps, columns_size))</span><br><span class="line">	lstm_out = layers.LSTM(<span class="number">64</span>, dropout=<span class="number">0.3</span>, recurrent_dropout=<span class="number">0.3</span>)(lstm_input)</span><br><span class="line"></span><br><span class="line">	lstm_model = Model(inputs=lstm_input, outputs=lstm_out)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># embedding model </span></span><br><span class="line">	embed_input = layers.Input(shape=(<span class="keyword">None</span>,))</span><br><span class="line">	embed_out = layers.Embedding(max_words, <span class="number">8</span>, input_length=max_len)(embed_input)</span><br><span class="line">	embed_out = layers.Bidirectional(layers.LSTM(<span class="number">64</span>, dropout=<span class="number">0.3</span>, recurrent_dropout=<span class="number">0.3</span>))(embed_out)</span><br><span class="line"></span><br><span class="line">	embed_model = Model(inputs=embed_input, outputs=embed_out)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># concatenate</span></span><br><span class="line">	concatenated = layers.concatenate([lstm_model.output, embed_model.output])</span><br><span class="line">	concatenated = layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>)(concatenated)</span><br><span class="line">	concatenated = layers.BatchNormalization()(concatenated)</span><br><span class="line">	concat_out = layers.Dense(<span class="number">2</span>, activation=<span class="string">'sigmoid'</span>)(concatenated)</span><br><span class="line"></span><br><span class="line">	concat_model = models.Model([lstm_input, embed_input], concat_out)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> concat_model</span><br><span class="line"></span><br><span class="line"><span class="comment">## model define</span></span><br><span class="line">concat_model = multi_input_lstm_embedding_model(timesteps, columns_size, max_words, max_len)</span><br><span class="line">concat_model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># model fit</span></span><br><span class="line">concat_model.fit([df_label_train, pad_train], target_train</span><br><span class="line">				epochs=<span class="number">7</span>, batch_size=<span class="number">32</span>,</span><br><span class="line">				callbacks=callbacks_list,</span><br><span class="line">				validation_data=([sequence_test, pad_test], target_test),</span><br><span class="line">				shuffle=<span class="keyword">False</span>)	<span class="comment"># because of time-series</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>keras functional api를 이용한다면 좀 더 데이터 특성에 유연하게 모델을 학습시킬 수 있다는 것이 큰 장점인 것 같다. </p>

  <p><a class="classtest-link" href="/tags/deeplearning/">deeplearning</a>, <a class="classtest-link" href="/tags/embedding/">embedding</a>, <a class="classtest-link" href="/tags/functionalapi/">functionalapi</a>, <a class="classtest-link" href="/tags/keras/">keras</a>, <a class="classtest-link" href="/tags/lstm/">lstm</a>, <a class="classtest-link" href="/tags/machinelearning/">machinelearning</a>, <a class="classtest-link" href="/tags/rnn/">rnn</a>, <a class="classtest-link" href="/tags/tensorflow/">tensorflow</a> — Mar 26, 2019</p>
  
  <hr>
<section id="comments" class="mt-2 mb-3">

  <div id="disqus_thread">
    <a href="#" class="button button-primary" onclick="loadDisqus();return false;">View / Make Comments</a>
  </div>

  <script>
    var disqus_config = function() {
      this.page.url = 'https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-모델-구축하기/index.html';
      this.page.identifier = '2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-모델-구축하기/index.html';
      this.page.title = 'Keras functional api - Multi-input 모델 구축하기';
    };

    var is_disqus_loaded = false;

    function loadDisqus() {
      if (!is_disqus_loaded) {
        is_disqus_loaded = true;

        var d = document,
          s = d.createElement('script');
        s.src = 'https://jaehyeongan.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      }
    }

  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi">
      
      <a class="ml-0 footer-link icon" href="https://github.com/jaehyeongAN" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://www.linkedin.com/in/jaehyeong-an-005603160/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="LinkedIn">
        <svg class="linkedin svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
      

      

      
      <a class="ml-0 footer-link icon" href="https://www.instagram.com/an_jh.ds/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Instagram">
        <svg class="instagram svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z"/></svg>
      </a>
      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
