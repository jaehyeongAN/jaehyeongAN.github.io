<!DOCTYPE html>
<html lang="en">

<head><meta name="generator" content="Hexo 3.9.0">

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>합성곱 신경망(ConvNet, Convolutional Neural Network)</title>
  
  <link rel="sitemap" href="https://jaehyeongan.github.iositemap.xml">
  
  <link rel="canonical" href="https://jaehyeongan.github.io/2019/09/23/basic-convnet/">
  
  <meta name="description" content="Intro 현재 ConvNet 기반의 모델은 단순 이미지 인식을 넘어 Object Detection, Semantic Segmentation 까지 딥러닝 알고리즘 중 가장 활발히 연구되고 성과를 내고 있는 분야이다. 우선 각 분야별 적용되고 있는 주요 모델을 간단히 살">
  
  
  <meta name="author" content>
  
  <meta property="og:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta property="og:site_name" content="jaehyeong&#39;s ds">
  <meta property="og:type" content="article">
  <meta property="og:title" content="합성곱 신경망(ConvNet, Convolutional Neural Network)">
  
  <meta property="og:description" content="Intro 현재 ConvNet 기반의 모델은 단순 이미지 인식을 넘어 Object Detection, Semantic Segmentation 까지 딥러닝 알고리즘 중 가장 활발히 연구되고 성과를 내고 있는 분야이다. 우선 각 분야별 적용되고 있는 주요 모델을 간단히 살">
  
  <meta property="og:url" content="https://jaehyeongan.github.io/2019/09/23/basic-convnet/">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="합성곱 신경망(ConvNet, Convolutional Neural Network)">
  
  <meta name="twitter:description" content="Intro 현재 ConvNet 기반의 모델은 단순 이미지 인식을 넘어 Object Detection, Semantic Segmentation 까지 딥러닝 알고리즘 중 가장 활발히 연구되고 성과를 내고 있는 분야이다. 우선 각 분야별 적용되고 있는 주요 모델을 간단히 살">
  
  
  <meta name="twitter:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta name="twitter:url" content="https://jaehyeongan.github.io/2019/09/23/basic-convnet/">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="/css/normalize.css">
  <link rel="stylesheet" href="/css/skeleton.css">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/prism-dark.css">
  <link rel="stylesheet" href="/css/prism-line-numbers.css">
  <!-- User css -->
  
  <link rel="stylesheet" href="/css/user.css">
  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/astronaut.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick="setDarkMode(true)" id="darkBtn">🌑</div>
      <div onclick="setDarkMode(false)" id="lightBtn" class="hidden">☀️</div>
      <script>
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      ⬅ Click this.
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/about" class="ml">About</a>
          
        
        
          
            <a href="mailto:nonamed000000@gmail.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>합성곱 신경망(ConvNet, Convolutional Neural Network)</h2>

  <h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro "></a>Intro </h2><p>현재 ConvNet 기반의 모델은 단순 이미지 인식을 넘어 Object Detection, Semantic Segmentation 까지 딥러닝 알고리즘 중 가장 활발히 연구되고 성과를 내고 있는 분야이다. 우선 각 분야별 적용되고 있는 주요 모델을 간단히 살펴보면 아래와 같다.</p>
<blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>Classification</th>
<th>Image Detection</th>
<th>Semantic Segentation</th>
</tr>
</thead>
<tbody>
<tr>
<td>VGG Net</td>
<td>RCNN</td>
<td>FCN</td>
</tr>
<tr>
<td>GoogLeNet</td>
<td>Fast RCNN</td>
<td>DeepLab</td>
</tr>
<tr>
<td>ResNet</td>
<td>Faster RCNN</td>
<td>U-Net</td>
</tr>
<tr>
<td>MobileNet</td>
<td>YOLO</td>
<td>ReSeg</td>
</tr>
<tr>
<td>ShuffleNet</td>
<td>SDD</td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p>이 글에서는 위의 훌륭한 모델들이 가장 기본으로 하는 ConvNet의 구조 및 학습 방법에 대해 간단히 알려보려고 한다.</p>
<hr>
<h2 id="합성곱-신경망-Convolutional-Neural-Network-ConvNet"><a href="#합성곱-신경망-Convolutional-Neural-Network-ConvNet" class="headerlink" title="합성곱 신경망(Convolutional Neural Network, ConvNet)"></a>합성곱 신경망(Convolutional Neural Network, ConvNet)</h2><p>합성곱 신경망은 합성곱 연산을 사용하는 신경망 중 하나로서, 주로 음성 인식이나 시각적 이미지를 분석하는데 사용된다. 합성곱 신경망이 일반 신경망과 다른 점은 일반적인 신경망들이 이미지 데이터를 원본 그대로 1차원 신경망인 Fully-Connected layer(FC layer 혹은 Dense layer)에 입력되어 전체 특성을 학습하고 처리하는 데 반해, <strong>합성곱 신경망은 FC layer를 거치기 전에 Convolution 및 Poolling과 같은 데이터의 주요 특징 벡터를 추출하는 과정을 거친 후 FC layer로 입력되게 된다.</strong><br>그렇기 때문에 대부분의 이미지 인식 분야는 딥러닝 기반의 합성곱 신경망이 주를 이루고 있다.<br><br></p>
<h2 id="ConvNet의-구조"><a href="#ConvNet의-구조" class="headerlink" title="ConvNet의 구조"></a>ConvNet의 구조</h2><p><img src="/image/convnet.jpg" width="700"></p>
<p>합성곱 신경망은 기본적으로 위와 같은 구조로 이루어져 있다. 위 ConvNet을 크게 3덩어리로 짤라서 보면 아래와 같다.</p>
<blockquote>
<p><strong><em>1. Input layer</em></strong><br><strong><em>2. Convolutional layer ~ Max pooling layer</em></strong><br><strong><em>3. Fully-connected layer ~ Output layers로</em></strong></p>
</blockquote>
<p>위 구조를 간단히 설명하면 위에서도 말했듯이 ConvNet은 단순 FC Layer로만 구성되어 있지 않다. Convolutional Layer와 Pooling Layer라는 과정을 거치게 되는데 이는 Input Image의 주요 특징 벡터를 추출하는 과정이라고 할 수 있다. 그 후 이렇게 추출된 주요 특징 벡터들은 그제야 FC Layer를 거치며 1차원 벡터로 변환되고 마지막 Output layer에서 활성화 함수인 Softmax함수를 통해 각 해당 클래스의 확률로 출력되게 된다. 아래에서 각 과정을 좀 더 상세히 살펴보겠다.<br><br></p>
<h3 id="1-Input-Layer"><a href="#1-Input-Layer" class="headerlink" title="1. Input Layer"></a>1. Input Layer</h3><p>Input Layer는 입력된 이미지 데이터가 최초로 거치게 되는 Layer이다. 모두가 알고 있듯이 이미지는 단순 1차원의 데이터가 아니다. 이미지는 기본적으로 <strong><em>(높이, 넓이, 채널)</em></strong>의 크기를 갖는 3차원의 크기를 가지며, 여기서 채널(channels)의 경우 Gray Scale(1)이냐 RGB(3)이냐 에 따라 크기가 달라지게 된다. (채널의 컬러 공간은 Gray, RGB, HSV, CMYK 등 다양하다)<br><img src="/image/cnn_img_shape.png" width="550"></p>
<p>위와 같은 형태는 높이 4, 넓이 4, 채널 RGB를 갖고 있으므로 위 이미지의 shape은 (4, 4, 3)으로 표현할 수 있으며, </p>
<p><img src="/image/mnist_shape.png" width="150"><br>이미지 인식의 교과서라 할 수 있는 위 MNIST 손글씨 데이터 셋의 경우 높이 28, 넓이 28, 채널 Gray를 가지고 있으므로 (28, 28, 1)의 shape을 가졌다고 말할 수 있다. 또한 다른 말로 특성 맵(Feature Map)이라고도 한다.<br><br></p>
<h3 id="2-Convolutional-Layer"><a href="#2-Convolutional-Layer" class="headerlink" title="2. Convolutional Layer"></a>2. Convolutional Layer</h3><p>Convolutional Layer와 FC Layer의 경우 근본적은 차이가 존재하는데, Dense 층의 경우 특성 공간에 있는 전역 패턴(입력된 이미지의 모든 픽셀에 걸친 패턴)을 학습하는 반면 합성곱 층의 경우 지역 패턴을 학습하게 된다.</p>
<h4 id="2-1-kernel"><a href="#2-1-kernel" class="headerlink" title="2.1 kernel"></a>2.1 kernel</h4><p>Convolutional Layer에서는 Input Image의 크기인 특성 맵(Feature Map)을 입력으로 받게 되는데 지역 패턴 학습을 위하여 이러한 특성 맵에  <strong>커널(kernel) 혹은 필터(Filter)</strong>라 불리는 정사각 행렬을 적용하며 합성곱 연산을 수행하게 된다.<br>커널의 경우 3 x 3, 5 x 5크기로 적용되는 것이 일반적이며 <strong>스트라이드(Stride)</strong>라고 불리는 지정된 간격에 따라 순차적으로 이동하게 된다.<br><img src="/image/cnn_kernel.gif" width="500"></p>
<p>위 그림의 경우 Image의 크기는 (5, 5, 1)의 크기를 가지고 있으며, 현재 3 x 3크기의 kernel이 1 Stride의 간격으로 이동하며 합성곱 연산을 수행하는 것을 보여준다. 만약 커널이 2개의 크기만큼 이동하고 있다면 2 Stride 간격으로 이동한다고 할 수 있다. </p>
<p>이렇게 커널은 스트라이드 간격만큼 순회하며 모든 채널의 합성곱의 합을 새로운 특성 맵으로 만들게 되며, 결국 위 그림의 경우 커널과 스트라이드의 상호작용으로 인해 원본 (5, 5, 1) 크기의 Feature Map아 (3, 3, 1)크기의 Feature Map의 크기로 줄어들게 되었다.</p>
<blockquote>
<p><strong><em>커널과 스트라이드의 경우 크기가 클 수 록 좀더 빨리 이미지를 처리할 수 있지만, 넓은 특성을 큰 보폭으로 이동하는 만큼 주요 특성을 놓칠 수 있다는 단점이 존재한다.</em></strong></p>
</blockquote>
<p><br></p>
<h4 id="2-2-Padding"><a href="#2-2-Padding" class="headerlink" title="2.2 Padding"></a>2.2 Padding</h4><p>합성곱 연산을 수행할 경우 단점이 존재하는데, 바로 위에서 살펴보았듯이 kernel과 stride의 작용으로 인해 원본 크기가 줄어든다는 것이다. 따라서 이렇게 Feature Map의 크기가 작아지는 것을 방지하기 위해서 Padding이란 기법을 이용하게 되는데, 쉽게 말해 단순히 원본 이미지에 0이라는 padding값을 채워 넣어 이미지를 확장한 후 합성곱 연산을 적용하는 것을 말한다. </p>
<p><img src="/image/cnn_padding.gif" width="400"></p>
<p>위 그림을 보면 위에서 살펴본 바와 같이 똑같은 (5, 5, 1)크기의 이미지 데이터가 놓여있다. 다른 점은 사방으로 빈 공간(0)이 1칸씩 더 채워져 있다는 것인데 이것이 바로 padding이다. 이후 위와 똑같은 3 x 3 크기의 커널을 적용하게 되는데 출력되는 feature map의 크기는 (3, 3, 1)이 아닌 원본 이미지와 똑같은 (5, 5, 1)크기의 feature map이다. </p>
<p>이렇듯, <strong>원본 이미지의 크기를 줄이지 않으면서 합성곱 연산을 수행가능하게 해주는 것이 바로 padding의 역할</strong>이라고 할 수 있다.<br><br></p>
<h4 id="2-3-ReLU-Activation-Function"><a href="#2-3-ReLU-Activation-Function" class="headerlink" title="2.3 ReLU Activation Function"></a>2.3 ReLU Activation Function</h4><p>합성곱 연산을 거친 Feature Map은 활성화 함수를 거치게 되는데, 많은 활성화 함수 중 가장 널리 사용되고 있는 것은 ReLU 함수 이다.</p>
<p><img src="/image/cnn_sigmoid_relu.png" width="500"></p>
<p>일반적으로 Sigmoid 함수의 경우 값을 0 ~ 1사이로 정규화시키는데 레이어가 깊어질 수 록 0.xxx의 값이 계속 미분되게 되면 값이 점차 0으로 수렴하게 되어 결국 weight값이 희미해지는 gradient vanishing문제가 발생하게 된다.<br>하지만 ReLU의 경우 0미만의 값은 0으로 출력하고 0이상의 값은 그대로 출력하기 때문에 이러한 문제에 덜 민감하고 그렇기 때문에 깊은 레이어에서도 효율적인 역전파(Back Propagation)가 가능하다. </p>
<p>이러한 이유로 합성곱 연산을 통해 출력된 feature map의 경우 일반적으로 ReLU 활성화 함수를 거치게 되며, ReLU 함수가 양의 값만을 활성화하며 특징을 좀 더 두드러지게 표현해주게 된다.<br><br></p>
<h3 id="3-Pooling-Layer"><a href="#3-Pooling-Layer" class="headerlink" title="3. Pooling Layer"></a>3. Pooling Layer</h3><p>Convolutional Layer와 유사하게 feature map의 차원을 다운 샘플링하여 연산량을 감소시키고 주요한 특징 벡터를 추출하여 학습을 효과적으로 하는 것이 pooling layer의 역할이라고 할 수 있다. </p>
<p>풀링 연산에는 대표적으로 두 가지가 사용된다.</p>
<ul>
<li><strong>Max Pooling : 각 커널에서 다루는 이미지 패치에서 최대값을 추출</strong></li>
<li><strong>Average Pooling: 각 커널에서 다루는 이미지 패치에서 모든 값의 평균을 반환</strong><br><img src="/image/cnn_pooling.png" width="600"></li>
</ul>
<p>하지만 대부분의 ConvNet에서는 Avg Pooling이 아닌 <strong><em>Max Pooling</em></strong>이 사용된다. Avg Pooling의 경우 각 커널의 값을 평균화시키기 때문에 주요한 가중치를 갖는 value의 특성이 희미해질 수 있는 문제가 있기 때문이다. </p>
<p>또한 Pooling 사이즈의 경우 Stride와 같은 크기로 설정하여 모든 원소가 한번씩 처리되도록 하는것이 일반적이며, <strong>보통 Max Pooling의 경우 2 x 2커널과 2 stride를 사용하여 feature map을 절반 크기로 다운샘플링하게 된다.</strong><br><br></p>
<h3 id="4-Fully-Connected-Layer"><a href="#4-Fully-Connected-Layer" class="headerlink" title="4. Fully Connected Layer"></a>4. Fully Connected Layer</h3><p>위에서 설명한 Convolutional Layer - ReLU Activation Function - Pooling Layer의 과정을 거치며 차원이 축소 된 feature map은 최종적으로 Fully Connected Layer라는 완전 연결 층으로 전달되게 된다. </p>
<p><img src="/image/cnn_fclayer.png" width="500"></p>
<p>이 부분에서는 이미지의 <strong>3차원 벡터는 1차원으로 Flatten</strong>되게 되고 신경망에서 흔히 사용되는 활성화 함수(relu)와 함께 Output Layer로 학습이 진행된다.<br><strong>Output Layer는 Softmax 활성화 함수</strong>가 사용되는데, Softmax 함수는 입력받은 값을 모두 0 ~ 1사이의 값으로 정규화하하고 이렇게 정규화된 값들의 총합은 항상 1이되는 특성을 가지는 함수이다.</p>
<blockquote>
<p><img src="/image/cnn_softmax.png" width="430"></p>
</blockquote>
<p>따라서 마지막 Output layer의 softmax함수를 통해 이미지가 각 레이블에 속할 확률값이 레이블마다 각각 출력되게 되고 이중 가장 높은 확률값을 가지는 레이블이 최종 예측치로 선정되게 된다.<br><br></p>
<h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><ul>
<li><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" target="_blank" rel="noopener">https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53</a></li>
<li><a href="https://sonofgodcom.wordpress.com/2018/12/31/cnn%EC%9D%84-%EC%9D%B4%ED%95%B4%ED%95%B4%EB%B3%B4%EC%9E%90-fully-connected-layer%EB%8A%94-%EB%AD%94%EA%B0%80/" target="_blank" rel="noopener">https://sonofgodcom.wordpress.com/2018/12/31/cnn%EC%9D%84-%EC%9D%B4%ED%95%B4%ED%95%B4%EB%B3%B4%EC%9E%90-fully-connected-layer%EB%8A%94-%EB%AD%94%EA%B0%80/</a></li>
<li><a href="https://medium.com/dataseries/basic-overview-of-convolutional-neural-network-cnn-4fcc7dbb4f17" target="_blank" rel="noopener">https://medium.com/dataseries/basic-overview-of-convolutional-neural-network-cnn-4fcc7dbb4f17</a></li>
<li><a href="https://de-novo.org/2018/05/27/convnet-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/" target="_blank" rel="noopener">https://de-novo.org/2018/05/27/convnet-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/</a></li>
<li><a href="https://reniew.github.io/10/" target="_blank" rel="noopener">https://reniew.github.io/10/</a></li>
</ul>

  <p><a class="classtest-link" href="/tags/cnn/">cnn</a>, <a class="classtest-link" href="/tags/convnet/">convnet</a>, <a class="classtest-link" href="/tags/convolutional/">convolutional</a>, <a class="classtest-link" href="/tags/deeplearing/">deeplearing</a>, <a class="classtest-link" href="/tags/image/">image</a>, <a class="classtest-link" href="/tags/kernel/">kernel</a>, <a class="classtest-link" href="/tags/maxpooling/">maxpooling</a>, <a class="classtest-link" href="/tags/padding/">padding</a>, <a class="classtest-link" href="/tags/relu/">relu</a> — Sep 23, 2019</p>
  
  <hr>
<section id="comments" class="mt-2 mb-3">

  <div id="disqus_thread">
    <a href="#" class="button button-primary" onclick="loadDisqus();return false;">View / Make Comments</a>
  </div>

  <script>
    var disqus_config = function() {
      this.page.url = 'https://jaehyeongan.github.io/2019/09/23/basic-convnet/index.html';
      this.page.identifier = '2019/09/23/basic-convnet/index.html';
      this.page.title = '합성곱 신경망(ConvNet, Convolutional Neural Network)';
    };

    var is_disqus_loaded = false;

    function loadDisqus() {
      if (!is_disqus_loaded) {
        is_disqus_loaded = true;

        var d = document,
          s = d.createElement('script');
        s.src = 'https://jaehyeongan.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      }
    }

  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi">
      
      <a class="ml-0 footer-link icon" href="https://github.com/jaehyeongAN" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://www.linkedin.com/in/jaehyeong-an-005603160/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="LinkedIn">
        <svg class="linkedin svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
      

      

      
      <a class="ml-0 footer-link icon" href="https://www.instagram.com/an_jh.ds/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Instagram">
        <svg class="instagram svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z"/></svg>
      </a>
      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
