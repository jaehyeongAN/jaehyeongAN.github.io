<!DOCTYPE html>
<html lang="en">

<head><meta name="generator" content="Hexo 3.9.0">

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta charset="utf-8">

  
  <title>Autoencoderì™€ LSTM Autoencoder</title>
  
  <link rel="sitemap" href="https://jaehyeongan.github.iositemap.xml">
  
  <link rel="canonical" href="https://jaehyeongan.github.io/2020/02/28/Autoencoder-LSTMautoencoder/">
  
  <meta name="description" content="IntroëŒ€í‘œì ì¸ ìê¸° ì§€ë„ í•™ìŠµì¸ Autoencoderì™€ Autoencoderì— LSTM cellì„ ì ìš©í•´ ì‹œí€€ìŠ¤ í•™ìŠµì´ ê°€ëŠ¥í•œ LSTM Autoencoderì— ëŒ€í•´ ì†Œê°œí•œë‹¤. ì´í›„ ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ëŠ” LSTM Autoencoderë¥¼ í†µí•´ ë¯¸ë˜ì— ë°œìƒ í•  ê³ ì¥ì´ë‚˜ ì´ìƒì‹ ">
  
  
  <meta name="author" content>
  
  <meta property="og:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta property="og:site_name" content="jaehyeong&#39;s ds">
  <meta property="og:type" content="article">
  <meta property="og:title" content="Autoencoderì™€ LSTM Autoencoder">
  
  <meta property="og:description" content="IntroëŒ€í‘œì ì¸ ìê¸° ì§€ë„ í•™ìŠµì¸ Autoencoderì™€ Autoencoderì— LSTM cellì„ ì ìš©í•´ ì‹œí€€ìŠ¤ í•™ìŠµì´ ê°€ëŠ¥í•œ LSTM Autoencoderì— ëŒ€í•´ ì†Œê°œí•œë‹¤. ì´í›„ ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ëŠ” LSTM Autoencoderë¥¼ í†µí•´ ë¯¸ë˜ì— ë°œìƒ í•  ê³ ì¥ì´ë‚˜ ì´ìƒì‹ ">
  
  <meta property="og:url" content="https://jaehyeongan.github.io/2020/02/28/Autoencoder-LSTMautoencoder/">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Autoencoderì™€ LSTM Autoencoder">
  
  <meta name="twitter:description" content="IntroëŒ€í‘œì ì¸ ìê¸° ì§€ë„ í•™ìŠµì¸ Autoencoderì™€ Autoencoderì— LSTM cellì„ ì ìš©í•´ ì‹œí€€ìŠ¤ í•™ìŠµì´ ê°€ëŠ¥í•œ LSTM Autoencoderì— ëŒ€í•´ ì†Œê°œí•œë‹¤. ì´í›„ ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ëŠ” LSTM Autoencoderë¥¼ í†µí•´ ë¯¸ë˜ì— ë°œìƒ í•  ê³ ì¥ì´ë‚˜ ì´ìƒì‹ ">
  
  
  <meta name="twitter:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta name="twitter:url" content="https://jaehyeongan.github.io/2020/02/28/Autoencoder-LSTMautoencoder/">

  <!-- Mobile Specific Metas
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="stylesheet" href="/css/normalize.css">
  <link rel="stylesheet" href="/css/skeleton.css">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/prism-dark.css">
  <link rel="stylesheet" href="/css/prism-line-numbers.css">
  <!-- User css -->
  
  <link rel="stylesheet" href="/css/user.css">
  

  <!-- Favicon
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <link rel="icon" type="image/png" href="/images/astronaut.png">

  <!-- Custom Theme Color Style
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“â€“ -->
  

</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick="setDarkMode(true)" id="darkBtn">ğŸŒ‘</div>
      <div onclick="setDarkMode(false)" id="lightBtn" class="hidden">â˜€ï¸</div>
      <script>
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      â¬… Click this.
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/about" class="ml">About</a>
          
        
        
          
            <a href="mailto:nonamed000000@gmail.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>Autoencoderì™€ LSTM Autoencoder</h2>

  <h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>ëŒ€í‘œì ì¸ ìê¸° ì§€ë„ í•™ìŠµì¸ Autoencoderì™€ Autoencoderì— LSTM cellì„ ì ìš©í•´ ì‹œí€€ìŠ¤ í•™ìŠµì´ ê°€ëŠ¥í•œ LSTM Autoencoderì— ëŒ€í•´ ì†Œê°œí•œë‹¤. ì´í›„ ë‹¤ìŒ í¬ìŠ¤íŒ…ì—ëŠ” LSTM Autoencoderë¥¼ í†µí•´ ë¯¸ë˜ì— ë°œìƒ í•  ê³ ì¥ì´ë‚˜ ì´ìƒì‹ í˜¸ë¥¼ ì¡°ê¸° ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ Anomaly Detection ë°©ì•ˆì— ëŒ€í•´ ì†Œê°œí•  ê²ƒì´ë‹¤. </p>
<hr>
<h2 id="1-Autoencoder"><a href="#1-Autoencoder" class="headerlink" title="1. Autoencoder?"></a>1. Autoencoder?</h2><p><strong>ì˜¤í† ì¸ì½”ë”ëŠ”(autoencoder)ëŠ” ë¼ë²¨ì´ ì—†ëŠ” í›ˆë ¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ í•™ìŠµ(ì¦‰, ì§€ë„ í•™ìŠµ) ì—†ì´ë„ ì…ë ¥ ë°ì´í„°ì˜ í‘œí˜„ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì¸ê³µì‹ ê²½ë§ì´ë‹¤.</strong> ì˜¤í† ì¸ì½”ë”ëŠ” ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ input ë ˆì´ì–´, hidden ë ˆì´ì–´, output ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©° ì¼ë°˜ì ìœ¼ë¡œ Input ìœ ë‹›ë³´ë‹¤ í›¨ì”¬ ë‚®ì€ ì°¨ì›ì˜ hidden ìœ ë‹›ì„ ê°€ì§€ë¯€ë¡œ ì£¼ë¡œ <strong>ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction)</strong> ëª©ì ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤. ë˜í•œ ì˜¤í† ì¸ì½”ë”ëŠ” ê°•ë ¥í•œ feature extractorë¡œ ì‘ë™í•˜ê¸° ë•Œë¬¸ì— ë¹„ì§€ë„ ì‚¬ì „í›ˆë ¨ì— ì‚¬ìš©ë  ìˆ˜ ìˆê³ , í›ˆë ¨ ë°ì´í„°ì™€ ë§¤ìš° ë¹„ìŠ·í•œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” <strong>ìƒì„± ëª¨ë¸(generative model)</strong>ë¡œì„œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤.<br><img src="/image/autoencoder-architecture.png" width="700px"></p>
<p>ì˜¤í† ì¸ì½”ë”ê°€ í•™ìŠµí•˜ëŠ” ê²ƒì€ ë‹¨ìˆœíˆ ì…ë ¥ì„ ì¶œë ¥ìœ¼ë¡œ ë³µì‚¬í•˜ëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ê·¸ ê³¼ì •ì—ì„œ ì—¬ëŸ¬ ë°©ë²•ì˜ ì œì•½(ë‚´ë¶€ í‘œí˜„ í¬ê¸° ì œí•œ, ì…ë ¥ ì¡ìŒ ì¶”ê°€ ë“±)ì„ í†µí•´ ì˜¤í† ì¸ì½”ë”ê°€ ë‹¨ìˆœíˆ ì…ë ¥ì„ ë°”ë¡œ ì¶œë ¥ìœ¼ë¡œ ë³µì‚¬í•˜ì§€ ëª»í•˜ë„ë¡ ë§‰ê³ , ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¬í‘œí˜„(representation)í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•˜ë„ë¡ ì œì–´í•œë‹¤. ì˜¤í† ì¸ì½”ë”ëŠ” ì¸ì½”ë”(encoder)ì™€ ë””ì½”ë”(decoder)ë¡œ êµ¬ë¶„ëœë‹¤.</p>
<ul>
<li><strong>ì¸ì½”ë”(encoder) : ì¸ì§€ ë„¤íŠ¸ì›Œí¬(recognition network)ë¼ê³ ë„ í•˜ë©°, ì…ë ¥ì„ ë‚´ë¶€ í‘œí˜„ìœ¼ë¡œ ë³€í™˜</strong></li>
<li><strong>ë””ì½”ë”(decoder) : ìƒì„± ë„¤íŠ¸ì›Œí¬(generative network)ë¼ê³ ë„ í•˜ë©°, ë‚´ë¶€ í‘œí˜„ì„ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜</strong><br><br></li>
</ul>
<blockquote>
<p><img src="/image/autoencoder-reconstruction-error.PNG"></p>
</blockquote>
<p>ì˜¤í† ì¸ì½”ë”ê°€ ì…ë ¥ì„ ì¬êµ¬ì„±í•˜ê¸° ë•Œë¬¸ì— ì¶œë ¥ì„ ì¬êµ¬ì„±(reconstruction)ì´ë¼ê³  ë¶€ë¥´ë©°, ì…ë ¥ê³¼ ì¬êµ¬ì„±ëœ ì¶œë ¥ê³¼ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ <strong>ì¬êµ¬ì„± ì†ì‹¤(reconstruction loss)</strong>ì´ë¼ê³  í•œë‹¤. ì—¬ê¸°ì„œ íŒŒë¼ë¯¸í„° (Î¸,Ï†)ëŠ” encoderì— ì…ë ¥ë˜ëŠ” original input (x)ê³¼ ë””ì½”ë”ë¥¼ í†µí•´ ì¶œë ¥ ëœ reconstruced input (f(g(x))ì´ ê°™ì•„ì§€ë„ë¡ í•™ìŠµí•˜ë©° ì—…ë°ì´íŠ¸ ëœë‹¤.<br><br></p>
<h3 id="1-1-Stacked-Autoencoder"><a href="#1-1-Stacked-Autoencoder" class="headerlink" title="1.1. Stacked Autoencoder"></a>1.1. Stacked Autoencoder</h3><p>ì—¬ëŸ¬ ê°œì˜ hidden ë ˆì´ì–´ë¥¼ ê°€ì§„ ê²½ìš°ë¥¼ ì ì¸µ ì˜¤í† ì¸ì½”ë”(stacked autoencoder)ë¼ê³  í•œë‹¤. ì•„ë˜ ê·¸ë¦¼ì™€ ê°™ì´ ë ˆì´ì–´ë¥¼ ë” ì¶”ê°€í•  ê²½ìš° ì˜¤í† ì¸ì½”ë”ëŠ” ë” ë³µì‘í•œ í‘œí˜„ì„ í•™ìŠµí•  ìˆ˜ ìˆê²Œ ë˜ë©° ì¼ë°˜ì ìœ¼ë¡œ ì ì¸µ ì˜¤í† ì¸ì½”ë”ëŠ” ì¶”ê°€ëœ hideen ë ˆì´ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ëŠ” ëŒ€ì¹­ êµ¬ì¡°ë¥¼ ì´ë£¬ë‹¤.<br><img src="/image/stacked-autoencoder.png" width="650px"></p>
<p>ìœ„ì™€ ê°™ì´ ì˜¤í† ì¸ì½”ë”ê°€ ì™„ë²½í•˜ê²Œ ëŒ€ì¹­ êµ¬ì¡°ë¥¼ ì´ë£° ë•ŒëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë¬¶ê²Œ ë˜ëŠ”ë° ì´ë ‡ê²Œ í•  ê²½ìš° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ìˆ˜ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì—¬ í›ˆë ¨ì†ë„ë¥¼ ë†’ì´ê³  overfitting ìœ„í—˜ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.</p>
<p><br></p>
<h3 id="1-2-Denoising-Autoencoder"><a href="#1-2-Denoising-Autoencoder" class="headerlink" title="1.2. Denoising Autoencoder"></a>1.2. Denoising Autoencoder</h3><p>ìœ„ì—ì„œ ì‚´í´ë³´ì•˜ë˜ Stacked Autoencoderì˜ ê²½ìš° ë‹¤ìˆ˜ì˜ hidden ë ˆì´ì–´ì™€ ë…¸ë“œê°€ ì¶”ê°€ ë  ê²½ìš° overfitting ìì‹ ì— ëŒ€í•œ í‘œí˜„ì„ ì„¸ë°€í•˜ê²Œ í•™ìŠµí•˜ê²Œ ë˜ëŠ” overfitting ë¬¸ì œì— ì§ë©´í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ í•œ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ì œì•ˆëœ ê²ƒì´ <strong>Denoising Autoencoder</strong>(Vincent et al. 2008)ì´ë‹¤. ì´ ëª¨ë¸ì€ ë§ ê·¸ëŒ€ë¡œ ëª¨ë¸ì— í•™ìŠµë˜ê¸° ì „ Input ë°ì´í„°ì— ì¡ìŒ(noise)ì„ ì£¼ì–´ ëª¨ë¸ì´ ë°ì´í„° í‘œí˜„ì„ í•™ìŠµí•˜ê¸° í˜ë“¤ê²Œ ë§Œë“ ë‹¤.<br><img src="/image/denoising-autoencoder-architecture.png" width="700px"></p>
<p>ì´ë ‡ê²Œ í•˜ëŠ” ì´ìœ ëŠ” ëª¨ë¸ì„ ì¼ë°˜í™”í•˜ê¸° ìœ„í•œ ëª©ì ì´ë©°, ë…¸ì´ì¦ˆ ì¦‰, ì œì•½ì´ ìˆëŠ” ìƒí™©ì—ì„œë„ ë°ì´í„°ë¥¼ íš¨ìš¸ì ìœ¼ë¡œ ë³µì›í•˜ê¸° ìœ„í•¨ì´ë‹¤. ì´ë•Œ ì¡ìŒì„ ì£¼ê¸° ìœ„í•œ ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆì§€ë§Œ í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ ë°ì´í„°ì˜ ì¼ë¶€ê°€ ì‚­ì œëœ input(x~) ë¥¼ ë„£ì–´ ì´ x~ê°€ ì¶œë ¥ ëœ reconstruced input(xâ€™)ê³¼ ìœ ì‚¬í•´ì§€ë„ë¡ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤.</p>
<blockquote>
<p><img src="/image/denoising-autoencoder-error.png"></p>
</blockquote>
<p><br></p>
<h2 id="2-LSTM-Autoencoer"><a href="#2-LSTM-Autoencoer" class="headerlink" title="2. LSTM Autoencoer"></a>2. LSTM Autoencoer</h2><p>LSTM AutoencoderëŠ” ì‹œí€€ìŠ¤(sequence) ë°ì´í„°ì— Encoder-Decoder LSTM ì•„í‚¤í…ì²˜ë¥¼ ì ìš©í•˜ì—¬ êµ¬í˜„í•œ ì˜¤í† ì¸ì½”ë”ì´ë‹¤. ì•„ë˜ ê·¸ë¦¼ì€ LSTM ì˜¤í† ì¸ì½”ë”ì˜ êµ¬ì¡°ì´ë©° ì…ë ¥ ì‹œí€€ìŠ¤ê°€ ìˆœì°¨ì ìœ¼ë¡œ ë“¤ì–´ì˜¤ê²Œ ë˜ê³ , ë§ˆì§€ë§‰ ì…ë ¥ ì‹œí€€ìŠ¤ê°€ ë“¤ì–´ì˜¨ í›„ ë””ì½”ë”ëŠ” ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì¬ìƒì„±í•˜ê±°ë‚˜ í˜¹ì€ ëª©í‘œ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ì¶œë ¥í•œë‹¤. </p>
<p><img src="/image/lstm-autoencoder-architecture.png" width="650px"><br><br></p>
<h3 id="2-1-Reconstruction-LSTM-Autoencoder"><a href="#2-1-Reconstruction-LSTM-Autoencoder" class="headerlink" title="2.1 Reconstruction LSTM Autoencoder"></a>2.1 Reconstruction LSTM Autoencoder</h3><p>ì¬êµ¬ì„±(reconstruction)ì„ ìœ„í•œ LSTM Autoencoder êµ¬ì¡°ì´ë‹¤. ì¦‰, inputê³¼ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ outputì„ ë””ì½”ë”©í•˜ë©°, LSTM í•™ìŠµì„ ìœ„í•´ ë°ì´í„°ë¥¼ ìš°ì„  (samples, timesteps, feature)ì™€ ê°™ì€ 3dí˜•íƒœë¡œ ë³€í™˜í•œë‹¤. input ë ˆì´ì–´ì˜ featureëŠ” 1ì°¨ì›ìœ¼ë¯€ë¡œ output ë ˆì´ì–´ë„ ë™ì¼í•œ ì°¨ì›ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ì¶œë ¥ë˜ë„ë¡ í•œë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model ,models, layers, optimizers, utils</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define input sequence</span></span><br><span class="line">sequence = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># reshape input into [samples, timesteps, features]</span></span><br><span class="line">n_in = len(sequence)</span><br><span class="line">sequence = sequence.reshape((<span class="number">1</span>, n_in, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># define model</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, input_shape=(n_in, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.RepeatVector(n_in))</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(layers.TimeDistributed(layers.Dense(<span class="number">1</span>)))</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit model</span></span><br><span class="line">model.fit(sequence, sequence, epochs=<span class="number">300</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">yhat = model.predict(sequence)</span><br><span class="line">yhat</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">array([[[0.10559099],</span><br><span class="line">        [0.20217314],</span><br><span class="line">        [0.30041453],</span><br><span class="line">        [0.39952287],</span><br><span class="line">        [0.49908453],</span><br><span class="line">        [0.5987617 ],</span><br><span class="line">        [0.69832975],</span><br><span class="line">        [0.7991052 ],</span><br><span class="line">        [0.9024458 ]]], dtype=float32)</span><br></pre></td></tr></table></figure>
<p><br></p>
<h3 id="2-2-Prediction-LSTM-Autoencoder"><a href="#2-2-Prediction-LSTM-Autoencoder" class="headerlink" title="2.2 Prediction LSTM Autoencoder"></a>2.2 Prediction LSTM Autoencoder</h3><p>ì‹œê³„ì—´ì  ì˜ˆì¸¡ì„ ìœ„í•œ LSTM êµ¬ì¡°ì´ë©° input ì‹œí€€ìŠ¤ëŠ” í˜„ì¬ ì‹œì (t) output ì‹œì ì€ (t+1)ë¡œ ë‘ì–´ í•œ ì‹œì  ì•ì„ í•™ìŠµí•˜ë„ë¡ ë°ì´í„°ë¥¼ êµ¬ì„±í•œë‹¤. ì—¬ê¸°ì„œ autoencoderëŠ” í•™ìŠµ ì‹œ encoderì—ëŠ” t ì‹œì ì´ ì…ë ¥ë˜ì§€ë§Œ decoding í›„ì—ëŠ” (t+1)ì‹œì ê³¼ reconstruction errorë¥¼ ê³„ì‚°í•˜ë©° ê²°êµ­ t ì‹œì ì´ t+1 ì‹œì ì„ í•™ìŠµí•˜ê²Œ ëœë‹¤.<br>ê²°ê³¼ì ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ëŠ” 1ì´ ì…ë ¥ë˜ë©´ 2ì™€ ê°€ê¹Œìš´ ìˆ˜ë¥¼, 2ê°€ ì…ë ¥ë˜ë©´ 3ê³¼ ê°€ê¹Œìš´ ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê²Œ ëœë‹¤.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define input sequence</span></span><br><span class="line">seq_in = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># reshape input into [samples, timesteps, features]</span></span><br><span class="line">n_in = len(seq_in)</span><br><span class="line">seq_in = seq_in.reshape((<span class="number">1</span>, n_in, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare output sequence</span></span><br><span class="line">seq_out = seq_in[:, <span class="number">1</span>:, :]</span><br><span class="line">n_out = n_in - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define model </span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, input_shape=(n_in, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.RepeatVector(n_out))</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(layers.TimeDistributed(layers.Dense(<span class="number">1</span>)))</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit model</span></span><br><span class="line">model.fit(seq_in, seq_out, epochs=<span class="number">300</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">yhat = model.predict(seq_in)</span><br><span class="line">yhat</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">array([[[0.16683361],</span><br><span class="line">        [0.2898971 ],</span><br><span class="line">        [0.403169  ],</span><br><span class="line">        [0.5089176 ],</span><br><span class="line">        [0.6094323 ],</span><br><span class="line">        [0.7060289 ],</span><br><span class="line">        [0.7997408 ],</span><br><span class="line">        [0.89148134]]], dtype=float32)</span><br></pre></td></tr></table></figure>
<p><br></p>
<h3 id="2-3-Composite-LSTM-Autoencoder"><a href="#2-3-Composite-LSTM-Autoencoder" class="headerlink" title="2.3 Composite LSTM Autoencoder"></a>2.3 Composite LSTM Autoencoder</h3><p>Reconstructionê³¼ Prediction ëª¨ë¸ì„ í†µí•©í•œ ëª¨ë¸ì´ë‹¤. ëª¨ë¸ì˜ í†µí•©ì„ ìœ„í•´ ì˜ˆì œì—ì„œëŠ” <a href="https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/">keras functional api</a>ë¥¼ í™œìš©í•˜ì˜€ìœ¼ë©°, ê²°ê³¼ì ìœ¼ë¡œ ì¶œë ¥ ì‹œ reconstructionê²°ê³¼ì™€ predictionê²°ê³¼ê°€ í•¨ê»˜ ì¶œë ¥ëœë‹¤.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define input sequence</span></span><br><span class="line">seq_in = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># reshape input into [samples, timesteps, features]</span></span><br><span class="line">n_in = len(seq_in)</span><br><span class="line">seq_in = seq_in.reshape((<span class="number">1</span>, n_in, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare output sequence</span></span><br><span class="line">seq_out = seq_in[:, <span class="number">1</span>:, :]</span><br><span class="line">n_out = n_in - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define encoder</span></span><br><span class="line">visible = layers.Input(shape=(n_in, <span class="number">1</span>))</span><br><span class="line">encoder = layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>)(visible)</span><br><span class="line"><span class="comment"># define reconstruct decoder</span></span><br><span class="line">decoder1 = layers.RepeatVector(n_in)(encoder)</span><br><span class="line">decoder1 = layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>)(decoder1)</span><br><span class="line">decoder1 = layers.TimeDistributed(layers.Dense(<span class="number">1</span>))(decoder1)</span><br><span class="line"><span class="comment"># define predict decoder</span></span><br><span class="line">decoder2 = layers.RepeatVector(n_out)(encoder)</span><br><span class="line">decoder2 = layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>)(decoder2)</span><br><span class="line">decoder2 = layers.TimeDistributed(layers.Dense(<span class="number">1</span>))(decoder2)</span><br><span class="line"><span class="comment"># concat model</span></span><br><span class="line">model = Model(inputs=visible, outputs=[decoder1, decoder2])</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line"><span class="comment"># utils.plot_model(model, show_shapes=True, to_file='composite_lstm_autoencoder.png')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fit model </span></span><br><span class="line">model.fit(seq_in, [seq_in, seq_out], epochs=<span class="number">300</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">yhat = model.predict(seq_in)</span><br><span class="line">yhat</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[array([[[0.10127164],</span><br><span class="line">         [0.19949059],</span><br><span class="line">         [0.29943317],</span><br><span class="line">         [0.39987874],</span><br><span class="line">         [0.50023794],</span><br><span class="line">         [0.60028654],</span><br><span class="line">         [0.7000689 ],</span><br><span class="line">         [0.79983366],</span><br><span class="line">         [0.89999163]]], dtype=float32), array([[[0.19868489],</span><br><span class="line"></span><br><span class="line">         [0.30206183],</span><br><span class="line">         [0.3981459 ],</span><br><span class="line">         [0.4989811 ],</span><br><span class="line">         [0.600592  ],</span><br><span class="line">         [0.7013527 ],</span><br><span class="line">         [0.80077535],</span><br><span class="line">         [0.8988221 ]]], dtype=float32)]</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a href="https://github.com/ageron/handson-ml" target="_blank" rel="noopener">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a></li>
<li><a href="https://arxiv.org/abs/1502.04681" target="_blank" rel="noopener">Unsupervised Learning of Video Representations using LSTMs</a></li>
<li><a href="https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html</a></li>
<li><a href="https://machinelearningmastery.com/lstm-autoencoders/" target="_blank" rel="noopener">https://machinelearningmastery.com/lstm-autoencoders/</a></li>
</ul>

  <p><a class="classtest-link" href="/tags/autoencoder/">autoencoder</a>, <a class="classtest-link" href="/tags/decoder/">decoder</a>, <a class="classtest-link" href="/tags/encoder/">encoder</a>, <a class="classtest-link" href="/tags/lstm/">lstm</a>, <a class="classtest-link" href="/tags/reconstruction/">reconstruction</a>, <a class="classtest-link" href="/tags/rnn/">rnn</a> â€” Feb 28, 2020</p>
  
  <hr>
<section id="comments" class="mt-2 mb-3">

  <div id="disqus_thread">
    <a href="#" class="button button-primary" onclick="loadDisqus();return false;">View / Make Comments</a>
  </div>

  <script>
    var disqus_config = function() {
      this.page.url = 'https://jaehyeongan.github.io/2020/02/28/Autoencoder-LSTMautoencoder/index.html';
      this.page.identifier = '2020/02/28/Autoencoder-LSTMautoencoder/index.html';
      this.page.title = 'Autoencoderì™€ LSTM Autoencoder';
    };

    var is_disqus_loaded = false;

    function loadDisqus() {
      if (!is_disqus_loaded) {
        is_disqus_loaded = true;

        var d = document,
          s = d.createElement('script');
        s.src = 'https://jaehyeongan.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      }
    }

  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with â¤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi">
      
      <a class="ml-0 footer-link icon" href="https://github.com/jaehyeongAN" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://www.linkedin.com/in/jaehyeong-an-005603160/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="LinkedIn">
        <svg class="linkedin svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
      

      

      
      <a class="ml-0 footer-link icon" href="https://www.instagram.com/an_jh.ds/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Instagram">
        <svg class="instagram svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z"/></svg>
      </a>
      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
