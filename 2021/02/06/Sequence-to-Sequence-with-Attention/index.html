<!DOCTYPE html>
<html lang="en">

<head><meta name="generator" content="Hexo 3.9.0">

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>[Basic NLP_1] Sequence-to-Sequence with Attention</title>
  
  <link rel="sitemap" href="https://jaehyeongan.github.iositemap.xml">
  
  <link rel="canonical" href="https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/">
  
  <meta name="description" content="Intro최근 몇 년간 Transformer 모델의 등장 이후 BERT, GPT, RoBERTa, XLNet, ELECTRA, BART 등과 같은 언어 모델(Language Model)이 매해 새로운 SOTA를 달성하며 등장하고 있다.특히 언어모델의 경우 self-su">
  
  
  <meta name="author" content>
  
  <meta property="og:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta property="og:site_name" content="jaehyeong&#39;s ds">
  <meta property="og:type" content="article">
  <meta property="og:title" content="[Basic NLP_1] Sequence-to-Sequence with Attention">
  
  <meta property="og:description" content="Intro최근 몇 년간 Transformer 모델의 등장 이후 BERT, GPT, RoBERTa, XLNet, ELECTRA, BART 등과 같은 언어 모델(Language Model)이 매해 새로운 SOTA를 달성하며 등장하고 있다.특히 언어모델의 경우 self-su">
  
  <meta property="og:url" content="https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="[Basic NLP_1] Sequence-to-Sequence with Attention">
  
  <meta name="twitter:description" content="Intro최근 몇 년간 Transformer 모델의 등장 이후 BERT, GPT, RoBERTa, XLNet, ELECTRA, BART 등과 같은 언어 모델(Language Model)이 매해 새로운 SOTA를 달성하며 등장하고 있다.특히 언어모델의 경우 self-su">
  
  
  <meta name="twitter:image" content="https://jaehyeongan.github.ioundefined">
  
  <meta name="twitter:url" content="https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="../fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="../fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="/css/normalize.css">
  <link rel="stylesheet" href="/css/skeleton.css">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/prism-dark.css">
  <link rel="stylesheet" href="/css/prism-line-numbers.css">
  <!-- User css -->
  
  <link rel="stylesheet" href="/css/user.css">
  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/astronaut.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick="setDarkMode(true)" id="darkBtn">🌑</div>
      <div onclick="setDarkMode(false)" id="lightBtn" class="hidden">☀️</div>
      <script>
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      ⬅ Apply Dark.
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
          
          <a href="/about" class="ml">About</a>
          
        
        
          
            <a href="mailto:nonamed000000@gmail.com" target="_blank" class="ml">Email</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>[Basic NLP_1] Sequence-to-Sequence with Attention</h2>

  <h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>최근 몇 년간 Transformer 모델의 등장 이후 BERT, GPT, RoBERTa, XLNet, ELECTRA, BART 등과 같은 언어 모델(Language Model)이 매해 새로운 SOTA를 달성하며 등장하고 있다.<br>특히 언어모델의 경우 self-supervised learning으로 영어 뿐만 아니라 최근 다양한 언어로 학습된 모델이 등장하고 있고, 그 덕에 다양한 자연어 처리 태스크들에서 fine-tuning시 데이터가 많지 않더라도 좋은 성능을 보여주고 있다. 이러한 트렌드를 이끈 것은 Transformer의 역할이 크지만 그 전에 Transformer의 전신인 <strong>Sequence-to-Sequnce모델</strong>과 <strong>Attention mechanism</strong>에 대해 먼저 간단하게 살펴보려고 한다.</p>
<hr>
<h1 id="Sequnece-to-Sequence"><a href="#Sequnece-to-Sequence" class="headerlink" title="Sequnece-to-Sequence"></a>Sequnece-to-Sequence</h1><p><img src="/image/sequence-to-sequence.PNG" width="800"><br>Sequence-to-Sequence(이하 seq2seq)모델은 2014년 구글에 의해 제안된 모델로서 이름 그대로 시퀀스 형태의 입력값을 받아 시퀀스 형태의 출력값을 만드는 모델이며, 기존 DNN모델이 입력과 출력 벡터의 차원이 고정되어있다는 한계를 극복하여 가변 길이의 출력을 가능하게 한 모델이다.<br>seq2seq모델은 기본적으로 RNN 모델을 기반으로 하며, 크게 인코더(Encoder)와 디코더(Decoder)로 구분된다.</p>
<h2 id="1-Encoder"><a href="#1-Encoder" class="headerlink" title="1. Encoder"></a>1. Encoder</h2><p>Encoder에서는 각 시퀀스마다 embedding vector를 입력으로 받아 입력 시퀀스의 마지막까지 순차적으로 weight을 업데이트한다.(RNN 학습 방법과 동일) 그렇게 되면 마지막 시퀀스의 hidden states는 이전 입력 시퀀스들을 정보를 순차적으로 반영하여 업데이트 된 상태이며, 입력 시퀀스의 전반적인 문맥을 반영하고 있다고 하여 <strong>컨텍스트 벡터(Context vector)</strong>라고 부른다.<br><br></p>
<h2 id="2-Decoder"><a href="#2-Decoder" class="headerlink" title="2. Decoder"></a>2. Decoder</h2><p>Decoder는 우선 Encoder의 전체적인 문맥이 학습된 context vector와 &lt; SOS &gt; (Start of Sentence) 토큰을 첫 입력으로 받아 출력 토큰을 예측한다. </p>
<p align="center"><img src="/image/seq2seq_probability.PNG" width="400"></p>

<p>Decoder의 현재 시점(t)의 출력결과는 이전 시점(t1,…,t-1) 출력 결과의 조건부 확률로서, 이전 시점의 결과에 따라 현재 시점의 출력 결가 영향을 받게 되는 구조이며, 이렇게 예측된 출력값은 다시 다음 시퀀스의 예측을 위해 입력값으로 사용되고 이러한 과정이 &lt; EOS &gt; (End of Sentence) 토큰이 등장할 때 까지 반복된다.<br><br></p>
<h2 id="Example-Machine-Translation"><a href="#Example-Machine-Translation" class="headerlink" title="Example (Machine Translation)"></a>Example (Machine Translation)</h2><p><img src="/image/seq2seq_gif.gif" width="800"><br>seq2seq를 기계번역에 적용할 시 위와 같이 프랑스어에 해당하는 입력 시퀀스들이 순차적으로 Encoder로 입력되어 마지막 시퀀스까지 weight을 업데이트하고 그렇게 업데이트 된 마지막 입력 시퀀스 즉, Context Vector를 Decoder의 입력으로 넘겨주어 영어로 출력하게 된다.<br><br></p>
<h2 id="seq2seq의-한계"><a href="#seq2seq의-한계" class="headerlink" title="seq2seq의 한계"></a>seq2seq의 한계</h2><p>seq2seq는 출력 시퀀스의 가변 길이 출력이 가능해짐으로써 언어 모델의 발전을 가져왔지만 입력 시퀀스가 길어질 수 록 초기 입력 시퀀스의 정보를 잃게 되는 gradient vanishing 문제가 제기되었다. 아무래도 하나의 context vector에 입력 시퀀스의 모든 정보를 담다보니 전체 문맥 정보가 희미해질 수 밖에 없고 이는 RNN 계열의 모델(RNN, LSTM, GRU 등)에서 고질적으로 발생하는 문제이다.<br><br><br></p>
<h2 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h2><p>Attention mechanism은 위에서 언급한 seq2seq의 한계를 극복하기 위해 제안된 개념이다. Attention의 기본적인 아이디어는 Decoder에서 출력 토큰 예측 시 매 시점(time step)마다 입력 시퀀스의 토큰을 참조하여 <strong>연관성이 높은 토큰에 가중치를 높여 학습</strong>한다는 것이다.<br><img src="/image/attention_mechanism.png"></p>
<h3 id="1-Query-Key-Value"><a href="#1-Query-Key-Value" class="headerlink" title="1. Query, Key, Value"></a>1. Query, Key, Value</h3><p>Attention 계산은 Decoder 출력 토큰 예측 시 수행되며 아래와 같이 Query, Key, Value라는 개념이 사용된다.</p>
<blockquote>
<p>Q(Query) : t 시점의 decoder셀의 hidden states<br>K(Key) : 모든 시점의 encoder셀의 hidden states<br>V(Value) : 모든 시점의 encoder셀의 hidden states</p>
</blockquote>
<h3 id="2-Attention-Score"><a href="#2-Attention-Score" class="headerlink" title="2. Attention Score"></a>2. Attention Score</h3><p>Attention Score란 Decoder에서 출력 토큰 예측 시 Encoder의 모든 시퀀스 정보를 참조(attention)하여 각각의 시퀀스가 얼마나 출력 토큰과 유사한지를 판단한 유사도 값이다.<br>이 과정에서 Decoder의 현재 t시점은 Query가 되고, 참조하고자 하는 Encoder의 모든 hidden states는 Key가 된다. 이때 Query는 전치(transpose) 후 모든 key에 대해 각각 <strong>내적(dot-product)연산</strong>을 수행하여 Encoder의 Key 갯수만큼의 Attention score를 계산한다.</p>
<p align="center"><img src="/image/attention_score.PNG" width="350"></p>

<h3 id="3-Attention-Distribution"><a href="#3-Attention-Distribution" class="headerlink" title="3. Attention Distribution"></a>3. Attention Distribution</h3><p>입력 시퀀스 갯수만큼 나온 Attention Score 리스트에 <strong>Softmax 함수</strong>를 적용한다. Softmax를 적용하게 되면 합이 1이되는 확률분포가 되는데 여기서 각각의 값들을 Attention weight라고 한다.</p>
<p align="center"><img src="/image/attention_distribution.PNG" width="330"></p>

<h3 id="4-Attention-Value"><a href="#4-Attention-Value" class="headerlink" title="4. Attention Value"></a>4. Attention Value</h3><p>위에서 구한 Attention weight을 다시 각각의 Encoder의 hidden state와 곱셈연산을 하고, 이후 모든 값들을 더해주는 <strong>가중합(weighted sum)</strong>을 하여 최종 Attention Value(혹은 Context Value)를 구하여 이를 Decoder의 현재 t시점의 입력값으로 사용한다. </p>
<p align="center"><img src="/image/attention_value.PNG" width="150"></p>

<p>위의 과정을 거쳐 나온 최종 Attention value는 Decoder의 예측하려는 t 시점의 입력값으로 사용되고 매 시점 예측 시 마다 위와 같은 과정이 반복된다. </p>
<p>아래는 Attention 과정을 애니메이션으로 표현한 것이다.<br><img src="/image/attention-process.gif" width="800"></p>
<p><br></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>사실 Transformer는 Sequence-to-Sequence와 같은 Encoder-Decoder 구조를 여러개 사용한 것이고, Transformer에서 사용되는 self-attention 및 multi-head attention 또한 기존 Attention mechanism을 응용한 것이기 때문에 Sequence-to-Sequence모델과 Attention 개념만 알아도 Transformer 아키텍처를 이해하는데 어렵지 않을 것이다. 또한 이후 등장한 모델들도 대부분 이와 같은 구조를 응용한 모델이라고 할 수 있기 때문에 확실히 이해하고 넘어가는 것이 좋을 듯 하다.</p>
<p>Tensorflow, Pytorch 공식 doc에서 seq-to-seq with attention모델 구현 tutorial이 준비되어 있으니 참고!</p>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/text/nmt_with_attention" target="_blank" rel="noopener">Neural machine translation with attention</a></li>
<li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" target="_blank" rel="noopener">NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION</a></li>
</ul>
<hr>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://arxiv.org/abs/1409.3215" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
<li><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank" rel="noopener">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a></li>
</ul>

  <p><a class="classtest-link" href="/tags/attention/">attention</a>, <a class="classtest-link" href="/tags/context/">context</a>, <a class="classtest-link" href="/tags/nlp/">nlp</a>, <a class="classtest-link" href="/tags/seq2seq/">seq2seq</a>, <a class="classtest-link" href="/tags/transformer/">transformer</a> — Feb 6, 2021</p>
  
  <hr>
<section id="comments" class="mt-2 mb-3">

  <div id="disqus_thread">
    <a href="#" class="button button-primary" onclick="loadDisqus();return false;">View / Make Comments</a>
  </div>

  <script>
    var disqus_config = function() {
      this.page.url = 'https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/index.html';
      this.page.identifier = '2021/02/06/Sequence-to-Sequence-with-Attention/index.html';
      this.page.title = '[Basic NLP_1] Sequence-to-Sequence with Attention';
    };

    var is_disqus_loaded = false;

    function loadDisqus() {
      if (!is_disqus_loaded) {
        is_disqus_loaded = true;

        var d = document,
          s = d.createElement('script');
        s.src = 'https://jaehyeongan.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
      }
    }

  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>



          <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi">
      
      <a class="ml-0 footer-link icon" href="https://github.com/jaehyeongAN" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      
      <a class="ml-0 footer-link icon" href="https://www.linkedin.com/in/jaehyeong-an-005603160/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="LinkedIn">
        <svg class="linkedin svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>LinkedIn</title><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
      </a>
      

      

      
      <a class="ml-0 footer-link icon" href="https://www.instagram.com/an_jh.ds/" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Instagram">
        <svg class="instagram svg-hov" width="18" role="img" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Instagram</title><path d="M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z"/></svg>
      </a>
      

    </div>
  
</div>

        </div>
      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>
  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
