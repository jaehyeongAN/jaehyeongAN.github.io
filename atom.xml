<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jaehyeong&#39;s ds</title>
  
  <subtitle>for data scientist</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jaehyeongan.github.io/"/>
  <updated>2021-02-17T15:08:22.023Z</updated>
  <id>https://jaehyeongan.github.io/</id>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[Basic NLP_2] Transformer (Attention Is All You Need)</title>
    <link href="https://jaehyeongan.github.io/2021/02/07/Transformer/"/>
    <id>https://jaehyeongan.github.io/2021/02/07/Transformer/</id>
    <published>2021-02-07T14:45:19.000Z</published>
    <updated>2021-02-17T15:08:22.023Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>지난 포스트인 <a href="https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/">Sequence-to-Sequence with Attention</a>에서 sequence-to-sequence 모델의 경우 RNN 계열의 순환 신경망을 사용함으로 인해 입력 시퀀스가 길어질 수 록 하나의 Context Vector에 모든 정보를 담기 부족하다는 한계가 있음을 확인하였다. 그로 인해 Attention mechanism이 적용되었지만 이 또한 결국 문장에 가중치만 줄 뿐 하나의 Context Vector에 문맥 정보를 압축한다는 점에서 같은 문제가 있었고, 이러한 시퀀스 순서를 유지하며 학습하는 RNN의 한계가 지적되었다.<br>이후 이러한 문제를 해결하기 위해 RNN셀이 전부 제거되고 Attention기법을 중점으로 학습하는 모델이 등장하였으니 그것이 바로 트랜스포머(Transformer) 모델이다.</p><p style="text-align: center;"><img src="/image/Transformer_movie.png"></p><p style="text-align: center; font-size:12px;">(우리가 아는 그 영화는 뒤에 's'가 붙는다. Transformers...)</p><hr><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p>트랜스포머(Transformer)모델은 2017년 구글에 의해 소개된 논문인 <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">“Attention is all you need”</a>에서 등장한 모델이다. 기본적으로 트랜스포머 모델은 앞서 살펴보았던 Sequence-to-Sequence의 인코더(Encoder), 디코더(Decoder)의 구조를 가지고 있지만 RNN셀을 사용하지 않고 단순히 어텐션(Attention)구조만으로 이루어져 있다는 것, 그리고 이러한 인코더-디코더 구조가 n개(논문에서는 6개) 존재한다는 것이 큰 특징이다.</p><p style="text-align: center;"><img src="/image/transformer-model-architecture.png"></p><p>위 그림은 트랜스포머 모델의 전체적인 아키텍처이다. <strong>크게 왼쪽 부분을 인코더(Encoder)로 구분하고, 오른쪽을 디코더(Decoder)로 구분하며 이러한 구조가 n개 존재한다.</strong> 학습 방법은 seq2seq모델과 같이 인코더에서 입력 시퀀스의 특징을 학습하고 이를 디코더의 입력 벡터로 넘겨주어 하나의 토큰씩 출력하게 된다. 하지만 seq2seq와 크게 다른 점은 시퀀스 순서를 학습하기 위한 RNN셀을 사용하지 않는다는 것인데 그것을 대체하기 위해 <strong>Positinal Encoding</strong>이라는 기법을 사용하였으며, 기존 Attention과 비슷하면서도 조금 다른 <strong>Self-Attention</strong>과 <strong>Multi-Head Attention</strong>이라는 기법을 적용하였다. 아래에서 각 부분에 대해 자세히 살펴보도록 하자.<br><br></p><h2 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h2><p>위에서 언급했다시피 RNN셀을 통해 순차적으로 시퀀스를 입력받는 seq2seq와 달리 트랜스포머 모델은 입력 시퀀스가 순차적으로 입력되는 것이 아니라 한번에 병렬적으로 인코더로 입력된다. 이렇게 모든 단어가 한번에 입력되면 입력 단어들의 순서정보를 보존할 수 없게 되는데, 이런 문제를 해결하기 위한 방법이 바로 Positional Encoding이다.</p><p>순서정보를 유지하기 위한 Positional Encoding함수의 수식은 아래와 같다.</p><p style="text-align: center;"><img src="/image/positional_encoding2.png" width="400"></p><p style="text-align: center;"><img src="/image/positional_encoding.png" width="400"></p><p>위 수식의 <em>‘pos’</em>는 임베딩 벡터의 위치를 나타내고 <em>‘i’</em>는 인덱스를 나타낸다.<br>위 수식을 살펴보면 <strong>인덱스가 짝수(pos, 2i)인 경우는 사인(sin)함수를 적용</strong>하고, <strong>홀수(pos, 2i+1)인 경우는 코사인(cos)함수</strong>를 적용하여 순서 정보를 반영해주는 것을 알 수 있다.</p><p style="text-align: center;"><img src="/image/positional_encoding_matrix.png"></p><p>이렇게 계산된 포지션 임베딩 행렬(Positional Embedding Matrix)은 입력 원본 문장의 임베딩 행렬(Input Embedding Matrix)에 단순 덧셈연산을 통해 더해져 인코더의 input으로 사용되게 된다.<br><br></p><h2 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h2><p style="text-align: center;"><img src="/image/scaled_dot_product_attention.png"></p><p>Self-Attention은 기존 Attention개념과 크게 다르지 않다. 기존 Attention은 디코더에서 예측하고자 하는 시퀀스(Query)를 인코더의 모든 시퀀스(Keys)와 내적연산을 통해 계산하였었는데,<br><em>(참고 :  <a href="https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/">Seq2Seq with Attention 모델에서의 Attention</a>)</em></p><p>Self-Attention은 말 그대로 Attention 연산을 해당 문장 시퀀스 자체에서 수행하는 것을 말하며 다른 점은 기존에는 내적(Dot-Product) 연산을 수행하였는데 트랜스포머 모델에서는 <strong>스케일 내적(scaled Dot-Product) 연산</strong>을 통해 Attention을 수행한다는 것이다. </p><p style="text-align: center;"><img src="/image/scaled_dot_product_attention_expression.png" width="400"></p><p>위 수식을 보면 key를 전치 후 query와 내적 연산을 한 후, Dk(key의 차원(dimension))를 제곱근한 값으로로 나눠주는 것을 알 수 있다. Scaling을 해주는 이유는 query와 key의 차원이 클 수 록 내적 연산을 통한 값도 계속해서 폭증하게 되는데 이렇게 되면 후에 Softmax함수에서 학습이 잘 안되기 때문에 이러한 경우를 위해 차원의 루트값으로 나눠주는 것이다. </p><p style="text-align: center;"><img src="/image/scaled_dot_product_attention_matrix.png"></p><p>그리고 주의할 점은 self-attention 연산이 각각의 벡터마다 한번씩 이루어지는 게 아니라 <strong>행렬(maxtrix) 연산</strong>으로 이루어진다는 것이다. 이것을 <strong>외적(Outer-Product) 연산</strong>이라고 하는데, 각각의 벡터에 내적 연산을 하나 벡터 매트릭스 자체에 외적 연산을 하나 결국 동일한 연산이고, 한번에 외적 연산을 수행하는 것이 더 컴퓨팅 연산 상 효율적이다.<br><br></p><h2 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h2><p style="text-align: center;"><img src="/image/multi-head-attention.png"></p><p>그리고 위에서 살펴 본 self-attention을 한번만 수행하는 것이 아니라 Query, Key, Value의 특징값을 헤드 수만큼 나눠서 여러번 Self-Attention을 수행한 후 각각의 값을 합산하는 것을 Multi-Head Attention이라고 한다.</p><p><strong>아래는 Multi-Head Self-Attention의 전체적인 프로세스이다.</strong></p><p style="text-align: center;"><img src="/image/transformer_multi-headed_self-attention-recap.png"></p><p><br></p><h2 id="Masked-Multi-Head-Attention"><a href="#Masked-Multi-Head-Attention" class="headerlink" title="Masked Multi-Head Attention"></a>Masked Multi-Head Attention</h2><p>Masked Multi-Head Attention은 디코더 단에서 수행되는 것으로 Multi-Head Attention과 근본적으로 동일하나 다른 점은 Self-Attention 계산 수행 시 현재 시점보다 앞에 있는 시퀀스들과만 Attention을 수행하고 뒤에 오는 시퀀스는 참조하지 않는 것을 말한다. </p><p style="text-align: center;"><img src="/image/masked-self-attention.svg"></p><p>기존 seq2seq와 같은 순환 신경망 모델은 시퀀스가 순차적으로 입력되기 때문에 앞쪽부터 순차적으로 업데이트 되어온 hidden state을 다음 시퀀스 예측을 위해 사용하게된다. 하지만 언급했다시피 트랜스포머 모델은 입력 시퀀스가 한번에 들어가기 때문에 현재 시점보다 뒤에 올 시퀀스의 정보까지 알 수 있게 된다. 현재 시점의 값도 알지못하는데 뒤에 올 정보를 참조한다는 것은 직관적으로도 틀리다. 그래서 현재 시점보다 뒤에 있는 시퀀스를 참조하지 않기 위해 Masking을 한 후 Self-Attention을 수행하게 된다.<br><br></p><h2 id="Residual-Connection-amp-Layer-Nomalization"><a href="#Residual-Connection-amp-Layer-Nomalization" class="headerlink" title="Residual Connection &amp; Layer Nomalization"></a>Residual Connection &amp; Layer Nomalization</h2><p style="text-align: center;"><img src="/image/transformer_resideual_layer_norm_2.png" width="450"></p><p>위 그림을 보면 점선으로 표시된 화살표가 Attention 레이어와 Feed-Forward 레이어를 지나쳐 <strong>Add &amp; Normalize</strong> 해주는 부분이 있는데, 이 부분에서 Residual Conntection과 Layer Normalization이 수행된다.</p><p>Residual Connection이란 ResNet(Residual Network)에서 나온 개념으로 보존된 identity를 현재 레이어를 뛰어넘어 다음 레이어로 더해주는 방법을 말한다. 당시 ResNet은 2015년 ImageNet대회에서 높은 성능을 보였는데 이러한 학습 방법이 앙상블(Ensemble) 학습과 같은 효과가 있고, 경사소실(Gradient Vanishing) 문제에 도움이 되어 더 깊은 신경망 학습이 가능하다고 한다.</p><p style="text-align: center;"><img src="/image/residual_connection.png" width="400"></p><p>우선 Residual Connection은 학습시 입력값을 보존하였다가(identity x) 비선형 활성화함수(ReLU)를 거친 다음 레이어의 값에 직접적으로 더해줌으로써 <strong>gradient가 소실되는 것을 방지하고, 이후 수행될 Layer Normalization의 학습 효율을 증대시킨다.</strong></p><p>트랜스포머에서는 인코더와 디코더 모두에서 사용되며 각각 Attention Layer와 Feed-Forward Network를 거치기 전 입력값에 대해 Residual Connection과 Layer Nomalization을 수행한다.<br><br></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>처음 트랜스포머 아키텍처를 봤을 때 인코더와 디코더 내에서 각각 여러 개의 레이어를 거치는 모습을 보고 복잡한 구조라고 생각했었다. 그런데 막상 보니 기존 Sequence-to-Sequence with Attention 원리 자체는 크게 다르지 않은 것 같고, 모델 사이즈의 증가와 약간의 학습방법의 차이만 존재하는 것 같다. </p><p>최근 대다수의 pretrain 모델이 트랜스포머 아키텍처를 base로 설계되고 있기 때문에 굉장히 중요한 모델임에 틀림없는 것 같고, 이후 등장한 BERT, XLnet RoBERTa, BART 등과 같은 모델들도 단지 training 방법에 차이만 있을 뿐이라 트랜스포머 아키텍처만 잘 알아도 쉽게 접근할 수 있을 것 같다. </p><p>트랜스포머 모델 또한 Tensorflow와 Pytorch 공식 doc에 tutorial이 준비되어 있느니 참고!<br><a href="https://www.tensorflow.org/tutorials/text/transformer" target="_blank" rel="noopener">Transformer model for language understanding</a><br><a href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html" target="_blank" rel="noopener">SEQUENCE-TO-SEQUENCE MODELING WITH NN.TRANSFORMER AND TORCHTEXT</a></p><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a></li><li><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a></li><li><a href="https://wikidocs.net/31379" target="_blank" rel="noopener">딥러닝을 이용한 자연어 처리 입문 - 트랜스포머</a></li><li><a href="https://medium.com/swlh/what-exactly-is-happening-inside-the-transformer-b7f713d7aded" target="_blank" rel="noopener">What Exactly Is Happening Inside the Transformer</a></li><li><a href="https://yohai.tistory.com/93" target="_blank" rel="noopener">Residual Connection의 성능 및 효과와 Transformer에서의 Residual Connection</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;지난 포스트인 &lt;a href=&quot;https://jaehyeongan.github.io/2021/02/06/
      
    
    </summary>
    
    
      <category term="nlp" scheme="https://jaehyeongan.github.io/tags/nlp/"/>
    
      <category term="transformer" scheme="https://jaehyeongan.github.io/tags/transformer/"/>
    
      <category term="attention" scheme="https://jaehyeongan.github.io/tags/attention/"/>
    
      <category term="self-attention" scheme="https://jaehyeongan.github.io/tags/self-attention/"/>
    
      <category term="positional-encoding" scheme="https://jaehyeongan.github.io/tags/positional-encoding/"/>
    
  </entry>
  
  <entry>
    <title>[Basic NLP_1] Sequence-to-Sequence with Attention</title>
    <link href="https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/"/>
    <id>https://jaehyeongan.github.io/2021/02/06/Sequence-to-Sequence-with-Attention/</id>
    <published>2021-02-06T12:46:46.000Z</published>
    <updated>2021-02-17T15:07:23.363Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>최근 몇 년간 Transformer 모델의 등장 이후 BERT, GPT, RoBERTa, XLNet, ELECTRA, BART 등과 같은 언어 모델(Language Model)이 매해 새로운 SOTA를 달성하며 등장하고 있다.<br>특히 언어모델의 경우 self-supervised learning으로 영어 뿐만 아니라 최근 다양한 언어로 학습된 모델이 등장하고 있고, 그 덕에 다양한 자연어 처리 태스크들에서 fine-tuning시 데이터가 많지 않더라도 좋은 성능을 보여주고 있다. 이러한 트렌드를 이끈 것은 Transformer의 역할이 크지만 그 전에 Transformer의 전신인 <strong>Sequence-to-Sequnce모델</strong>과 <strong>Attention mechanism</strong>에 대해 먼저 간단하게 살펴보려고 한다.</p><hr><h1 id="Sequnece-to-Sequence"><a href="#Sequnece-to-Sequence" class="headerlink" title="Sequnece-to-Sequence"></a>Sequnece-to-Sequence</h1><p><img src="/image/sequence-to-sequence.PNG" width="800"><br>Sequence-to-Sequence(이하 seq2seq)모델은 2014년 구글에 의해 제안된 모델로서 이름 그대로 시퀀스 형태의 입력값을 받아 시퀀스 형태의 출력값을 만드는 모델이며, 기존 DNN모델이 입력과 출력 벡터의 차원이 고정되어있다는 한계를 극복하여 가변 길이의 출력을 가능하게 한 모델이다.<br>seq2seq모델은 기본적으로 RNN 모델을 기반으로 하며, 크게 인코더(Encoder)와 디코더(Decoder)로 구분된다.</p><h2 id="1-Encoder"><a href="#1-Encoder" class="headerlink" title="1. Encoder"></a>1. Encoder</h2><p>Encoder에서는 각 시퀀스마다 embedding vector를 입력으로 받아 입력 시퀀스의 마지막까지 순차적으로 weight을 업데이트한다.(RNN 학습 방법과 동일) 그렇게 되면 마지막 시퀀스의 hidden states는 이전 입력 시퀀스들을 정보를 순차적으로 반영하여 업데이트 된 상태이며, 입력 시퀀스의 전반적인 문맥을 반영하고 있다고 하여 <strong>컨텍스트 벡터(Context vector)</strong>라고 부른다.<br><br></p><h2 id="2-Decoder"><a href="#2-Decoder" class="headerlink" title="2. Decoder"></a>2. Decoder</h2><p>Decoder는 우선 Encoder의 전체적인 문맥이 학습된 context vector와 &lt; SOS &gt; (Start of Sentence) 토큰을 첫 입력으로 받아 출력 토큰을 예측한다. </p><p align="center"><img src="/image/seq2seq_probability.PNG" width="400"></p><p>Decoder의 현재 시점(t)의 출력결과는 이전 시점(t1,…,t-1) 출력 결과의 조건부 확률로서, 이전 시점의 결과에 따라 현재 시점의 출력 결가 영향을 받게 되는 구조이며, 이렇게 예측된 출력값은 다시 다음 시퀀스의 예측을 위해 입력값으로 사용되고 이러한 과정이 &lt; EOS &gt; (End of Sentence) 토큰이 등장할 때 까지 반복된다.<br><br></p><h2 id="Example-Machine-Translation"><a href="#Example-Machine-Translation" class="headerlink" title="Example (Machine Translation)"></a>Example (Machine Translation)</h2><p><img src="/image/seq2seq_gif.gif" width="800"><br>seq2seq를 기계번역에 적용할 시 위와 같이 프랑스어에 해당하는 입력 시퀀스들이 순차적으로 Encoder로 입력되어 마지막 시퀀스까지 weight을 업데이트하고 그렇게 업데이트 된 마지막 입력 시퀀스 즉, Context Vector를 Decoder의 입력으로 넘겨주어 영어로 출력하게 된다.<br><br></p><h2 id="seq2seq의-한계"><a href="#seq2seq의-한계" class="headerlink" title="seq2seq의 한계"></a>seq2seq의 한계</h2><p>seq2seq는 출력 시퀀스의 가변 길이 출력이 가능해짐으로써 언어 모델의 발전을 가져왔지만 입력 시퀀스가 길어질 수 록 초기 입력 시퀀스의 정보를 잃게 되는 gradient vanishing 문제가 제기되었다. 아무래도 하나의 context vector에 입력 시퀀스의 모든 정보를 담다보니 전체 문맥 정보가 희미해질 수 밖에 없고 이는 RNN 계열의 모델(RNN, LSTM, GRU 등)에서 고질적으로 발생하는 문제이다.<br><br><br></p><h2 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h2><p>Attention mechanism은 위에서 언급한 seq2seq의 한계를 극복하기 위해 제안된 개념이다. Attention의 기본적인 아이디어는 Decoder에서 출력 토큰 예측 시 매 시점(time step)마다 입력 시퀀스의 토큰을 참조하여 <strong>연관성이 높은 토큰에 가중치를 높여 학습</strong>한다는 것이다.<br><img src="/image/attention_mechanism.png"></p><h3 id="1-Query-Key-Value"><a href="#1-Query-Key-Value" class="headerlink" title="1. Query, Key, Value"></a>1. Query, Key, Value</h3><p>Attention 계산은 Decoder 출력 토큰 예측 시 수행되며 아래와 같이 Query, Key, Value라는 개념이 사용된다.</p><blockquote><p>Q(Query) : t 시점의 decoder셀의 hidden states<br>K(Key) : 모든 시점의 encoder셀의 hidden states<br>V(Value) : 모든 시점의 encoder셀의 hidden states</p></blockquote><h3 id="2-Attention-Score"><a href="#2-Attention-Score" class="headerlink" title="2. Attention Score"></a>2. Attention Score</h3><p>Attention Score란 Decoder에서 출력 토큰 예측 시 Encoder의 모든 시퀀스 정보를 참조(attention)하여 각각의 시퀀스가 얼마나 출력 토큰과 유사한지를 판단한 유사도 값이다.<br>이 과정에서 Decoder의 현재 t시점은 Query가 되고, 참조하고자 하는 Encoder의 모든 hidden states는 Key가 된다. 이때 Query는 전치(transpose) 후 모든 key에 대해 각각 <strong>내적(dot-product)연산</strong>을 수행하여 Encoder의 Key 갯수만큼의 Attention score를 계산한다.</p><p align="center"><img src="/image/attention_score.PNG" width="350"></p><h3 id="3-Attention-Distribution"><a href="#3-Attention-Distribution" class="headerlink" title="3. Attention Distribution"></a>3. Attention Distribution</h3><p>입력 시퀀스 갯수만큼 나온 Attention Score 리스트에 <strong>Softmax 함수</strong>를 적용한다. Softmax를 적용하게 되면 합이 1이되는 확률분포가 되는데 여기서 각각의 값들을 Attention weight라고 한다.</p><p align="center"><img src="/image/attention_distribution.PNG" width="330"></p><h3 id="4-Attention-Value"><a href="#4-Attention-Value" class="headerlink" title="4. Attention Value"></a>4. Attention Value</h3><p>위에서 구한 Attention weight을 다시 각각의 Encoder의 hidden state와 곱셈연산을 하고, 이후 모든 값들을 더해주는 <strong>가중합(weighted sum)</strong>을 하여 최종 Attention Value(혹은 Context Value)를 구하여 이를 Decoder의 현재 t시점의 입력값으로 사용한다. </p><p align="center"><img src="/image/attention_value.PNG" width="150"></p><p>위의 과정을 거쳐 나온 최종 Attention value는 Decoder의 예측하려는 t 시점의 입력값으로 사용되고 매 시점 예측 시 마다 위와 같은 과정이 반복된다. </p><p>아래는 Attention 과정을 애니메이션으로 표현한 것이다.<br><img src="/image/attention-process.gif" width="800"></p><p><br></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>사실 Transformer는 Sequence-to-Sequence와 같은 Encoder-Decoder 구조를 여러개 사용한 것이고, Transformer에서 사용되는 self-attention 및 multi-head attention 또한 기존 Attention mechanism을 응용한 것이기 때문에 Sequence-to-Sequence모델과 Attention 개념만 알아도 Transformer 아키텍처를 이해하는데 어렵지 않을 것이다. 또한 이후 등장한 모델들도 대부분 이와 같은 구조를 응용한 모델이라고 할 수 있기 때문에 확실히 이해하고 넘어가는 것이 좋을 듯 하다.</p><p>Tensorflow, Pytorch 공식 doc에서 seq-to-seq with attention모델 구현 tutorial이 준비되어 있으니 참고!</p><ul><li><a href="https://www.tensorflow.org/tutorials/text/nmt_with_attention" target="_blank" rel="noopener">Neural machine translation with attention</a></li><li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" target="_blank" rel="noopener">NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION</a></li></ul><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://arxiv.org/abs/1409.3215" target="_blank" rel="noopener">Sequence to Sequence Learning with Neural Networks</a></li><li><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">Neural Machine Translation by Jointly Learning to Align and Translate</a></li><li><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank" rel="noopener">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;최근 몇 년간 Transformer 모델의 등장 이후 BERT, GPT, RoBERTa, XLNet, E
      
    
    </summary>
    
    
      <category term="nlp" scheme="https://jaehyeongan.github.io/tags/nlp/"/>
    
      <category term="transformer" scheme="https://jaehyeongan.github.io/tags/transformer/"/>
    
      <category term="attention" scheme="https://jaehyeongan.github.io/tags/attention/"/>
    
      <category term="seq2seq" scheme="https://jaehyeongan.github.io/tags/seq2seq/"/>
    
      <category term="context" scheme="https://jaehyeongan.github.io/tags/context/"/>
    
  </entry>
  
  <entry>
    <title>[Paper Review] PEGASUS:Pre-training with Extracted Gap-sentences for Abstractive Summarization</title>
    <link href="https://jaehyeongan.github.io/2020/08/01/PEGASUS/"/>
    <id>https://jaehyeongan.github.io/2020/08/01/PEGASUS/</id>
    <published>2020-08-01T11:05:03.000Z</published>
    <updated>2021-02-07T14:56:06.987Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>최근 NLP의 downstream tasks 중 하나인 Summarization분야에 “PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization”이라는 새로운 논문(멋진 이름이다..)이 등장하여 간략하게 소개해보려고 한다.</p><h2 id><a href="#" class="headerlink" title></a><p style="text-align: center;"><img src="/image/pegasus-image.jpg" width="550"></p></h2><h2 id="What-is-Text-Summarization"><a href="#What-is-Text-Summarization" class="headerlink" title="What is Text Summarization?"></a>What is Text Summarization?</h2><p>Text Summarization은 자연어 처리 분야의 여러 개의 Downstram tasks중 하나이다.<br>이름에서부터 쉽게 알 수 있듯이 Text Summarization은 문서를 요약하는 기술을 의미한다. </p><p>Text Summarization은 크게 아래와 같이 두 가지로 분류가 된다.</p><blockquote><p><strong>1. Extractive Summarization</strong><br><strong>2. Abstractive Summarization</strong></p></blockquote><p><img src="/image/extractive-abstractive.PNG" width="900"><br>위 두 방식은 요약(summarization)을 한다는 측면에서는 동일하나, 그 방법에 차이가 있다.<br>위 예시와 같이 Extractive는 원문 텍스트로부터 주요 Sentence를 원문 그대로 추출해내는 방식이라면, Abstractive는 우리가 원문 텍스트를 보고 생각과 느낌을 한 줄 요약하듯이 표현하는 방식이라고 할 수 있다. </p><p>Extractive Summarization에서 가장 많이 알려진 알고리즘은 아무래도 Text-Rank일 것이다. 초기 구글의 검색엔진랭킹 알고리즘인 Page-Rank를 Text에 적용한 알고리즘으로, 적은 연산량으로도 좋은 성능을 내고 있다. Text-Rank알고리즘은 Document 내에서 Term-Frequency가 높고, Co-occurence가 높은 단어를 keyword로 판단하며, 그러한 keyword를 많이 갖는 Sentence를 Key-Sentence일 것이라 가정하는 알고리즘이라고 할 수 있다.<br>Text-Rank의 자세한 설명은 해당 링크(<a href="https://lovit.github.io/nlp/2019/04/30/textrank/" target="_blank" rel="noopener">TextRank 를 이용한 키워드 추출과 핵심 문장 추출</a>) 참조하면 좋을 것 같다.</p><h4 id="Extractive-Summarization-vs-Abstractive-Summarization"><a href="#Extractive-Summarization-vs-Abstractive-Summarization" class="headerlink" title="Extractive Summarization vs Abstractive Summarization"></a>Extractive Summarization vs Abstractive Summarization</h4><p>둘 중에 최근 가장 활발히 연구되는 분야는 아무래도 Abstractive Summarization이다.<br>Abstractive방식이 Extractive방식보다 훨씬 어려운 난이도의 task일 뿐만 아니라 원문을 그대로 추출해내는 것이 아닌 다양한 표현방식으로 Generate하기 때문에 훨씬 더 다양한 분야에 사용될 수 있기 때문이다.<br>최근 몇 년 사이 Seqence-to-Sequence, Attention mechanism, Transformer 등과 같은 아키텍처가 등장하고 Bert와 같은 대량의 corpus로 학습된 pre-training 모델이 등장하며 이러한 generator모델의 성능도 나날이 향상되는 추세이다.<br>이제 아래에서 가장 최근 Abstractive Summarizaion 논문으로 등장한 PEGASUS에 대해 알아보자.<br><br></p><h1 id="PEGASUS-Pre-training-with-Extracted-Gap-sentences-for-Abstractive-Summarization"><a href="#PEGASUS-Pre-training-with-Extracted-Gap-sentences-for-Abstractive-Summarization" class="headerlink" title="PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"></a>PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>최근 대량의 text corpora로 self-supervised된 pre-training Transfomers 모델들이 text summarization을 포함한 fine-tuning downstream NLP task에서 좋은 성능을 보이고 있다. 하지만, Abstractive Text Summarization의 목적에 맞게 pre-training된 모델은 찾아보기 힘들고, 더욱이 다양한 domain을 커버할만 한 체계적인 평가 방법도 부족한 상황이다. </p><p>따라서, 해당 논문에서는 대량의 text copora로 self-supervised된 encoder-decoder 기반의 pre-training Transformer 모델인 PEGASUS를 소개한다. PEGASUS의 주요 특징은 GSG(Gap sentence generation)을 사용한다는 것인데, 간단히 설명하면 MLM방식에서는 token 단위로 masking하여 masked token을 예측하는 방식으로 학습했던 것과 유사하게, GSG는 token 단위가 아닌 Importance Sentence 단위로 masking을 하여 학습을 수행한다. 여기서 말하는 Importance Sentence란 document 내에서 다른 문장에 비해 전체적인 context를 잘 설명할 수 있는 문장을 말한다. </p><p>PEGASUS 모델은 12개의 downstream summarization tasks로부터 ROUGE score를 기반으로 SOTA를 달성하였고, 그 중 6개의 데이터 셋에서 오직 1,000개의 examples만으로도 SOTA를 달성할 만큼 적은 리소스 비용으로 놀라운 성능을 나타내었다. </p><h2 id="The-Basic-architecture-of-PEGASUS"><a href="#The-Basic-architecture-of-PEGASUS" class="headerlink" title="The Basic architecture of PEGASUS"></a>The Basic architecture of PEGASUS</h2><p><img src="/image/PEGASUS-architecture.PNG" width="800"><br><img src="/image/pegasus-transformer.gif" width="800"></p><p>PEGASUS는 기본적으로 encoder-decoder기반의 Transformer구조를 하고 있으며, 기존 MLM(Masked Language Model)과 유사하게 Input text의 일부를 masking하여 Encoder의 input으로 보내게 된다. 하지만 기존 MLM과 다른 점은 바로 Sentence 자체를 masking한다는 점이다.<br>기존 MLM 모델들은 token 단위로 masking하여 masked token을 예측하는 방식으로 학습을 진행하였지만, PEGASUS는 Input Document로부터 Sentence 단위로 Masking을 한 후 남은 Sentence를 기반으로 masked sentence를 예측하는 방식으로 학습된다. 논문에서는 이러한 방식을 <strong>Gap-Sentences-Generation(GSG)</strong>라고 말하고 있다.<br><br></p><h3 id="Gap-Sentences-Generation-GSG"><a href="#Gap-Sentences-Generation-GSG" class="headerlink" title="Gap Sentences Generation (GSG)"></a>Gap Sentences Generation (GSG)</h3><p>해당 section에서는 새로운 pre-training 방식인 GSG를 소개하고, 기존 BERT masked-language model과 비교를 수행한다.</p><p>해당 논문에서 강조하는 것 중 하나는, <strong>좋은 성능을 얻기 위해서는 적용하고자 하는 downstream task의 목적에 맞는 pre-training 모델을 사용하고 이를 fine-tuning 하라는 것이다.</strong> 즉, 뉴스를 요약하기 위한 데이터로 학습된 모델은 뉴스 요약에 좋은 성능을 내겠지만, 영화 시나리오를 요약하는데는 전혀 맞지 않을 수 있기 때문이다. 논문의 실험부분에서 더 소개가 되는데 News관련 데이터셋으로 학습한 모델은 Non-news task에서는 좋은 성능을 내지 못했다.</p><p>Summarization을 수행하기 위해서는 input document와 그에 맞는 summary text가 쌍으로 활용되어야 한다. 하지만 단순히 extractive 방식으로 summary를 추출하게 되면 모델은 단순히 sentence를 copy하는 방식으로 학습이 되기 때문에, 저자는 최근 masking words와 contiguous spans의 성공에 영감을 받아 GSG를 수행한다고 설명한다. </p><p>GSG는 전체적으로 아래와 같은 방식으로 수행된다.</p><blockquote><ol><li>Select and mask whole sentences form documents.</li><li>Concatenate the gap-sentences into a pseudo-summary.</li><li>The corresponding position of each selected gap sentence is replaced by a mask token [MASK1] to inform the model</li></ol></blockquote><p>여기서 gap sentence 비율은 GSR(Gap Sentences Ratio)에 의해 결정되는데 이는 문서의 전체 sentence에서 선택된 gap sentence의 비율을 의미하고, 다른 Masked Language Model에서의 mask rate와 유사한 개념이라고 생각하면 된다. 해당 논문에서는 GSR의 비율에 따른 성능을 실험하였는데 데이터셋에 따라 성능 편차가 있었지만, <strong>최종적으로 GSR을 30%로 선택하였다고 한다.</strong></p><p><br></p><h4 id="Three-primary-strategies-for-gap-sentence"><a href="#Three-primary-strategies-for-gap-sentence" class="headerlink" title="Three primary strategies for gap-sentence"></a>Three primary strategies for gap-sentence</h4><p>그렇다면 어떤 문장이 gap sentence로 선택이 되는걸까?<br>해당 논문은 적절한 Summarization을 위해서 gap sentence는 document내에서 다른 문장들(remaining sentence)에 비해 전체 문맥을 설명할 수 있는 중요한(important/principal) 문장이 선택되어야 한다고 한다. 이를 위해 Random, Lead, Principal이라는 3가지 전략을 사용한다. </p><p><img src="/image/gap-sentence-select.PNG" width="500"><br>Random은 말그대로 랜덤하게 m개의 sentence를 추출하는 것이고, Lead는 문서의 가장 첫 m개의 문장, Principal은 selected sentence와 remaining sentence간의 ROUGE1-F1 score를 기반으로 top-m개의 sentence를 선정하는 것을 말한다. (Principal 방법의 경우는 Ind/seq그리고 Orig/Uniq 옵션으로 세분화 되어 실험된다.)</p><p>아래는 document내에서 Random, Lead, Principal(Ing-Orig) 각각의 전략에 의해 선택된 sentence들을 보여준다.<br><img src="/image/gap-sentence-select-example.PNG" width="500"></p><h3 id="Masked-Language-Model-MLM"><a href="#Masked-Language-Model-MLM" class="headerlink" title="Masked Language Model(MLM)"></a>Masked Language Model(MLM)</h3><p>BERT에서는 input text의 15%의 token을 선택하여, 그 중 80%는 mask token으로 변환하고, 10%는 random token, 나머지 10%는 그대로 사용하게 된다.<br>위 첫번째 그림인 PEGASUS 모델의 아키텍처를 보면 GSG와 MLM이 동시에 적용되고 있는 것을 볼 수 있지만, 실제로는 MLM이 downstream task의 성능 향상에 영향을 주지 않아 최종 모델에서는 MLM을 포함하지 않았다고 한다. </p><p><br></p><h3 id="Pre-training-Corpus"><a href="#Pre-training-Corpus" class="headerlink" title="Pre-training Corpus"></a>Pre-training Corpus</h3><p>pre-training을 위해 사용된 corpus는 C4와 HugeNews이다.</p><ul><li>C4(Colossal and Cleaned version of Common Crawl) : consist of text from 350M web-pages(750GB)</li><li>HugeNews : a dataset of 1.5B articles (3.8TB) collected from news and news-like websites from 2013-2019</li></ul><h4 id="Downstream-Tasks-Datasets"><a href="#Downstream-Tasks-Datasets" class="headerlink" title="Downstream Tasks/Datasets"></a>Downstream Tasks/Datasets</h4><p>downstream summarization 및 재현 가능한 코드 제공을 위해 public datasets인 <em><a href="https://www.tensorflow.org/datasets/catalog/overview" target="_blank" rel="noopener">Tensorflow Summarization Datasets</a></em> 데이터 셋을 활용하였다. 사용된 데이터 셋은 총 12개로 아래와 같다.<br>-Xsum<br>-CNN/DailyMail<br>-NEWSROOM<br>-Multi-News<br>-Gigaword<br>-arXiv<br>-PubMed<br>-BIGPATENT<br>-WikiHow<br>-Reddit TIFU<br>-AESLC<br>-BillSum</p><p><br></p><h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>효율적인 실험을 위하여 모델의 사이즈를 줄인 PEAGASUS-base모델(223M parameters)과 PEGASUS-large모델(568M parmeters)을 각각 비교한다.</p><blockquote><p><strong>PEAGASUS-base</strong></p><ul><li>number of layers of encoder and decoder(L) : 12</li><li>hidden size(H) : 768</li><li>feed-forward layer size(F) : 3,072</li><li>number of self-attention heads(A) : 12</li></ul><p><strong>PEGASUS-large</strong></p><ul><li>number of layers of encoder and decoder(L) : 16</li><li>hidden size(H) : 1024</li><li>feed-forward layer size(F) : 4,096</li><li>number of self-attention heads(A) : 16</li></ul></blockquote><p><br></p><h4 id="Pre-Training-Corpus"><a href="#Pre-Training-Corpus" class="headerlink" title="Pre-Training Corpus"></a>Pre-Training Corpus</h4><p><img src="/image/effect-of-pre-training-corpus.PNG" width="600"><br>위 그림에서 볼 수 있듯이 학습시 사용된 Corpus가 무엇이냐에 따라 downstream task의 성능에 영향을 주게 된다.<br>HugeNews를 토대로 학습된 모델은 news 데이터 셋(XSum, CNN/DailyMail)에서는 높은 성능을 보여주고 있는 반면, non-news 데이터셋(WikiHow, Reddit TIFU)에서는 낮은 성능을 보여주고 있다.</p><p><br></p><p><strong>EFFECT OF PRE-TRAINING OBJECTIVES</strong><br>GSG의 성능비교를 위해 Lead, Random, Ing-Oig, Ing-Uniq, Seq-Orig, Seq-Uniq를 비교하였으며, GSR의 경우 데이터셋마다 성능 차이를 보이지만, <strong>최종적으로 30%를 선택하였다.</strong><br><img src="/image/effect-of-gap-sentence.PNG" width="1000"></p><p><strong>EFFECT OF VOCABULARY</strong><br>실험을 위해 BPE(Byte-pair encoding)와 SentencePiece Unigram을 비교하였다.<br>비교결과 news 데이터셋에서는 BPE와 Unigram의 성능이 유사하였지만, non-news 데이터셋(especially WikiHow)에서는 SentencePiece Unigram모델이 훨씬 좋은 성능을 나타냈다. </p><p>위 그래프에서 볼 수 있듯이, WikiHow의 경우 Unigram이 128k일 때, Reddit TIFU는 64k일 때 best score를 나타내었기 때문에 이를 고려하여 <strong>최종적으로 SentencePiece Unigram을 사용하고 vocabulary size는 96k로 선정하였다.</strong></p><p><br></p><h4 id="Larger-Model"><a href="#Larger-Model" class="headerlink" title="Larger Model"></a>Larger Model</h4><p><img src="/image/PEGASUS-result1.PNG" width="1000"><br>위 table에서 볼 수 있듯이, PEGASUS모델은 이전 SOTA모델 대비 모든 12개의 downstream tasks에서 모두 SOTA를 달성한 것을 확인할 수 있다.</p><p><br></p><h4 id="Zero-and-Low-Resource-Summarization"><a href="#Zero-and-Low-Resource-Summarization" class="headerlink" title="Zero and Low-Resource Summarization"></a>Zero and Low-Resource Summarization</h4><p><img src="/image/PEGASUS-result2.PNG" width="1000"><br>PAGASUS-large 모델을 2000 steps, 256 batch-size, 0.0005 learning-rate로 fine-tuning하였을 때, 단지 100개의 examples만으로도 기존 20k~200k개로 학습된 Transformer-base모델과 유사한 성능을 달성하였고, 1000개의 examples를 사용하였을때 12개 데이터 셋중 6개의 데이터 셋에서 SOTA를 달성할 만큼 <strong>기존 모델 대비 적은 비용으로 높은 성능을 달성하였다는 것이 큰 특징이다.</strong></p><p><img src="/image/PEGASUS-result3.PNG" width="600"><br>또한, 실제 사람이 만든 요약본과 PEGASUS-large모델이 만든 요약본은 비교한 결과를 보면, Reddit TIFU 데이터셋을 제외한 XSum, CNN/DailyMail 데이터셋에서는 PEGASUS-large모델이 만든 요약본이 사람이 만든 요약본보다 더 높은 성능을 나타냈다는 것이 특징이다.</p><p><br></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>정리해보자면 해당 논문의 큰 특징이라고 할 수 있는 점은,</p><blockquote><p>첫째, Abstractive summmarization이라는 특정 task를 위해 GSG(Gap-Sentence Generation)라는 새로운 pre-training기법을 통해 적용한 점<br>둘째, GSG에서 principal sentence selection을 위해 다양한 방법을 적용한 점<br>셋째, 적은 리소스 비용(ex, 1000 examples)만으로도 대부분의 결과에서 SOTA를 달성한 점</p></blockquote><p>인 것 같다. 그런데 여기서 의문이 들었던 점은 사람의 요약본과 성능 비교를 하는데 있어서 PEGASUS-large모델이 대부분 더 좋은 성능을 보였는데, 과연 human evaluation이 객관적으로 이루어졌는지 의문이 들었다. 각 task마다 3명의 평가자에 의해 1-5점으로 평가를 하였다고 하는데 과연 일반화 할 수 있을까?</p><p>여하튼, 최근 text summarization분야를 관심있게 보고 있었는데, summarization task에 최적화된 모델이 나왔다는 점에서 흥미가 갔던 논문이었다.</p><hr><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://arxiv.org/pdf/1912.08777.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1912.08777.pdf</a></li><li><a href="https://www.youtube.com/watch?v=JhGmeQBbDdA" target="_blank" rel="noopener">https://www.youtube.com/watch?v=JhGmeQBbDdA</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;최근 NLP의 downstream tasks 중 하나인 Summarization분야에 “PEGASUS: 
      
    
    </summary>
    
    
      <category term="nlp" scheme="https://jaehyeongan.github.io/tags/nlp/"/>
    
      <category term="summarization" scheme="https://jaehyeongan.github.io/tags/summarization/"/>
    
      <category term="transformer" scheme="https://jaehyeongan.github.io/tags/transformer/"/>
    
      <category term="gap-sentence-generator" scheme="https://jaehyeongan.github.io/tags/gap-sentence-generator/"/>
    
      <category term="mlm" scheme="https://jaehyeongan.github.io/tags/mlm/"/>
    
  </entry>
  
  <entry>
    <title>Basic Object-Detection</title>
    <link href="https://jaehyeongan.github.io/2020/04/15/Basic-Object-Detection/"/>
    <id>https://jaehyeongan.github.io/2020/04/15/Basic-Object-Detection/</id>
    <published>2020-04-15T09:34:17.000Z</published>
    <updated>2020-10-28T15:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p><em>Inflearn의 <a href="https://www.inflearn.com/course/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%BB%B4%ED%93%A8%ED%84%B0%EB%B9%84%EC%A0%84-%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C/dashboard" target="_blank" rel="noopener">딥러닝 컴퓨터 비전 완벽 가이드</a>를 수강하며 공부 목적으로 정리한 글입니다.</em></p><hr><h2 id="Computer-Vision-Techniques"><a href="#Computer-Vision-Techniques" class="headerlink" title="Computer Vision Techniques"></a>Computer Vision Techniques</h2><p><img src="/image/computer-vision-problem.png" width="900px"></p><ul><li>Classification(분류) : 이미지에 있는 object가 무엇인지만 판별, 위치 고려 x</li><li>Localization(발견) : object 판별 및 단 하나의 object 위치를 bounding box로 지정하여 찾음</li><li>Detection(발견) : object 판별 및 여러 개의 object들에 대한 위치를 bounding box로 지정하여 찾음</li><li>Segmentation(분할) : object 판별 및 Pixel 레벨의 detection을 통해 모든 픽셀의 레이블을 예측<br><br></li></ul><h2 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h2><h3 id="History"><a href="#History" class="headerlink" title="History"></a>History</h3><p><img src="/image/object-detection-history.png" width="900px"></p><ul><li>현재 <strong>YOLO 모델</strong>이 real-time 예측 측면에서 성능이 나쁘지 않아 실무에서 가장 많이 활용되고 있음</li><li>real-time에는 한계가 있으나 가장 성능이 좋은 모델은 <strong>RetinaNet</strong></li></ul><p><br></p><h3 id="Sliding-Window-방식을-활용한-초기-object-detection"><a href="#Sliding-Window-방식을-활용한-초기-object-detection" class="headerlink" title="Sliding Window 방식을 활용한 초기 object detection"></a>Sliding Window 방식을 활용한 초기 object detection</h3><p><img style="padding-left: 50px" src="/image/sliding_window_example.gif" width="150px"></p><ul><li>object detection의 초기 기법</li><li>window를 왼쪽 상단에서부터 오른쪽 하단으로 이동시키면서 object를 detection하는 방식</li><li>오브젝트가 없는 역역도 무조건 슬라이딩하며 여러 형태의 window와 scale을 스캔해야 하므로 수행시간 및 성능이 효율적이지 않음</li><li>Region Proposal 기법의 등장 이후 활용도가 떨어졌지만 object detection의 기술적 토대 제공<br><br></li></ul><h3 id="Obejct-Detection의-주요-구성-요소-및-문제"><a href="#Obejct-Detection의-주요-구성-요소-및-문제" class="headerlink" title="Obejct Detection의 주요 구성 요소 및 문제"></a>Obejct Detection의 주요 구성 요소 및 문제</h3><p><strong>주요 구성요소</strong></p><blockquote><ol><li>Region Proposal</li><li>Detection을 위한 Network 구성(feature extraction, network prediction)</li><li>detection을 위한 요소들(IoU, NMS, mAP, Anchor Box 등)</li></ol></blockquote><p><strong>주요 문제</strong></p><blockquote><ol><li>물체 판별(Classification) + 물체 위치 찾기(Regression)을 동시에 수행해야 함</li><li>한 이미지 내에 크기, 색, 생김새가 다양한 object가 섞여 있음</li><li>실시간 detection을 위해 시간 성능이 중요 </li><li>명확하지 않은 이미지가 많음(노이즈 혹은 배경이 전부인 사진 등)</li><li>이미지 데이터 셋의 부족</li></ol></blockquote><p><br></p><h2 id="Region-Proposal-영역-추정"><a href="#Region-Proposal-영역-추정" class="headerlink" title="Region Proposal(영역 추정)"></a>Region Proposal(영역 추정)</h2><ul><li>목표 : Object가 있을 만한 후보 영역을 찾자! </li><li>대표적인 기법이 Selective Search</li></ul><h3 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h3><ul><li>Region Proposal의 대표적인 기법</li><li>컬러(color), 무늬(texture), 크기(size), 형태(shape) 등에 따라 유사한 region들을 계층적으로 그룹핑 하는 방법<br><img src="/image/selective-search.png" width="600px"><br><br></li></ul><p><strong>Selective Search 수행 프로세스</strong></p><blockquote><ol><li>초기 수 천개의 개별 Over segmentation된 모든 부분들을 bounding box로 만들어 region proposal 리스트에 추가 </li><li>컬러(color), 무늬(texture), 크기(size), 형태(shape) 등에 따라 유사한 segment들을 그룹핑 </li><li>위 과정을 반복하며 최종 그룹핑 된 segment들을 제안</li></ol></blockquote><p><br></p><h4 id="Python을-통한-Selective-Search-구현"><a href="#Python을-통한-Selective-Search-구현" class="headerlink" title="Python을 통한 Selective Search 구현"></a>Python을 통한 Selective Search 구현</h4><ul><li><code>pip install selectivesearch</code> 를 통해 라이브러리 설치 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> selectivesearch</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">'./image/test.jpg'</span>) <span class="comment"># 이미지 로드 </span></span><br><span class="line">img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">plt.imshow(img_rgb)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/audrey_original.png" width="250px"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#selectivesearch.selective_search()는 이미지의 Region Proposal정보를 반환 </span></span><br><span class="line">_, regions = selectivesearch.selective_search(img_rgb, </span><br><span class="line">                                              scale=<span class="number">100</span>, <span class="comment"># bounding box scale </span></span><br><span class="line">                                              min_size=<span class="number">2000</span>) <span class="comment"># rect의 최소 사이즈</span></span><br><span class="line"></span><br><span class="line">regions[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[&#123;&apos;rect&apos;: (0, 0, 58, 257), &apos;size&apos;: 7918, &apos;labels&apos;: [0.0]&#125;,</span><br><span class="line"> &#123;&apos;rect&apos;: (16, 0, 270, 50), &apos;size&apos;: 5110, &apos;labels&apos;: [1.0]&#125;,</span><br><span class="line"> &#123;&apos;rect&apos;: (284, 0, 90, 420), &apos;size&apos;: 6986, &apos;labels&apos;: [2.0]&#125;,</span><br><span class="line"> &#123;&apos;rect&apos;: (59, 14, 262, 407), &apos;size&apos;: 3986, &apos;labels&apos;: [3.0]&#125;,</span><br><span class="line"> &#123;&apos;rect&apos;: (62, 17, 256, 401), &apos;size&apos;: 5282, &apos;labels&apos;: [4.0]&#125;]</span><br></pre></td></tr></table></figure><p>반환된 regions 변수는 리스트 타입으로 세부 원소로 딕셔너리를 가지고 있음. </p><ul><li>rect 키값은 x,y 시작 좌표와 너비, 높이 값을 가지며 이 값이 Detected Object 후보를 나타내는 Bounding box임. </li><li>size는 Bounding box의 크기</li><li>labels는 해당 rect로 지정된 Bounding Box내에 있는 오브젝트들의 고유 ID</li><li>아래로 내려갈 수록 특성이 비슷한 것들이 합쳐지고, 너비와 높이 값이 큰 Bounding box이며 하나의 Bounding box에 여러개의 오브젝트가 있을 확률이 커짐. </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bounding Box 시각화 </span></span><br><span class="line">green_rgb = (<span class="number">125</span>, <span class="number">255</span>, <span class="number">51</span>)</span><br><span class="line">img_rgb_copy = img_rgb.copy()</span><br><span class="line"><span class="keyword">for</span> rect <span class="keyword">in</span> cand_rects:</span><br><span class="line">    </span><br><span class="line">    left = rect[<span class="number">0</span>]</span><br><span class="line">    top = rect[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># rect[2], rect[3]은 너비와 높이이므로 우하단 좌표를 구하기 위해 좌상단 좌표에 각각을 더함. </span></span><br><span class="line">    right = left + rect[<span class="number">2</span>]</span><br><span class="line">    bottom = top + rect[<span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line">    img_rgb_copy = cv2.rectangle(img_rgb_copy, (left, top), (right, bottom), color=green_rgb, thickness=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">plt.imshow(img_rgb_copy)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/audrey-bounding.png" width="250px"><br><br></p><h3 id="IoU-Intersection-over-Union"><a href="#IoU-Intersection-over-Union" class="headerlink" title="IoU(Intersection over Union)"></a>IoU(Intersection over Union)</h3><p>모델이 예측한 bounding box와 실제 ground truth box가 얼마나 정확하게 겹치는지를 측정하는 지표</p><ul><li>아래와 같은 지표로 계산 되며<br><img src="/image/IoU.jpg" width="500px"></li><li>100%로 정확하게 겹쳐질 때의 값은 1이 됨<br><img src="/image/iou-score.png" width="450px"></li></ul><blockquote><p>IoU 값에 따라 detection 예측 성공 결정</p><ul><li>object detection에서 개별 object에 대한 검출 예측이 성공하였는지에 대한 여부를 IoU를 통해 결정</li><li>일반적으로 PASCAL VOC Challenge에서 는 IoU가 0.5이상이면 예측 성공했다고 판단</li></ul></blockquote><p><br></p><h4 id="Python을-통한-IoU-계산"><a href="#Python을-통한-IoU-계산" class="headerlink" title="Python을 통한 IoU 계산"></a>Python을 통한 IoU 계산</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_iou</span><span class="params">(cand_box, gt_box)</span>:</span></span><br><span class="line">    <span class="comment"># Calculate intersection areas</span></span><br><span class="line">    x1 = np.maximum(cand_box[<span class="number">0</span>], gt_box[<span class="number">0</span>])</span><br><span class="line">    y1 = np.maximum(cand_box[<span class="number">1</span>], gt_box[<span class="number">1</span>])</span><br><span class="line">    x2 = np.minimum(cand_box[<span class="number">2</span>], gt_box[<span class="number">2</span>])</span><br><span class="line">    y2 = np.minimum(cand_box[<span class="number">3</span>], gt_box[<span class="number">3</span>])</span><br><span class="line">    </span><br><span class="line">    intersection = np.maximum(x2 - x1, <span class="number">0</span>) * np.maximum(y2 - y1, <span class="number">0</span>) <span class="comment"># width * height (x2에서 x1을 뺀 값이 width, y2에서 y1을 뺀 값이 height 이므로)</span></span><br><span class="line">    </span><br><span class="line">    cand_box_area = (cand_box[<span class="number">2</span>] - cand_box[<span class="number">0</span>]) * (cand_box[<span class="number">3</span>] - cand_box[<span class="number">1</span>]) <span class="comment"># width * height</span></span><br><span class="line">    gt_box_area = (gt_box[<span class="number">2</span>] - gt_box[<span class="number">0</span>]) * (gt_box[<span class="number">3</span>] - gt_box[<span class="number">1</span>]) <span class="comment"># width * height</span></span><br><span class="line">    union = cand_box_area + gt_box_area - intersection <span class="comment"># 실제box와 예측box의 합에서 intersection을 뺌</span></span><br><span class="line">    </span><br><span class="line">    iou = intersection / union</span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure><ul><li>실제 bounding box와 후보 bounding box가 있을 때, 둘 중에서  x1과 y1좌표는 max값, x2와 y2좌표는 min값을 선택하게 되면 그 좌표가 Intersection area가 되며</li><li>두 개의 box를 더한 후 intersection을 빼준 값이 Union area </li><li>마지막으로 intersection을 union으로 나누어 주면 IoU값을 얻을 수 있음<br><br></li></ul><h3 id="NMS-Non-Max-Suppression"><a href="#NMS-Non-Max-Suppression" class="headerlink" title="NMS(Non Max Suppression)"></a>NMS(Non Max Suppression)</h3><p>object detection 시 최대한 object를 놓치지 않기 위해 많은 bounding box를 찾게 되는데, 이렇게 detected 된 수많은 bounding box 중 비슷한 위치에 있는 box를 제거하고 가장 적합한 box를 선택하는 기법<br><img src="/image/nms.png" width="700px"><br><br></p><p><strong>NMS 수행 프로세스</strong></p><blockquote><ol><li>Detected 된 Bounding box별로 특정 Confidence score threshold 이하 bounding box는 먼저 제거 (ex. confidence score threshold &lt; 0.5)</li><li>가장 높은 confidence score를 가진 box 순으로 내림차순 정렬하고 아래 로직을 모든 box에 순차적으로 적용<ul><li>높은 confidence score를 가진 box와 겹치는 다른 box를 모두 조사하여 IoU가 특정 threshold 이상인 box를 모두 제거 (ex. IoU Threshold &gt; 0.4)</li></ul></li><li>남아있는 box만 선택 </li></ol></blockquote><p><strong><em>Confidence score threshold가 높을 수록, IoU Threshold가 낮을 수록 많은 box가 제거 됨</em></strong><br><br></p><h2 id="Object-Detection-성능-평가"><a href="#Object-Detection-성능-평가" class="headerlink" title="Object Detection 성능 평가"></a>Object Detection 성능 평가</h2><h3 id="mAP-mean-Average-Precision"><a href="#mAP-mean-Average-Precision" class="headerlink" title="mAP(mean Average Precision)"></a>mAP(mean Average Precision)</h3><ul><li><p>실제 Object가 detected된 재현율(recall)의 변화에 따른 정밀도(precision)의 값을 평균한 성능 수치</p><blockquote><p><strong>정밀도와 재현율</strong></p><ul><li>정밀도는 모델이 positive라고 예측한 대상 중 예측 값이 실제 positive 값과 얼마나 일치하는지에 대한 비율(즉, 예측한 object가 실제 object들과 얼마나 일치하는지)</li><li>재현율은 실제 positive 값 중 모델이 얼마나 실제 값을 positive라고 예측했는지에 대한 비율(즉, 실제 object를 얼마나 빠드리지 않고 잘 예측했는지)</li><li>Precision Recall Trade-off : 정밀도와 재현율은 상호 보완적인 관계이므로 어느 한쪽이 높아지면 다른 쪽이 낮아지게 됨</li><li>Precision-Recall Curve : confidence threshold의 변화에 따른 정밀도와 재현율의 변화 곡선, 이 곡선의 아랫부분 면적을 AP(Averge Precision, 평균 정밀도)라고 함<br><img src="/image/average-precision.png" width="300px"></li></ul></blockquote></li><li><p>AP는 하나의 object에 대한 성능 수치이며, mAP는 여러 object들의 AP를 평균한 값을 의미<br><img src="/image/map.png" width="500px"><br><br></p></li></ul><h3 id="Image-Resolution-FPS-Detection-성능-상관-관계"><a href="#Image-Resolution-FPS-Detection-성능-상관-관계" class="headerlink" title="Image Resolution / FPS / Detection 성능 상관 관계"></a>Image Resolution / FPS / Detection 성능 상관 관계</h3><p><img src="/image/resolution-detection-score.png" width="400px"><br>일반적으로 이미지 해상도(Image Resolution)가 높을 수록 Detection성능이 좋아지지만 이미지를 처리하는 시간(FPS)이 오래걸림</p><ul><li>High Resolution -&gt; High Detection Score -&gt; Low FPS</li><li>Low Resolution -&gt; Low Detection Score -&gt; High FPS<br><br></li></ul><h2 id="Object-Detection을-위한-주요-데이터-셋"><a href="#Object-Detection을-위한-주요-데이터-셋" class="headerlink" title="Object Detection을 위한 주요 데이터 셋"></a>Object Detection을 위한 주요 데이터 셋</h2><ul><li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/" target="_blank" rel="noopener">Pascal-VOC</a> - XML format, 20개의 오브젝트 카테고리 </li><li><a href="http://cocodataset.org/#home" target="_blank" rel="noopener">MS-COCO</a> - json format, 80개의 오브젝트 카테고리</li><li><a href="https://opensource.google/projects/open-images-dataset" target="_blank" rel="noopener">Google Open Images</a> - csv format, 600개의 오브젝트 카테고리</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;&lt;em&gt;Inflearn의 &lt;a href=&quot;https://www.inflearn.com/course/%EB
      
    
    </summary>
    
    
      <category term="objectdetection" scheme="https://jaehyeongan.github.io/tags/objectdetection/"/>
    
      <category term="region-proposal" scheme="https://jaehyeongan.github.io/tags/region-proposal/"/>
    
      <category term="selectivesearch" scheme="https://jaehyeongan.github.io/tags/selectivesearch/"/>
    
      <category term="IoU" scheme="https://jaehyeongan.github.io/tags/IoU/"/>
    
      <category term="NMS" scheme="https://jaehyeongan.github.io/tags/NMS/"/>
    
      <category term="mAP" scheme="https://jaehyeongan.github.io/tags/mAP/"/>
    
  </entry>
  
  <entry>
    <title>LSTM Autoencoder for Anomaly Detection</title>
    <link href="https://jaehyeongan.github.io/2020/02/29/LSTM-Autoencoder-for-Anomaly-Detection/"/>
    <id>https://jaehyeongan.github.io/2020/02/29/LSTM-Autoencoder-for-Anomaly-Detection/</id>
    <published>2020-02-29T09:19:16.000Z</published>
    <updated>2020-10-28T15:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>지난 포스팅(<a href="https://jaehyeongan.github.io/2020/02/28/Autoencoder-LSTMautoencoder/">Autoencoder와 LSTM Autoencoder</a>)에 이어 <strong>LSTM Autoencoder를 통해 Anomaly Detection하는 방안</strong>에 대해 소개하고자 한다. Autoencoder의 경우 보통 이미지의 생성이나 복원에 많이 사용되며 이러한 구조를 이어받아 대표적인 딥러닝 생성 모델인 GAN(Generative Adversarial Network)으로 까지 이어졌는데 이러한 자기 학습 모델은 Anomaly Detection 분야에서도 널리 사용되고 있다.<br>대표적으로 이미지 분야에서도 정상적인 이미지로 모델 학습 후 비정상적인 이미지를 넣어 이를 디코딩 하게 되면 정상 이미지 특성과 디코딩 된 이미지 간의 차이인 재구성 손실(Reconstruction Error)를 계산하게 되는데 이 재구성 손실이 낮은 부분은 정상(normal), 재구성 손실이 높은 부분은 이상(Abnormal)로 판단할 수 있다. </p><p>이러한 Anomaly Detection은 이미지 뿐만 아니라 이제부터 살펴보고자 하는 시계열 데이터에도 적용이 가능하다. 예를 들어 특정 설비의 센서를 통해 비정상 신호를 탐지하고자 한다면 Autoencoder를 LSTM 레이어로 구성한다면 이러한 시퀀스 학습이 가능하게 된다. 이를 통해 정상 신호만을 이용하여 모델을 학습시켜 추후 비정상 신호가 모델에 입력되면 높은 reconstruction error를 나타낼 것이므로 이를 비정상 신호로 판단할 수 있게 된다.</p><hr><h2 id="LSTM-Autoencoder"><a href="#LSTM-Autoencoder" class="headerlink" title="LSTM Autoencoder"></a>LSTM Autoencoder</h2><p><img src="/image/lstm-autoencoder-architecture2.png"></p><p>LSTM Autoencoder는 시퀀스(sequence) 데이터에 Encoder-Decoder LSTM 아키텍처를 적용하여 구현한 오토인코더이다. 모델에 입력 시퀀스가 순차적으로 들어오게 되고, 마지막 입력 시퀀스가 들어온 후 디코더는 입력 시퀀스를 재생성하거나 혹은 목표 시퀀스에 대한 예측을 출력한다.<br>위에서 설명한 것과 마찬가지로 <strong>LSTM Autoencoder 학습 시에는 정상(normal) 신호의 데이터로만 모델을 학습시키게 된다.</strong> encoder와 decoder는 학습이 진행될 수 록 정상 신호를 더 정상 신호 답게 표현하는 방법을 학습하게 될 것이며 최종적으로 재구성 한 결과도 정상 신호와 매우 유사한 분포를 가지는 데이터일 것이다. 그렇기 때문에 이 모델에 비정상 신호를 입력으로 넣게 되면 정상 분포와 다른 특성의 분포를 나타낼 것이기 때문에 높은 reconstruction error를 보이게 될 것이다.<br><br></p><h2 id="Curve-Shifting을-적용한-LSTM-Autoencoder"><a href="#Curve-Shifting을-적용한-LSTM-Autoencoder" class="headerlink" title="Curve Shifting을 적용한 LSTM Autoencoder"></a>Curve Shifting을 적용한 LSTM Autoencoder</h2><p><img src="/image/lstm-autoencoder-through-curveshifting.png" width="800px"></p><p>전체 프로세스는 위 아키텍처와 같다. 먼저 Curve Shifting을 통해 데이터의 시점을 변환해주고 normal 데이터만을 통해 LSTM Autoencoder 모델을 학습시키게 된다. 그 후 재구성 손실을 계산 후 Precision Recall Curve를 통해 normal/abnormal을 구분하기 위한 threshold를 지정하게 되고 이 threshold를 기준으로 마지막으로 테스트 셋의 재구성 손실을 분류하여 t+n 시점을 예측하게 된다.<br>각 부분에 대해 아래에서 좀 더 상세히 살펴보자.</p><h3 id="1-Curve-Shifting"><a href="#1-Curve-Shifting" class="headerlink" title="1. Curve Shifting"></a>1. Curve Shifting</h3><p>비정상 신호를 탐지하기 위해서는 비정상 신호가 들어오기 전에 즉, 뭔가 고장 혹은 결함이 발생하기 전에 미리 예측을 해야만 한다. 그렇기 때문에 단순히 현재 시점의 error를 계산하여 비정상 신호를 탐지하는 것은 이미 고장이 발생한 후 예측하는 것과 다름이 없기 때문에 <strong>데이터에 대한 시점 변환</strong>이 꼭 필요하다. </p><p>이러한 future value 예측을 위해 다양한 방법이 있는데 여기서는 <strong>Curve Shifting</strong>이라는 기법을 적용할 것이다. </p><p><img src="/image/curve-shifting.png" width="400px"></p><p>Curve Shifting은 <strong>사전 예측 개념</strong>을 적용하기 위한 Shifting 방법이다. 예를 들어 위 그림과 같이 비정상 신호(1)를 2일 전에 조기 예측 하고자 한다면 단순히 Y값을 두 칸씩 내리는 것이 아니라 비정상 신호(1)가 있는 날짜로부터 2일 전까지의 데이터를 비정상 신호(1)로 바꾸어주는 것이다. 이는 비정상 신호가 발생하기 전 어떠한 조짐이 있을 것이며 이러한 조짐이 데이터 특성에 나타날 것이라는 가정을 가지고 학습하는 방법이다.<br>그리고 나서 본래 비정상 신호(1) 데이터를 제거해주는데 이렇게 하는 이유는 라벨을 바꿔주는 순간 이는 비정상 신호 예측 문제가 아닌 비정상 신호 조짐 예측 문제가 되는 것이 때문에 데이터의 학습 혼동을 없애주기 위해 제거하는 것이라 보면 될 것이다.<br><br></p><h3 id="2-Threshold-by-Precision-Recall-Curve"><a href="#2-Threshold-by-Precision-Recall-Curve" class="headerlink" title="2. Threshold by Precision-Recall-Curve"></a>2. Threshold by Precision-Recall-Curve</h3><p>Autoencoder는 재구성 된 결과를 intput과 비교하여 재구성 손실(Reconstruction Error)를 계산한다고 말했다. 그리고 이 재구성 손실값을 통해 손실값이 낮으면 정상으로, 손실값이 높으면 이상으로 판단한다고 하였는데, 이 정상과 이상을 나누는 기준은 과연 무엇일까?<br>일반적으로 모델이 정상 데이터만으로 학습을 하여 정상 데이터를 재구성하였을 때 학습이 잘 되었다고 가정하면 손실값은 0에 가까울 것이고, 학습이 잘 안되었다고 하면 손실값은 1에 가까울 것이다. 보통 분류(Classification)문제에서는 예측 확률값(0% ~ 100%)을 통해 50%를 기준으로 분류를 하게 되는데, 이 recontruction error의 경우 그렇게 극단적으로 값이 튀기는 힘들기 때문에 정상과 이상을 분리하는 타당한 threshold값을 정하는 것이 필요하다. </p><h4 id="Precision-Recall-Curve"><a href="#Precision-Recall-Curve" class="headerlink" title="Precision Recall Curve"></a>Precision Recall Curve</h4><p><img src="/image/precision-recall-curve.png" width="600px"></p><p>위와 같은 문제의 적절한 threshold값을 적용하기 위한 방법 중 하나로 precision recall curve가 있다. 이는 Recall(재현율)과 Precision(정밀도)가 서로 Trade off 관계를 가지기 때문에 어느 한쪽에 치우지지 않는 최적의 threshold를 구하기 위한 방법이다.<br>추후 이 검증 기법을 적용하여 LSTM Autoencoder를 통해 재구성 된 정상 신호와 비정상 신호를 구분하기 위한 적절한 threshold를 찾아낼 것이다.<br><br></p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>적용해 볼 데이터는 펄프 제지 공장의 Sheet breaks(종이 씹힘)에 관한 이진 라벨 데이터이다. 데이터 설명에 따르면 해당 공장에서 한번 sheet break가 발생하면 수천 달러의 손해가 발생한다고 하며, 이러한 사고가 적어도 매일 한 번 이상 발생한다고 한다.<br>해당 데이터는 15일치에 해당하는 18,268 rows를 가지고 있으며 이 중 sheet break에 해당하는 positive label의 비율은 124개로 전체 데이터의 0.6%를 차지하고 있다.<br>데이터는 <a href="https://docs.google.com/forms/d/e/1FAIpQLSdyUk3lfDl7I5KYK_pw285LCApc-_RcoC0Tf9cnDnZ_TWzPAw/viewform" target="_blank" rel="noopener">여기</a>에서 신청 후 받을 수 있다.</p><h3 id="1-Import-Libraries"><a href="#1-Import-Libraries" class="headerlink" title="1. Import Libraries"></a>1. Import Libraries</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> rcParams</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model ,models, layers, optimizers, regularizers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br></pre></td></tr></table></figure><h3 id="2-Load-Data"><a href="#2-Load-Data" class="headerlink" title="2. Load Data"></a>2. Load Data</h3><p>time과 라벨 y값을 빼면 총 61개의 칼럼을 가지고 있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LABELS = [<span class="string">'Normal'</span>, <span class="string">'Break'</span>]</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'./data/processminer-rare-event-mts-csv.csv'</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure></p><p><img src="/image/lstm-autoencoder-code1.PNG"></p><p>normal(0)이 18,274건, break(1)가 124건으로 구성 되어있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Counter(df[<span class="string">'y'</span>])  <span class="comment"># Counter(&#123;0: 18274, 1: 124&#125;)</span></span><br></pre></td></tr></table></figure></p><h3 id="3-Curve-Shifting"><a href="#3-Curve-Shifting" class="headerlink" title="3. Curve Shifting"></a>3. Curve Shifting</h3><p>time 칼럼을 보면 2분 단위로 데이터가 나누어져 있는 것을 알 수 있다. 여기서의 목표는 break가 발생하기 4분 전에 조기 예측하는 것이다. 그러므로 4분 전까지의 데이터를 break 데이터로 만들기 위해서는 curve shifting을 2개의 row만큼만 적용하면 된다. 이후, 본래 break 데이터는 제거한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">sign = <span class="keyword">lambda</span> x: (<span class="number">1</span>, <span class="number">-1</span>)[x &lt; <span class="number">0</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">curve_shift</span><span class="params">(df, shift_by)</span>:</span></span><br><span class="line">vector = df[<span class="string">'y'</span>].copy()</span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> range(abs(shift_by)):</span><br><span class="line">tmp = vector.shift(sign(shift_by))</span><br><span class="line">tmp = tmp.fillna(<span class="number">0</span>)</span><br><span class="line">vector += tmp</span><br><span class="line">labelcol = <span class="string">'y'</span></span><br><span class="line"><span class="comment"># Add vector to the df</span></span><br><span class="line">df.insert(loc=<span class="number">0</span>, column=labelcol+<span class="string">'tmp'</span>, value=vector)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove the rows with labelcol == 1.</span></span><br><span class="line">df = df.drop(df[df[labelcol] == <span class="number">1</span>].index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Drop labelcol and rename the tmp col as labelcol</span></span><br><span class="line">df = df.drop(labelcol, axis=<span class="number">1</span>)</span><br><span class="line">df = df.rename(columns=&#123;labelcol+<span class="string">'tmp'</span>: labelcol&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make the labelcol binary</span></span><br><span class="line">df.loc[df[labelcol] &gt; <span class="number">0</span>, labelcol] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> df</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># shift the response column y by 2 rows to do a 4-min ahead prediction</span></span><br><span class="line">shifted_df = curve_shift(df, shift_by=<span class="number">-5</span>)</span><br><span class="line">shifted_df.head()</span><br></pre></td></tr></table></figure><p><img src="/image/lstm-autoencoder-code2.PNG"></p><p>몇 가지 불필요한 데이터는 제거한 후, 데이터와 라벨을 분리해준다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># drop remove columns</span></span><br><span class="line">shifted_df = shifted_df.drop([<span class="string">'time'</span>,<span class="string">'x28'</span>,<span class="string">'x61'</span>], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x, y</span></span><br><span class="line">input_x = shifted_df.drop(<span class="string">'y'</span>, axis=<span class="number">1</span>).values</span><br><span class="line">input_y = shifted_df[<span class="string">'y'</span>].values</span><br><span class="line"></span><br><span class="line">n_features = input_x.shape[<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p><h3 id="4-Transform-to-Series-Data"><a href="#4-Transform-to-Series-Data" class="headerlink" title="4. Transform to Series Data"></a>4. Transform to Series Data</h3><p>LSTM 모델은 (samples, timesteps, feature)에 해당하는 3d 차원의 shape을 가지므로, 데이터를 시퀀스 형태로 변환한다. timesteps은 5(즉, 10분)만큼 잡았다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">temporalize</span><span class="params">(X, y, timesteps)</span>:</span></span><br><span class="line">output_X = []</span><br><span class="line">output_y = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(X) - timesteps - <span class="number">1</span>):</span><br><span class="line">t = []</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, timesteps + <span class="number">1</span>):</span><br><span class="line"><span class="comment"># Gather the past records upto the lookback period</span></span><br><span class="line">t.append(X[[(i + j + <span class="number">1</span>)], :])</span><br><span class="line">output_X.append(t)</span><br><span class="line">output_y.append(y[i + timesteps + <span class="number">1</span>])</span><br><span class="line"><span class="keyword">return</span> np.squeeze(np.array(output_X)), np.array(output_y)</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">timesteps = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Temporalize</span></span><br><span class="line">x, y = temporalize(input_x, input_y, timesteps)</span><br><span class="line">print(x.shape) <span class="comment"># (18268, 5, 59)</span></span><br></pre></td></tr></table></figure><h3 id="5-Split-Train-Valid-Test"><a href="#5-Split-Train-Valid-Test" class="headerlink" title="5. Split Train / Valid / Test"></a>5. Split Train / Valid / Test</h3><p>이후, 훈련, 검증, 테스트 용 데이터로 분리한다. 각각 11,691, 2,923, 3,654개로 나누어주었다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Split into train, valid, and test </span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>)</span><br><span class="line">x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">print(len(x_train))  <span class="comment"># 11691</span></span><br><span class="line">print(len(x_valid))  <span class="comment"># 2923</span></span><br><span class="line">print(len(x_test))   <span class="comment"># 3654</span></span><br></pre></td></tr></table></figure></p><p>LSTM Autoencoder 학습 시에는 Normal(0) 데이터만으로 학습할 것이기 때문에 데이터로 부터 Normal(0)과 Break(1) 데이터를 분리한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For training the autoencoder, split 0 / 1</span></span><br><span class="line">x_train_y0 = x_train[y_train == <span class="number">0</span>]</span><br><span class="line">x_train_y1 = x_train[y_train == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">x_valid_y0 = x_valid[y_valid == <span class="number">0</span>]</span><br><span class="line">x_valid_y1 = x_valid[y_valid == <span class="number">1</span>]</span><br></pre></td></tr></table></figure></p><h3 id="6-Standardize"><a href="#6-Standardize" class="headerlink" title="6. Standardize"></a>6. Standardize</h3><p>각기 다른 데이터 특성의 표준화를 위해 z-score 정규화인 scikit-learn의 StandardScaler()를 적용하였다. 해당 함수를 적용하기 위해서는 2d 형태여야 하므로 Flatten 과정을 거친 후 스케일을 적용하였으며 이후 다시 3d 형태로 변환하였다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatten</span><span class="params">(X)</span>:</span></span><br><span class="line">    flattened_X = np.empty((X.shape[<span class="number">0</span>], X.shape[<span class="number">2</span>]))  <span class="comment"># sample x features array.</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">0</span>]):</span><br><span class="line">        flattened_X[i] = X[i, (X.shape[<span class="number">1</span>]<span class="number">-1</span>), :]</span><br><span class="line">    <span class="keyword">return</span>(flattened_X)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scale</span><span class="params">(X, scaler)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">0</span>]):</span><br><span class="line">        X[i, :, :] = scaler.transform(X[i, :, :])</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scaler = StandardScaler().fit(flatten(x_train_y0))</span><br><span class="line"></span><br><span class="line">x_train_y0_scaled = scale(x_train_y0, scaler)</span><br><span class="line">x_valid_scaled = scale(x_valid, scaler)</span><br><span class="line">x_valid_y0_scaled = scale(x_valid_y0, scaler)</span><br><span class="line">x_test_scaled = scale(x_test, scaler)</span><br></pre></td></tr></table></figure><h3 id="7-Training-LSTM-Autoencoder"><a href="#7-Training-LSTM-Autoencoder" class="headerlink" title="7. Training LSTM Autoencoder"></a>7. Training LSTM Autoencoder</h3><p>대칭 구조의 Staked Autoencoder 형태로 LSTM Autoencoder를 구성하여 정상 데이터로만 구성 된 데이터를 통해 총 200 epoch 학습시켰다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">200</span></span><br><span class="line">batch = <span class="number">128</span></span><br><span class="line">lr = <span class="number">0.001</span></span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">lstm_ae = models.Sequential()</span><br><span class="line"><span class="comment"># Encoder</span></span><br><span class="line">lstm_ae.add(layers.LSTM(<span class="number">32</span>, activation=<span class="string">'relu'</span>, input_shape=(timesteps, n_features), return_sequences=<span class="keyword">True</span>))</span><br><span class="line">lstm_ae.add(layers.LSTM(<span class="number">16</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">False</span>))</span><br><span class="line">lstm_ae.add(layers.RepeatVector(timesteps))</span><br><span class="line"><span class="comment"># Decoder</span></span><br><span class="line">lstm_ae.add(layers.LSTM(<span class="number">16</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">lstm_ae.add(layers.LSTM(<span class="number">32</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">lstm_ae.add(layers.TimeDistributed(layers.Dense(n_features)))</span><br><span class="line"></span><br><span class="line">lstm_ae.summary()</span><br></pre></td></tr></table></figure><p><img src="/image/lstm-autoencoder-code3.PNG"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># compile</span></span><br><span class="line">lstm_ae.compile(loss=<span class="string">'mse'</span>, optimizer=optimizers.Adam(lr))</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit</span></span><br><span class="line">history = lstm_ae.fit(x_train_y0_scaled, x_train_y0_scaled,</span><br><span class="line">                     epochs=epochs, batch_size=batch,</span><br><span class="line">                     validation_data=(x_valid_y0_scaled, x_valid_y0_scaled))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Train on 11314 samples, validate on 2830 samples</span><br><span class="line">Epoch 1/200</span><br><span class="line">11314/11314 [==============================] - 4s 393us/sample - loss: 0.8505 - val_loss: 0.6345</span><br><span class="line">Epoch 2/200</span><br><span class="line">11314/11314 [==============================] - 1s 86us/sample - loss: 0.5249 - val_loss: 0.4738</span><br><span class="line">Epoch 3/200</span><br><span class="line">11314/11314 [==============================] - 1s 83us/sample - loss: 0.4049 - val_loss: 0.3784</span><br><span class="line"></span><br><span class="line">::::</span><br><span class="line"></span><br><span class="line">Epoch 198/200</span><br><span class="line">11314/11314 [==============================] - 1s 94us/sample - loss: 0.1256 - val_loss: 0.1308</span><br><span class="line">Epoch 199/200</span><br><span class="line">11314/11314 [==============================] - 1s 97us/sample - loss: 0.1209 - val_loss: 0.1282</span><br><span class="line">Epoch 200/200</span><br><span class="line">11314/11314 [==============================] - 1s 96us/sample - loss: 0.1212 - val_loss: 0.1308</span><br></pre></td></tr></table></figure><p>train loss와 valid loss 모두 0.1근처로 수렴하고 있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(history.history[<span class="string">'loss'</span>], label=<span class="string">'train loss'</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'val_loss'</span>], label=<span class="string">'valid loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>); plt.ylabel(<span class="string">'loss'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/lstm-autoencoder-code4.PNG"></p><h3 id="8-Threshold-by-Precision-Recall-Curve"><a href="#8-Threshold-by-Precision-Recall-Curve" class="headerlink" title="8. Threshold by Precision Recall Curve"></a>8. Threshold by Precision Recall Curve</h3><p>normal과 break를 구분하기 위한 threshold를 지정하기 위해 precision recall curve를 적용한다. 주의해야할 것은 디코딩 된 재구성 결과가 아닌 재구성 손실(reconstruction error)와 실제 라벨 값을 비교한다는 것이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">valid_x_predictions = lstm_ae.predict(x_valid_scaled)</span><br><span class="line">mse = np.mean(np.power(flatten(x_valid_scaled) - flatten(valid_x_predictions), <span class="number">2</span>), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">error_df = pd.DataFrame(&#123;<span class="string">'Reconstruction_error'</span>:mse, </span><br><span class="line">                         <span class="string">'True_class'</span>:list(y_valid)&#125;)</span><br><span class="line">precision_rt, recall_rt, threshold_rt = metrics.precision_recall_curve(error_df[<span class="string">'True_class'</span>], error_df[<span class="string">'Reconstruction_error'</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(threshold_rt, precision_rt[<span class="number">1</span>:], label=<span class="string">'Precision'</span>)</span><br><span class="line">plt.plot(threshold_rt, recall_rt[<span class="number">1</span>:], label=<span class="string">'Recall'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Threshold'</span>); plt.ylabel(<span class="string">'Precision/Recall'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/lstm-autoencoder-code5.PNG"></p><p>여기서 threshold의 경우 <strong>Recall과 Precision의 값이 교차되는 지점을 최적의 threshold 지점으로 잡았다.</strong><br>여기서 최적의 threshold는 0.407이다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># best position of threshold</span></span><br><span class="line">index_cnt = [cnt <span class="keyword">for</span> cnt, (p, r) <span class="keyword">in</span> enumerate(zip(precision_rt, recall_rt)) <span class="keyword">if</span> p==r][<span class="number">0</span>]</span><br><span class="line">print(<span class="string">'precision: '</span>,precision_rt[index_cnt],<span class="string">', recall: '</span>,recall_rt[index_cnt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fixed Threshold</span></span><br><span class="line">threshold_fixed = threshold_rt[index_cnt]</span><br><span class="line">print(<span class="string">'threshold: '</span>,threshold_fixed)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">precision:  0.10752688172043011 , recall:  0.10752688172043011</span><br><span class="line">threshold:  0.40777142413843237</span><br></pre></td></tr></table></figure><h3 id="9-Predict-Test"><a href="#9-Predict-Test" class="headerlink" title="9. Predict Test"></a>9. Predict Test</h3><p>이제 테스트 셋에 적용해볼 차례이다. 학습하였던 LSTM Autoencoder 모델을 통해 테스트 셋을 예측 후 재구성 손실을 계산한다. 그 후 위에서 찾은 threshold를 적용하여 Normal과 Break를 구분한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">test_x_predictions = lstm_ae.predict(x_test_scaled)</span><br><span class="line">mse = np.mean(np.power(flatten(x_test_scaled) - flatten(test_x_predictions), <span class="number">2</span>), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">error_df = pd.DataFrame(&#123;<span class="string">'Reconstruction_error'</span>: mse,</span><br><span class="line">                         <span class="string">'True_class'</span>: y_test.tolist()&#125;)</span><br><span class="line"></span><br><span class="line">groups = error_df.groupby(<span class="string">'True_class'</span>)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, group <span class="keyword">in</span> groups:</span><br><span class="line">    ax.plot(group.index, group.Reconstruction_error, marker=<span class="string">'o'</span>, ms=<span class="number">3.5</span>, linestyle=<span class="string">''</span>,</span><br><span class="line">            label= <span class="string">"Break"</span> <span class="keyword">if</span> name == <span class="number">1</span> <span class="keyword">else</span> <span class="string">"Normal"</span>)</span><br><span class="line">ax.hlines(threshold_fixed, ax.get_xlim()[<span class="number">0</span>], ax.get_xlim()[<span class="number">1</span>], colors=<span class="string">"r"</span>, zorder=<span class="number">100</span>, label=<span class="string">'Threshold'</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.title(<span class="string">"Reconstruction error for different classes"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Reconstruction error"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Data point index"</span>)</span><br><span class="line">plt.show();</span><br></pre></td></tr></table></figure></p><p><img src="/image/lstm-autoencoder-code6.PNG"></p><h3 id="10-Evaluation"><a href="#10-Evaluation" class="headerlink" title="10. Evaluation"></a>10. Evaluation</h3><h4 id="confusion-matrix"><a href="#confusion-matrix" class="headerlink" title="confusion matrix"></a>confusion matrix</h4><p>테스트 셋에 대한 재구성 손실을 threshold를 기준으로 0/1로 나누고 이를 confusion matrix로 표현하였다.<br>Break에 대한 예측 결과가 실망스러울 수 있지만 이렇게 Sheet Break의 10%만 줄여도 엄청난 손실을 줄일 수 있다고 한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># classification by threshold</span></span><br><span class="line">pred_y = [<span class="number">1</span> <span class="keyword">if</span> e &gt; threshold_fixed <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> e <span class="keyword">in</span> error_df[<span class="string">'Reconstruction_error'</span>].values]</span><br><span class="line"></span><br><span class="line">conf_matrix = metrics.confusion_matrix(error_df[<span class="string">'True_class'</span>], pred_y)</span><br><span class="line">plt.figure(figsize=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=<span class="keyword">True</span>, fmt=<span class="string">'d'</span>)</span><br><span class="line">plt.title(<span class="string">'Confusion Matrix'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Predicted Class'</span>); plt.ylabel(<span class="string">'True Class'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/lstm-autoencoder-code7.PNG"></p><h4 id="ROC-Curve-and-AUC"><a href="#ROC-Curve-and-AUC" class="headerlink" title="ROC Curve and AUC"></a>ROC Curve and AUC</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">false_pos_rate, true_pos_rate, thresholds = metrics.roc_curve(error_df[<span class="string">'True_class'</span>], error_df[<span class="string">'Reconstruction_error'</span>])</span><br><span class="line">roc_auc = metrics.auc(false_pos_rate, true_pos_rate,)</span><br><span class="line"></span><br><span class="line">plt.plot(false_pos_rate, true_pos_rate, linewidth=<span class="number">5</span>, label=<span class="string">'AUC = %0.3f'</span>% roc_auc)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>], linewidth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim([<span class="number">-0.01</span>, <span class="number">1</span>])</span><br><span class="line">plt.ylim([<span class="number">0</span>, <span class="number">1.01</span>])</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.title(<span class="string">'Receiver operating characteristic curve (ROC)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'True Positive Rate'</span>); plt.xlabel(<span class="string">'False Positive Rate'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/lstm-autoencoder-code8.PNG"></p><h3 id="11-Result"><a href="#11-Result" class="headerlink" title="11. Result"></a>11. Result</h3><p>최종적으로 테스트 셋에 대한 재구성 손실을 threshold를 통해 구분한 <code>pred_y</code>의 마지막 5번째(timestep만큼)을 출력하여 예측 결과를 확인할 수 있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_y[<span class="number">-5</span>:]  <span class="comment"># [0, 0, 1, 0, 0]</span></span><br></pre></td></tr></table></figure></p><p>위 결과를 해석하기가 애매모호한 부분이 있지만, 대략 넓게 잡았을 때 최소 10분 이내에는 Break가 발생할 것 같다고 해석할 수 있을 것이다.</p><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://towardsdatascience.com/extreme-rare-event-classification-using-autoencoders-in-keras-a565b386f098" target="_blank" rel="noopener">Extreme Rare Event Classification using Autoencoders in Keras</a></li><li><a href="https://towardsdatascience.com/lstm-autoencoder-for-extreme-rare-event-classification-in-keras-ce209a224cfb" target="_blank" rel="noopener">LSTM Autoencoder for Extreme Rare Event Classification in Keras</a></li><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li><li><a href="https://m.blog.naver.com/PostView.nhn?blogId=chunjein&amp;logNo=221589624838&amp;proxyReferer=https%3A%2F%2Fwww.google.com%2F" target="_blank" rel="noopener">LSTM TimeDistributed layer</a></li><li><a href="https://stackoverflow.com/questions/51749404/how-to-connect-lstm-layers-in-keras-repeatvector-or-return-sequence-true" target="_blank" rel="noopener">How to connect LSTM layers in Keras, RepeatVector or return_sequence=True?</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;지난 포스팅(&lt;a href=&quot;https://jaehyeongan.github.io/2020/02/28/A
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="autoencoder" scheme="https://jaehyeongan.github.io/tags/autoencoder/"/>
    
      <category term="lstm" scheme="https://jaehyeongan.github.io/tags/lstm/"/>
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="lstmautoencoder" scheme="https://jaehyeongan.github.io/tags/lstmautoencoder/"/>
    
      <category term="prediction" scheme="https://jaehyeongan.github.io/tags/prediction/"/>
    
      <category term="shifting" scheme="https://jaehyeongan.github.io/tags/shifting/"/>
    
      <category term="windowing" scheme="https://jaehyeongan.github.io/tags/windowing/"/>
    
  </entry>
  
  <entry>
    <title>Autoencoder와 LSTM Autoencoder</title>
    <link href="https://jaehyeongan.github.io/2020/02/28/Autoencoder-LSTMautoencoder/"/>
    <id>https://jaehyeongan.github.io/2020/02/28/Autoencoder-LSTMautoencoder/</id>
    <published>2020-02-28T14:26:57.000Z</published>
    <updated>2020-10-28T15:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>대표적인 자기 지도 학습인 Autoencoder와 Autoencoder에 LSTM cell을 적용해 시퀀스 학습이 가능한 LSTM Autoencoder에 대해 소개한다. 이후 다음 포스팅에는 LSTM Autoencoder를 통해 미래에 발생 할 고장이나 이상신호를 조기 예측하기 위한 Anomaly Detection 방안에 대해 소개할 것이다. </p><hr><h2 id="1-Autoencoder"><a href="#1-Autoencoder" class="headerlink" title="1. Autoencoder?"></a>1. Autoencoder?</h2><p><strong>오토인코더는(autoencoder)는 라벨이 없는 훈련 데이터를 사용한 학습(즉, 지도 학습) 없이도 입력 데이터의 표현을 효율적으로 학습할 수 있는 인공신경망이다.</strong> 오토인코더는 아래 그림과 같이 input 레이어, hidden 레이어, output 레이어로 구성되어 있으며 일반적으로 Input 유닛보다 훨씬 낮은 차원의 hidden 유닛을 가지므로 주로 <strong>차원 축소(Dimensionality Reduction)</strong> 목적으로 사용된다. 또한 오토인코더는 강력한 feature extractor로 작동하기 때문에 비지도 사전훈련에 사용될 수 있고, 훈련 데이터와 매우 비슷한 새로운 데이터를 생성하는 <strong>생성 모델(generative model)</strong>로서 사용될 수 있다.<br><img src="/image/autoencoder-architecture.png" width="700px"></p><p>오토인코더가 학습하는 것은 단순히 입력을 출력으로 복사하는 것이다. 하지만 그 과정에서 여러 방법의 제약(내부 표현 크기 제한, 입력 잡음 추가 등)을 통해 오토인코더가 단순히 입력을 바로 출력으로 복사하지 못하도록 막고, 데이터를 효율적으로 재표현(representation)하는 방법을 학습하도록 제어한다. 오토인코더는 인코더(encoder)와 디코더(decoder)로 구분된다.</p><ul><li><strong>인코더(encoder) : 인지 네트워크(recognition network)라고도 하며, 입력을 내부 표현으로 변환</strong></li><li><strong>디코더(decoder) : 생성 네트워크(generative network)라고도 하며, 내부 표현을 출력으로 변환</strong><br><br></li></ul><blockquote><p><img src="/image/autoencoder-reconstruction-error.PNG"></p></blockquote><p>오토인코더가 입력을 재구성하기 때문에 출력을 재구성(reconstruction)이라고 부르며, 입력과 재구성된 출력과의 차이를 계산하여 <strong>재구성 손실(reconstruction loss)</strong>이라고 한다. 여기서 파라미터 (θ,φ)는 encoder에 입력되는 original input (x)과 디코더를 통해 출력 된 reconstruced input (f(g(x))이 같아지도록 학습하며 업데이트 된다.<br><br></p><h3 id="1-1-Stacked-Autoencoder"><a href="#1-1-Stacked-Autoencoder" class="headerlink" title="1.1. Stacked Autoencoder"></a>1.1. Stacked Autoencoder</h3><p>여러 개의 hidden 레이어를 가진 경우를 적층 오토인코더(stacked autoencoder)라고 한다. 아래 그림와 같이 레이어를 더 추가할 경우 오토인코더는 더 복작한 표현을 학습할 수 있게 되며 일반적으로 적층 오토인코더는 추가된 hideen 레이어를 기준으로 인코더와 디코더는 대칭 구조를 이룬다.<br><img src="/image/stacked-autoencoder.png" width="650px"></p><p>위와 같이 오토인코더가 완벽하게 대칭 구조를 이룰 때는 일반적으로 인코더와 디코더의 가중치를 묶게 되는데 이렇게 할 경우 모델의 가중치 수를 절반으로 줄여 훈련속도를 높이고 overfitting 위험을 줄일 수 있다고 한다.</p><p><br></p><h3 id="1-2-Denoising-Autoencoder"><a href="#1-2-Denoising-Autoencoder" class="headerlink" title="1.2. Denoising Autoencoder"></a>1.2. Denoising Autoencoder</h3><p>위에서 살펴보았던 Stacked Autoencoder의 경우 다수의 hidden 레이어와 노드가 추가 될 경우 overfitting 자신에 대한 표현을 세밀하게 학습하게 되는 overfitting 문제에 직면할 수 있다. 이를 해결하기 위한 한 가지 방법으로 제안된 것이 <strong>Denoising Autoencoder</strong>(Vincent et al. 2008)이다. 이 모델은 말 그대로 모델에 학습되기 전 Input 데이터에 잡음(noise)을 주어 모델이 데이터 표현을 학습하기 힘들게 만든다.<br><img src="/image/denoising-autoencoder-architecture.png" width="700px"></p><p>이렇게 하는 이유는 모델을 일반화하기 위한 목적이며, 노이즈 즉, 제약이 있는 상황에서도 데이터를 효울적으로 복원하기 위함이다. 이때 잡음을 주기 위한 방법은 여러가지가 있지만 해당 논문에서는 아래와 같이 데이터의 일부가 삭제된 input(x~) 를 넣어 이 x~가 출력 된 reconstruced input(x’)과 유사해지도록 학습하는 것이다.</p><blockquote><p><img src="/image/denoising-autoencoder-error.png"></p></blockquote><p><br></p><h2 id="2-LSTM-Autoencoer"><a href="#2-LSTM-Autoencoer" class="headerlink" title="2. LSTM Autoencoer"></a>2. LSTM Autoencoer</h2><p>LSTM Autoencoder는 시퀀스(sequence) 데이터에 Encoder-Decoder LSTM 아키텍처를 적용하여 구현한 오토인코더이다. 아래 그림은 LSTM 오토인코더의 구조이며 입력 시퀀스가 순차적으로 들어오게 되고, 마지막 입력 시퀀스가 들어온 후 디코더는 입력 시퀀스를 재생성하거나 혹은 목표 시퀀스에 대한 예측을 출력한다. </p><p><img src="/image/lstm-autoencoder-architecture.png" width="650px"><br><br></p><h3 id="2-1-Reconstruction-LSTM-Autoencoder"><a href="#2-1-Reconstruction-LSTM-Autoencoder" class="headerlink" title="2.1 Reconstruction LSTM Autoencoder"></a>2.1 Reconstruction LSTM Autoencoder</h3><p>재구성(reconstruction)을 위한 LSTM Autoencoder 구조이다. 즉, input과 최대한 유사하게 output을 디코딩하며, LSTM 학습을 위해 데이터를 우선 (samples, timesteps, feature)와 같은 3d형태로 변환한다. input 레이어의 feature는 1차원으므로 output 레이어도 동일한 차원으로 구성하여 출력되도록 한다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model ,models, layers, optimizers, utils</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define input sequence</span></span><br><span class="line">sequence = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># reshape input into [samples, timesteps, features]</span></span><br><span class="line">n_in = len(sequence)</span><br><span class="line">sequence = sequence.reshape((<span class="number">1</span>, n_in, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># define model</span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, input_shape=(n_in, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.RepeatVector(n_in))</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(layers.TimeDistributed(layers.Dense(<span class="number">1</span>)))</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit model</span></span><br><span class="line">model.fit(sequence, sequence, epochs=<span class="number">300</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">yhat = model.predict(sequence)</span><br><span class="line">yhat</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">array([[[0.10559099],</span><br><span class="line">        [0.20217314],</span><br><span class="line">        [0.30041453],</span><br><span class="line">        [0.39952287],</span><br><span class="line">        [0.49908453],</span><br><span class="line">        [0.5987617 ],</span><br><span class="line">        [0.69832975],</span><br><span class="line">        [0.7991052 ],</span><br><span class="line">        [0.9024458 ]]], dtype=float32)</span><br></pre></td></tr></table></figure><p><br></p><h3 id="2-2-Prediction-LSTM-Autoencoder"><a href="#2-2-Prediction-LSTM-Autoencoder" class="headerlink" title="2.2 Prediction LSTM Autoencoder"></a>2.2 Prediction LSTM Autoencoder</h3><p>시계열적 예측을 위한 LSTM 구조이며 input 시퀀스는 현재 시점(t) output 시점은 (t+1)로 두어 한 시점 앞을 학습하도록 데이터를 구성한다. 여기서 autoencoder는 학습 시 encoder에는 t 시점이 입력되지만 decoding 후에는 (t+1)시점과 reconstruction error를 계산하며 결국 t 시점이 t+1 시점을 학습하게 된다.<br>결과적으로 예측 결과는 1이 입력되면 2와 가까운 수를, 2가 입력되면 3과 가까운 수를 예측하게 된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define input sequence</span></span><br><span class="line">seq_in = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># reshape input into [samples, timesteps, features]</span></span><br><span class="line">n_in = len(seq_in)</span><br><span class="line">seq_in = seq_in.reshape((<span class="number">1</span>, n_in, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare output sequence</span></span><br><span class="line">seq_out = seq_in[:, <span class="number">1</span>:, :]</span><br><span class="line">n_out = n_in - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define model </span></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, input_shape=(n_in, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.RepeatVector(n_out))</span><br><span class="line">model.add(layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(layers.TimeDistributed(layers.Dense(<span class="number">1</span>)))</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit model</span></span><br><span class="line">model.fit(seq_in, seq_out, epochs=<span class="number">300</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">yhat = model.predict(seq_in)</span><br><span class="line">yhat</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">array([[[0.16683361],</span><br><span class="line">        [0.2898971 ],</span><br><span class="line">        [0.403169  ],</span><br><span class="line">        [0.5089176 ],</span><br><span class="line">        [0.6094323 ],</span><br><span class="line">        [0.7060289 ],</span><br><span class="line">        [0.7997408 ],</span><br><span class="line">        [0.89148134]]], dtype=float32)</span><br></pre></td></tr></table></figure><p><br></p><h3 id="2-3-Composite-LSTM-Autoencoder"><a href="#2-3-Composite-LSTM-Autoencoder" class="headerlink" title="2.3 Composite LSTM Autoencoder"></a>2.3 Composite LSTM Autoencoder</h3><p>Reconstruction과 Prediction 모델을 통합한 모델이다. 모델의 통합을 위해 예제에서는 <a href="https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/">keras functional api</a>를 활용하였으며, 결과적으로 출력 시 reconstruction결과와 prediction결과가 함께 출력된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define input sequence</span></span><br><span class="line">seq_in = np.array([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># reshape input into [samples, timesteps, features]</span></span><br><span class="line">n_in = len(seq_in)</span><br><span class="line">seq_in = seq_in.reshape((<span class="number">1</span>, n_in, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># prepare output sequence</span></span><br><span class="line">seq_out = seq_in[:, <span class="number">1</span>:, :]</span><br><span class="line">n_out = n_in - <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define encoder</span></span><br><span class="line">visible = layers.Input(shape=(n_in, <span class="number">1</span>))</span><br><span class="line">encoder = layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>)(visible)</span><br><span class="line"><span class="comment"># define reconstruct decoder</span></span><br><span class="line">decoder1 = layers.RepeatVector(n_in)(encoder)</span><br><span class="line">decoder1 = layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>)(decoder1)</span><br><span class="line">decoder1 = layers.TimeDistributed(layers.Dense(<span class="number">1</span>))(decoder1)</span><br><span class="line"><span class="comment"># define predict decoder</span></span><br><span class="line">decoder2 = layers.RepeatVector(n_out)(encoder)</span><br><span class="line">decoder2 = layers.LSTM(<span class="number">100</span>, activation=<span class="string">'relu'</span>, return_sequences=<span class="keyword">True</span>)(decoder2)</span><br><span class="line">decoder2 = layers.TimeDistributed(layers.Dense(<span class="number">1</span>))(decoder2)</span><br><span class="line"><span class="comment"># concat model</span></span><br><span class="line">model = Model(inputs=visible, outputs=[decoder1, decoder2])</span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'mse'</span>)</span><br><span class="line"><span class="comment"># utils.plot_model(model, show_shapes=True, to_file='composite_lstm_autoencoder.png')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># fit model </span></span><br><span class="line">model.fit(seq_in, [seq_in, seq_out], epochs=<span class="number">300</span>, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">yhat = model.predict(seq_in)</span><br><span class="line">yhat</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[array([[[0.10127164],</span><br><span class="line">         [0.19949059],</span><br><span class="line">         [0.29943317],</span><br><span class="line">         [0.39987874],</span><br><span class="line">         [0.50023794],</span><br><span class="line">         [0.60028654],</span><br><span class="line">         [0.7000689 ],</span><br><span class="line">         [0.79983366],</span><br><span class="line">         [0.89999163]]], dtype=float32), array([[[0.19868489],</span><br><span class="line"></span><br><span class="line">         [0.30206183],</span><br><span class="line">         [0.3981459 ],</span><br><span class="line">         [0.4989811 ],</span><br><span class="line">         [0.600592  ],</span><br><span class="line">         [0.7013527 ],</span><br><span class="line">         [0.80077535],</span><br><span class="line">         [0.8988221 ]]], dtype=float32)]</span><br></pre></td></tr></table></figure><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://github.com/ageron/handson-ml" target="_blank" rel="noopener">Hands-On Machine Learning with Scikit-Learn and TensorFlow</a></li><li><a href="https://arxiv.org/abs/1502.04681" target="_blank" rel="noopener">Unsupervised Learning of Video Representations using LSTMs</a></li><li><a href="https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html</a></li><li><a href="https://machinelearningmastery.com/lstm-autoencoders/" target="_blank" rel="noopener">https://machinelearningmastery.com/lstm-autoencoders/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;대표적인 자기 지도 학습인 Autoencoder와 Autoencoder에 LSTM cell을 적용해 시퀀
      
    
    </summary>
    
    
      <category term="autoencoder" scheme="https://jaehyeongan.github.io/tags/autoencoder/"/>
    
      <category term="rnn" scheme="https://jaehyeongan.github.io/tags/rnn/"/>
    
      <category term="lstm" scheme="https://jaehyeongan.github.io/tags/lstm/"/>
    
      <category term="reconstruction" scheme="https://jaehyeongan.github.io/tags/reconstruction/"/>
    
      <category term="encoder" scheme="https://jaehyeongan.github.io/tags/encoder/"/>
    
      <category term="decoder" scheme="https://jaehyeongan.github.io/tags/decoder/"/>
    
  </entry>
  
  <entry>
    <title>OpenCV를 활용한 기초 이미지 처리 with Python</title>
    <link href="https://jaehyeongan.github.io/2020/02/15/OpenCV%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EA%B8%B0%EC%B4%88-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%B2%98%EB%A6%AC/"/>
    <id>https://jaehyeongan.github.io/2020/02/15/OpenCV를-활용한-기초-이미지-처리/</id>
    <published>2020-02-15T09:01:24.000Z</published>
    <updated>2020-10-28T15:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>머신러닝 분야에서 가장 활발하게 연구 되고 있는 분야는 아무래도 컴퓨터 비전(computer vision)분야 인 것 같다.<br>최근 컨볼루션 네트워크 모델들은 <strong>feature extraction</strong> 능력이 매우 뛰어나서 이미지에 추가적인 전처리 작업을 하지 않더라도 뛰어난 성능을 내고 있다. 하지만 그렇더라도 더 효과적인 모델을 위해서는 적용하고자 하는 목적에 맞게 이미지 전처리 작업을 거쳐야 하는 경우가 있다.</p><p>이번 글은 <em>‘파이썬을 활용한 머신러닝 쿡북 - CHAPTER 8 이미지 다루기’</em>를 읽고 정리한 글이며, OpenCV를 활용한 다양한 이미지 처리 기술에 대해 소개한다. </p><hr><h2 id="1-OpenCV-설치"><a href="#1-OpenCV-설치" class="headerlink" title="1. OpenCV 설치"></a>1. OpenCV 설치</h2><p><a href="https://opencv.org/" target="_blank" rel="noopener">OpenCV(Open Source Computer Vision Libary)</a>는 이미지를 다루는 분야에서 가장 널리 이용되고 인기 있는 라이브러리이며, 이미지를 처리하기 위한 편리한 기능을 대부분 담고 있다. 아래의 명령어를 통해 설치가 가능하다.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure></p><p>설치가 제대로 되었는지 OpenCV를 import하여 버전을 확인한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">cv2.__version__    <span class="comment"># 4.1.2</span></span><br></pre></td></tr></table></figure></p><p><br></p><h2 id="2-이미지-로드"><a href="#2-이미지-로드" class="headerlink" title="2. 이미지 로드"></a>2. 이미지 로드</h2><p>여기서 활용하는 샘플 이미지는 해당 책의 <a href="https://github.com/rickiepark/machine-learning-with-python-cookbook/tree/master/images" target="_blank" rel="noopener">github</a> 에서 다운받을 수 있다. </p><p>먼저 앞으로 공통적으로 계속 사용 될 라이브러리를 임포트한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure></p><p><strong>imread()</strong> 메소드를 통해 이미지를 로드 후 matplotlib을 통해 출력해본다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">'images/plane.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line">plt.imshow(); plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/opencv-image-1.png"></p><p>위 이미지의 type 및 shape을 출력해보면 아래와 같다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image.type   <span class="comment"># numpy.ndarray</span></span><br><span class="line">image.shape  <span class="comment"># (2270, 3600)</span></span><br></pre></td></tr></table></figure></p><p>이미지 데이터는 본래 개별 원소로 이루어진 행렬의 집합이다. 여기서 개별 원소는 픽셀(pixel)이라고 할 수 있으며 개별 원소의 값은 픽셀의 강도라고 할 수 있다. 그리고 픽셀의 강도는 0(검정)부터 255(흰색) 사이의 범위를 가지고 있다. </p><p>이미지를 행렬 그대로 출력하게 되면 아래와 같이 표현된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([[140, 136, 146, ..., 132, 139, 134],</span><br><span class="line">       [144, 136, 149, ..., 142, 124, 126],</span><br><span class="line">       [152, 139, 144, ..., 121, 127, 134],</span><br><span class="line">       ...,</span><br><span class="line">       [156, 146, 144, ..., 157, 154, 151],</span><br><span class="line">       [146, 150, 147, ..., 156, 158, 157],</span><br><span class="line">       [143, 138, 147, ..., 156, 157, 157]], dtype=uint8)</span><br></pre></td></tr></table></figure><p>컬러를 이미지를 읽기 위해서는 imread() 메소드에 <strong>cv2.IMREAD_COLOR</strong> 매개변수를 넣어주면 된다. 그런데 주의할점은 OpenCV는 기본적으로 이미지를 BGR타입으로 읽는다는 것이다. 하지만 Matplotlib등 대부분의 이미지 라이브러리는 RGB타입을 사용하기 때문에 BGR RGB타입으로 변경해주는 것이 좋다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 컬러 이미지 로드</span></span><br><span class="line">image_bgr = cv2.imread(<span class="string">'images/plane.jpg'</span>, cv2.IMREAD_COLOR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># RGB타입으로 변환</span></span><br><span class="line">image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">plt.imshow(); plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-2.png"><br><br></p><h2 id="3-이미지-저장"><a href="#3-이미지-저장" class="headerlink" title="3. 이미지 저장"></a>3. 이미지 저장</h2><p>OpenCV의 <strong>imwrite()</strong> 메소드를 사용하여 이미지를 저장할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 로드 </span></span><br><span class="line">image = cv2.imread(<span class="string">'images/plane.jpg'</span>, cv.IMREAD_GRAYSCALE)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 저장 </span></span><br><span class="line">cv2.imwrite(<span class="string">'images/new_plane.jpg'</span>, image)</span><br></pre></td></tr></table></figure><p><br></p><h2 id="4-이미지-크기-변경"><a href="#4-이미지-크기-변경" class="headerlink" title="4. 이미지 크기 변경"></a>4. 이미지 크기 변경</h2><p>OpenCV의 <strong>resize()</strong> 메소드를 이용하여 이미지 크기 변경이 가능하다.<br>256x256 크기의 이미지를 로드한 후 이를 50x50 크기의 이미지로 변경한 후 출력해본다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 크기를 50x50으로 변경</span></span><br><span class="line">image_50x50 = cv2.resize(image, (<span class="number">50</span>, <span class="number">50</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 출력 </span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].imshow(image, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Original Image'</span>)</span><br><span class="line">ax[<span class="number">1</span>].imshow(image_50x50, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Resized Image'</span>)</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-3.png"><br><br></p><h2 id="5-이미지-자르기-crop"><a href="#5-이미지-자르기-crop" class="headerlink" title="5. 이미지 자르기(crop)"></a>5. 이미지 자르기(crop)</h2><p>이미지를 자르고 싶을  경우 배열 슬라이싱을 이용하여 원하는 부분만 crop할 수 있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미지의 모든 행과 열의 절반만 선택</span></span><br><span class="line">image_cropped = image[:,:<span class="number">128</span>]</span><br><span class="line"></span><br><span class="line">plt.imshow(image_cropped, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/opencv-image-4.png"><br><br></p><h2 id="6-이미지-blur-처리"><a href="#6-이미지-blur-처리" class="headerlink" title="6. 이미지 blur 처리"></a>6. 이미지 blur 처리</h2><p>이미지를 흐리게 하기 위해서는 각 픽셀을 주변 픽셀의 평균값으로 변환하면 되며, 이렇게 주변 픽셀에 수행되는 연산을 <strong>커널(kernel)</strong>이라고 한다. 커널이 클수록 이미지가 더 부드러워지게 된다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 로드 </span></span><br><span class="line">image = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># blur() : 각 픽셀에 커널 개수의 역수를 곱하여 모두 더함</span></span><br><span class="line">image_blurry = cv2.blur(image, (<span class="number">5</span>,<span class="number">5</span>)) <span class="comment"># 5 x 5 커널 평균값으로 이미지를 흐리게 함 </span></span><br><span class="line"></span><br><span class="line">plt.imshow(image_blurry, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-5.png"></p><p>100x100 커널과 같이 큰 커널을 적용할 경우 이미지가 훨씬 뭉개지게 된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image_very_blurry = cv2.blur(image, (<span class="number">100</span>,<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">plt.imshow(image_very_blurry, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/opencv-image-6.png"></p><p>아래와 같이 커널을 직접 정의한 후 <strong>filter2D()</strong> 메소드를 통해 이미지에 적용하는 것도 가능하다.<br>생성된 커널을 이미지에 적용 시 중앙 원소가 변환되는 픽셀이며, 나머지는 그 픽셀의 이웃이 된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 커널 생성 </span></span><br><span class="line">kernel = np.ones((<span class="number">10</span>,<span class="number">10</span>)) / <span class="number">25.0</span> <span class="comment"># 모두 더하면 1이 되도록 정규화</span></span><br><span class="line">kernel</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">array([[0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04],</span><br><span class="line">       [0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># filter2D함수로 커널을 이미지에 직접 적용 </span></span><br><span class="line">image_kernel = cv2.filter2D(image, <span class="number">-1</span>, kernel)</span><br><span class="line"></span><br><span class="line">plt.imshow(image_kernel, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-7.png"></p><p>자주 사용되는 블러 함수로 가우시안 분포를 사용하는 <strong>가우시안 블러(GaussianBlur)</strong>가 있다. GaussianBlur() 함수의 세 번째 매개변수는 X축(너비) 방향의 표준편차이며, 0으로 지정하면 ((너비-1)<em>0.5-1)</em>0.3+0.8과 같이 계산된다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image_very_blurry = cv2.GaussianBlur(image, (<span class="number">5</span>,<span class="number">5</span>), <span class="number">0</span>) </span><br><span class="line"></span><br><span class="line">plt.imshow(image_very_blurry, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-8.png"><br><br></p><h2 id="7-이미지-선명하게-표현"><a href="#7-이미지-선명하게-표현" class="headerlink" title="7. 이미지 선명하게 표현"></a>7. 이미지 선명하게 표현</h2><p>대상 픽셀을 강조하는 커널을 정의한 후 filter2D() 메소드를 사용하여 이미지에 적용한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 커널 생성(대상이 있는 픽셀을 강조)</span></span><br><span class="line">kernel = np.array([[<span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>],</span><br><span class="line">                   [<span class="number">-1</span>, <span class="number">5</span>, <span class="number">-1</span>],</span><br><span class="line">                   [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 커널 적용 </span></span><br><span class="line">image_sharp = cv2.filter2D(image, <span class="number">-1</span>, kernel)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">2</span>, figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].imshow(image, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Original Image'</span>)</span><br><span class="line">ax[<span class="number">1</span>].imshow(image_sharp, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Sharp Image'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/image/opencv-image-9.png"><br><br></p><h2 id="8-이미지-대비-높이기"><a href="#8-이미지-대비-높이기" class="headerlink" title="8. 이미지 대비 높이기"></a>8. 이미지 대비 높이기</h2><p><strong>히스토그램 평활화(Histogram Equalization)</strong>은 객체의 형태가 두드러지도록 만들어주는 이미지 처리 도구이며, OpenCV에서는 <strong>equalizeHist()</strong> 메소드를 통해 적용할 수 있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미지 대비를 향상</span></span><br><span class="line">image_enhanced = cv2.equalizeHist(image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">ax[<span class="number">0</span>].imshow(image, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Original Image'</span>)</span><br><span class="line">ax[<span class="number">1</span>].imshow(image_enhanced, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Enhanced Image'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/image/opencv-image-10.png"></p><p>컬러 이미지의 경우 먼저 YUV 컬러 포맷으로 변환해야 한다. Y는 루마 또는 밝기이고 U와 V는 컬러를 나타낸다. 변환한 뒤에 위와 동일하게 equlizeHist() 메소드를 적용하고 다시 RGB 포맷으로 변환 후 출력한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">image_bgr = cv2.imread(<span class="string">'images/plane.jpg'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># YUV 컬로 포맷으로 변환</span></span><br><span class="line">image_yuv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2YUV)</span><br><span class="line"><span class="comment"># 히스토그램 평활화 적용</span></span><br><span class="line">image_yuv[:, :, <span class="number">0</span>] = cv2.equalizeHist(image_yuv[:, :, <span class="number">0</span>])</span><br><span class="line"><span class="comment"># #RGB로 변환</span></span><br><span class="line">image_rgb = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax[<span class="number">0</span>].imshow(image_bgr, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Original Color Image'</span>)</span><br><span class="line">ax[<span class="number">1</span>].imshow(image_rgb, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Enhanced Color Image'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/image/opencv-image-11.png"><br><br></p><h2 id="9-이미지-이진화"><a href="#9-이미지-이진화" class="headerlink" title="9. 이미지 이진화"></a>9. 이미지 이진화</h2><p>이미지 이진화(임계처리)는 어떤 값보다 큰 값을 가진 픽셀을 흰색으로 만들고 작은 값을 가진 픽셀은 검은색으로 만드는 과정이다. 더 고급 기술은 <strong>적응적 이진화(Adaptive Thresholding)</strong>로, 픽셀의 임곗값이 주변 픽셀의 강도에 의해 결정된다. 이는 이미지 안의 영역마다 빛 조건이 달라질 때 도움이 된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 로드 </span></span><br><span class="line">image_grey = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Adaptive Thresholding 적용 </span></span><br><span class="line">max_output_value = <span class="number">255</span>   <span class="comment"># 출력 픽셀 강도의 최대값</span></span><br><span class="line">neighborhood_size = <span class="number">99</span></span><br><span class="line">subtract_from_mean = <span class="number">10</span></span><br><span class="line">image_binarized = cv2.adaptiveThreshold(image_grey,</span><br><span class="line">                                       max_output_value,</span><br><span class="line">                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,</span><br><span class="line">                                       cv2.THRESH_BINARY,</span><br><span class="line">                                       neighborhood_size,</span><br><span class="line">                                       subtract_from_mean)</span><br></pre></td></tr></table></figure></p><p>adaptiveThreshold() 함수에는 네 개의 중요한 매개변수가 있다.</p><ul><li>max_output_value : 출력 픽셀 강도의 최댓값 저장 </li><li>cv2.ADAPTIVE_THRESH_GAUSSIAN_C : 픽셀의 임곗값을 주변 픽셀 강도의 가중치 합으로 설정. 가중치는 가우시안 윈도우에 의해 결정 </li><li>cv2.ADAPTIVE_THRESH_MEAN_C : 주변 픽셀의 평균을 임곗값으로 설정 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot</span></span><br><span class="line">plt.imshow(image_binarized, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-12.png"><br><br></p><h2 id="10-배경-제거"><a href="#10-배경-제거" class="headerlink" title="10. 배경 제거"></a>10. 배경 제거</h2><p>배경을 제거하고자 하는 전경 주위에 사각형 박스를 그리고 그랩컷(grabCut) 알고리즘을 적용하여 배경을 제거한다.<br>grabCut의 경우 잘 작동하더라도 여전히 이미지에 제거하지 못한 배경이 발생할 수 있다. 이렇게 제거 되지 못한 부분은 다시 적용하여 제거할 수 있지만 실전에서 수 천장의 이미지를 수동으로 고치는 것은 불가능한 일이므로 머신러닝을 적용한다거나 할 때도 일부러 noise를 적용하는 것처럼 일부 배경이 남아있는 것을 수용하는 것이 좋다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 로드 후 RGB로 변환</span></span><br><span class="line">image_bgr = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>)</span><br><span class="line">image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 사각형 좌표: 시작점의 x,y  ,넢이, 너비</span></span><br><span class="line">rectangle = (<span class="number">0</span>, <span class="number">56</span>, <span class="number">256</span>, <span class="number">150</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 초기 마스크 생성</span></span><br><span class="line">mask = np.zeros(image_rgb.shape[:<span class="number">2</span>], np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># grabCut에 사용할 임시 배열 생성</span></span><br><span class="line">bgdModel = np.zeros((<span class="number">1</span>, <span class="number">65</span>), np.float64)</span><br><span class="line">fgdModel = np.zeros((<span class="number">1</span>, <span class="number">65</span>), np.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># grabCut 실행</span></span><br><span class="line">cv2.grabCut(image_rgb, <span class="comment"># 원본 이미지</span></span><br><span class="line">           mask,       <span class="comment"># 마스크</span></span><br><span class="line">           rectangle,  <span class="comment"># 사각형</span></span><br><span class="line">           bgdModel,   <span class="comment"># 배경을 위한 임시 배열</span></span><br><span class="line">           fgdModel,   <span class="comment"># 전경을 위한 임시 배열 </span></span><br><span class="line">           <span class="number">5</span>,          <span class="comment"># 반복 횟수</span></span><br><span class="line">           cv2.GC_INIT_WITH_RECT) <span class="comment"># 사각형을 위한 초기화</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 배경인 곳은 0, 그 외에는 1로 설정한 마스크 생성</span></span><br><span class="line">mask_2 = np.where((mask==<span class="number">2</span>) | (mask==<span class="number">0</span>), <span class="number">0</span>, <span class="number">1</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미지에 새로운 마스크를 곱행 배경을 제외</span></span><br><span class="line">image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">plt.imshow(image_rgb_nobg)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-13.png"></p><p>위에서 먼저 전경이 들어있는 영역 주위를 사각형으로 표시하였는데, grabCut은 이 사각형 밖에 있는 모든 것이 배경이라고 가정하고 이 정보를 사용하여 사각형 안에 있는 배경을 찾는다.<br><img src="/image/opencv-image-14.png"><br>왼쪽 그림의 검은 영역은 배경이라고 확실하게 가정한 사각형의 바깥쪽 영역이며, 회색 영역은 그랩컷이 배경이라고 생각하는 영역, 그리고 흰색 영역은 전경이다. 오른쪽 그림은 두 번째 마스크를 이미지에 적용하여 전경만 남긴 이미지이다.<br><br></p><h2 id="11-경계선-감지"><a href="#11-경계선-감지" class="headerlink" title="11. 경계선 감지"></a>11. 경계선 감지</h2><p>Canny()메소드를 활용하여 경계선을 감지 할 수 있다. Canny()메소드는 그래디언트 임곗값 사이의 저점과 고점을 나타내는 두 매개변수를 필요로 하며, 낮은 임곗값과 높은 임곗값 사이의 가능성 있는 경계선 픽셀은 약한 경계선 픽셀로 간주하고, 높은 임곗값보다 큰 픽셀은 강한 경계선 픽셀로 간주한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 로드</span></span><br><span class="line">image_gray = cv2.imread(<span class="string">'images/plane_256x256.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 픽셀 강도의 중간값을 계산</span></span><br><span class="line">median_intensity = np.median(image_gray)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 중간 픽셀 강도에서 위아래 1 표준편차 떨어진 값을 임곗값으로 지정</span></span><br><span class="line">lower_threshold = int(max(<span class="number">0</span>, (<span class="number">1.0</span> - <span class="number">0.33</span>) * median_intensity))</span><br><span class="line">upper_threshold = int(min(<span class="number">255</span>, (<span class="number">1.0</span> + <span class="number">0.33</span>) * median_intensity))</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Canny edge detection 적용</span></span><br><span class="line">image_canny = cv2.Canny(image_gray, lower_threshold, upper_threshold)</span><br><span class="line"></span><br><span class="line">plt.imshow(image_canny, cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/opencv-image-15.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;머신러닝 분야에서 가장 활발하게 연구 되고 있는 분야는 아무래도 컴퓨터 비전(computer vision
      
    
    </summary>
    
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="opencv" scheme="https://jaehyeongan.github.io/tags/opencv/"/>
    
      <category term="image" scheme="https://jaehyeongan.github.io/tags/image/"/>
    
  </entry>
  
  <entry>
    <title>AWS EC2에 플라스크(Flask) 클라우드 웹 서버 구축하기</title>
    <link href="https://jaehyeongan.github.io/2020/01/13/aws-flask/"/>
    <id>https://jaehyeongan.github.io/2020/01/13/aws-flask/</id>
    <published>2020-01-13T12:26:58.000Z</published>
    <updated>2020-12-10T14:50:03.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro "></a>Intro </h2><p>지난 번 글에서 Flask 웹 프레임워크를 통해 간단한 딥러닝 웹 애플리케이션을 개발해보았다. 하지만 로컬(local) 환경에서 개발하였기 때문에 개발 서버를 종일 켜놓거나 고정 도메인을 따로 받지 않은 이상 외부 IP로 접근은 불가능하다.<br>그렇기 때문에 나처럼 물리적인 서버를 구축 및 운영할 환경이 되지 않을 경우는 클라우드(Cloud) 서비스를 이용하게 되는데, </p><p>이번 글에서는 <strong>AWS(Amazon Web Services)</strong>라고 하는 클라우드 서비스를 활용하여 웹 서버를 구축 후 Flask를 배포하는 과정을 설명하려고 한다.</p><hr><h2 id="1-AWS-EC2-가입-및-인스턴스-생성"><a href="#1-AWS-EC2-가입-및-인스턴스-생성" class="headerlink" title="1. AWS EC2 가입 및 인스턴스 생성"></a>1. AWS EC2 가입 및 인스턴스 생성</h2><p>우선 <a href="https://ap-northeast-2.console.aws.amazon.com/console/home?region=ap-northeast-2#" target="_blank" rel="noopener">AWS Management Consol</a>로 이동 후 가입이 되어있지 않다면 가입 후 로그인을 한다. (가입 시 region을 Seoul로 설정할 것)<br>서비스 검색을 통해 EC2를 선택한다.<br><img src="/image/aws-mc.png" width="1000"></p><p>EC2 대시보드에서 인스턴스 생성 아래의 <strong>인스턴스 시작</strong> 버튼을 클릭<br><img src="/image/aws-instance.png" width="1000"></p><p>AMI로는 기업용이 아니니 개인 개발용으로 편한 <strong>Ubuntu Linux 18.04</strong> 버전을 사용하며,<br>무료 서버 이용이 가능한 <strong>프리 티어(Free Tier)</strong>로 서버를 생성한다.<br><img src="/image/aws-ami.png" width="1000"><br><img src="/image/aws-free.png" width="1000"><br><img src="/image/aws-start.png" width="1000"></p><p>위 이미지에서 시작 버튼을 누를 경우 키 페어를 설정하는 메시지가 나타나는데 이 키 페어는 말 그대로 생성한 웹 서버에 추후 접속할 때 꼭 필요한 키 역할을 한다. <strong>‘새 키 페어 생성’</strong>을 선택하고 <strong>‘키 페어 이름’</strong>을 본인 취향에 맞게 설정 후 <strong>‘키 페어 다운로드’</strong>를 선택한다. (이 키 페어는 추후 서버 접속 시 꼭 필요하므로 본인 개발 폴더에 잘 보관해둔다.)<br>키 페어를 다운로드하여 인스턴스 시작 버튼이 활성화되면 버튼을 클릭하여 진행한다.<br><img src="/image/aws-keypair.png" width="1000"></p><p><strong>인스턴스 보기</strong>를 선택<br><img src="/image/aws-status.png" width="1000"></p><p>여기까지가 진행하게 되면 인스턴스가 아래와 같이 생성된다.<br><img src="/image/aws-instance-view.png" width="1000"><br><br></p><h2 id="2-Key-Pair-권한-설정-변경"><a href="#2-Key-Pair-권한-설정-변경" class="headerlink" title="2. Key Pair 권한 설정 변경"></a>2. Key Pair 권한 설정 변경</h2><p>전 과정에서 인스턴스를 생성하면서 Key Pair를 같이 다운로드 하였을 것이다. 하지만 접속하기 위해서는 이 권한 설정을 변경해줘야만 접속이 가능하다. </p><p>우선 다운받은 키페어를 우클릭하여 <strong>[속성]-[보안]</strong> 탭으로 이동 후 <strong>[고급]</strong>을 클릭한다.<br><img src="/image/aws-admin.png" width="700"></p><p>아래와 같은 화면에서,<br><strong>[상속 사용 안 함]</strong>을 클릭 후, 팝업 메시지에서 <strong>‘상속된 사용 권한을 이 개체에 대한 명시적 사용 권한으로 변환합니다’</strong>를 선택<br><img src="/image/aws-admin-remove1.png" width="700"><br><img src="/image/aws-admin-remove2.png" width="700"></p><p>이후 아래와 같이 Administrators를 제외한 모든 사용 권한 항목을 제거한다<br><img src="/image/aws-admin-remove3.png" width="700"><br><br></p><h2 id="3-보안-그룹-설정"><a href="#3-보안-그룹-설정" class="headerlink" title="3. 보안 그룹 설정"></a>3. 보안 그룹 설정</h2><p>인스턴스 화면으로 돌아와 <strong>Flask 웹 서버 포트 번호인 5000번 포트</strong>를 열어 주기 위해 보안 그룹을 설정한다.<br><img src="/image/aws-security.png" width="1000"></p><p>[인바운드] 탭에서 [편집]을 클릭 후 [규칙 추가]를 하여 아래와 같이 5000번 포트를 설정한다.<br><img src="/image/aws-security2.png" width="1000"></p><h2 id="4-인스턴스-접속하기"><a href="#4-인스턴스-접속하기" class="headerlink" title="4. 인스턴스 접속하기"></a>4. 인스턴스 접속하기</h2><p>다시 인스턴스 화면으로 돌아와 아래 화면에서 생성한 인스턴스를 선택 후 연결 버튼을 클릭한다.<br>연결 방법으로는 <strong>‘독립 실행형 SSH 클라이언트’</strong>로 선택하고, 아래 ssh 명령어를 복사한다.<br><img src="/image/aws-connect.png" width="1000"><br><img src="/image/aws-connect2.png" width="1000"></p><p>명령프롬프트(CMD)를 관리자 권한으로 실행 후 다운 받은 Key Pair가 있는 위치로 이동한다. 그 후 위에서 복사한 SSH 명령어를 복사하여 우분투 리눅스 인스턴스에 접속한다.<br><img src="/image/aws-ubuntu.png" width="800"></p><p>우선 파이썬 라이브러리 도구인 pip 및 java jdk 등을 설치해주고, 본인의 파이썬 코드가 수행되기 위한 라이브러리를 설치해준다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"></span><br><span class="line"># java 설치 </span><br><span class="line">$ sudo apt install openjdk-8-jre</span><br><span class="line">$ sudo apt install openjdk-8-jdk</span><br><span class="line"></span><br><span class="line"># pip 설치 및 라이브러리 설치</span><br><span class="line">$ sudo apt install python3-pip</span><br><span class="line">$ sudo apt install tensorflow</span><br><span class="line">$ sudo apt install keras</span><br><span class="line">$ sudo apt install opencv-python</span><br><span class="line">$ sudo apt install scipy</span><br><span class="line">:</span><br></pre></td></tr></table></figure></p><p>이후 개발한 flask를 웹 서버로 clone하여 해당 경로로 이동 후 웹 서버를 실행해준다.<br><img src="/image/aws-ubuntu2.png" width="650"><br><img src="/image/aws-ubuntu3.png" width="650"></p><p>이제 웹 서버가 실행 중이니 퍼블릭 IP로 접속이 가능하다. 아래 인스턴스 화면에서 <strong>‘IPv4 퍼블릭 IP’</strong> 주소를 복사 후 5000번 포트번호( <a href="http://54.180.150.154:5000/" target="_blank" rel="noopener">http://54.180.150.154:5000/</a> )로 접속한다.</p><p><img src="/image/aws-dl-flask.PNG" width="1000"><br>고정 IP에서 서버가 잘 실행되고 있다.<br><br></p><h2 id="5-파이썬-서버-계속-실행-시키기"><a href="#5-파이썬-서버-계속-실행-시키기" class="headerlink" title="5. 파이썬 서버 계속 실행 시키기"></a>5. 파이썬 서버 계속 실행 시키기</h2><p>위와 같이 정상적으로 고정 IP를 통해 접속이 가능함을 확인하였다. 하지만 SSH 프롬프트를 종료하게 되면 파이썬 서버도 함께 종료되게 된다. 마지막으로 파이썬 서버가 항상 실행될 수 있도록 설정한다. </p><ol><li>Ctrl+Z 를 통해 파이썬 프로세스 중지</li><li>$ bg : 백그라운드에서 프로세스 재 구동</li><li>$ disown -h : 소유권 포기 </li></ol><hr><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><a href="https://ndb796.tistory.com/244" target="_blank" rel="noopener">https://ndb796.tistory.com/244</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro &quot;&gt;&lt;/a&gt;Intro &lt;/h2&gt;&lt;p&gt;지난 번 글에서 Flask 웹 프레임워크를 통해 간단한 딥러닝 웹 애플리케이션을 개발해보았다. 하지만
      
    
    </summary>
    
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="flask" scheme="https://jaehyeongan.github.io/tags/flask/"/>
    
      <category term="web" scheme="https://jaehyeongan.github.io/tags/web/"/>
    
      <category term="amazon" scheme="https://jaehyeongan.github.io/tags/amazon/"/>
    
      <category term="aws" scheme="https://jaehyeongan.github.io/tags/aws/"/>
    
      <category term="webservice" scheme="https://jaehyeongan.github.io/tags/webservice/"/>
    
      <category term="cloud" scheme="https://jaehyeongan.github.io/tags/cloud/"/>
    
      <category term="webframework" scheme="https://jaehyeongan.github.io/tags/webframework/"/>
    
  </entry>
  
  <entry>
    <title>파이썬 웹 프레임워크 Flask를 활용한 딥러닝 웹 애플리케이션 개발</title>
    <link href="https://jaehyeongan.github.io/2019/12/27/flask-deeplearning-webapplication/"/>
    <id>https://jaehyeongan.github.io/2019/12/27/flask-deeplearning-webapplication/</id>
    <published>2019-12-27T14:20:58.000Z</published>
    <updated>2020-12-10T15:19:35.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>Java의 Spring처럼 Python에서도 웹 프레임워크를 제공한다. 그 중 가장 인기 있는 것이 Django와 Flask인데, Django의 경우 Instagram, LinkedIn 사이트로 사용될 정도로 인기 있고 안정적인 웹 프레임워크라고 할 수 있다. 그 만큼 체계적이고 정교한 구조를 가지고 있다고 할 수 있는데 그와 반대로 Flask는 좀 더 간편하고 경량화 된 웹 프레임워크라고 생각하면 될 것 같다. 그래서 실제 서비스 하기 보다는 간단한 프로토타입 개발 용도로 많이 사용되는 것 같다. </p><p>이번에는 Flask 웹 프레임워크에 대해 알아보고 딥러닝 모델 중 Neural Style Transfer를 Flask에서 실행하여 결과를 웹으로 표출해보도록 할 것이다.</p><blockquote><p><em>※ 해당 전체 코드는 <a href="https://github.com/jaehyeongAN/PyFlask_DL-service" target="_blank" rel="noopener">github</a>에서 확인 할 수 있습니다.</em></p></blockquote><hr><h2 id="1-Flask-설치"><a href="#1-Flask-설치" class="headerlink" title="1. Flask 설치"></a>1. Flask 설치</h2><h4 id="1-flask-프로젝트-폴더-생성"><a href="#1-flask-프로젝트-폴더-생성" class="headerlink" title="1) flask 프로젝트 폴더 생성"></a>1) flask 프로젝트 폴더 생성</h4><p>우선 flask 프로젝트를 수행할 폴더를 본인의 임의 경로에 설치해준다. 나는 아래와 같은 경로에 폴더를 만들었다.</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">cd&nbsp;workspace</div><div style="padding:0 6px; white-space:pre; line-height:130%">workspace&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">&gt;</span>&nbsp;mkdir&nbsp;pyflask</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p><img src="/image/flask_dir.JPG" width="500"></p><h4 id="2-가상환경"><a href="#2-가상환경" class="headerlink" title="2) 가상환경"></a>2) 가상환경</h4><p>flask 환경을 위한 virtualenv 가상환경 라이브러리를 설치한다.</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">pip&nbsp;install&nbsp;virtualenv</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>설치 완료 후 본인의 flask 경로 내에서 가상환경을 생성해준다. </p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">workspace\pyflask&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">&gt;</span>&nbsp;virtualenv&nbsp;venv</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>정상적으로 실행 시 flask 폴더 내에 venv 폴더가 생성되는데 venv/Scripts 폴더로 이동하여 가상환경을 활성화(active) 한다.</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">workspace\pyflask&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">&gt;</span>&nbsp;cd&nbsp;venv<span style="color:#0086b3"></span><span style="color:#ff3399">/</span>Scripts</div><div style="padding:0 6px; white-space:pre; line-height:130%">workspace\pyflask\venv\Scripts&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">&gt;</span>&nbsp;activate</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><h4 id="3-Flask-설치"><a href="#3-Flask-설치" class="headerlink" title="3) Flask 설치"></a>3) Flask 설치</h4><p>위에서 active한 가상환경 내에서 flask를 설치해준다. </p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">(venv)&nbsp;pip&nbsp;install&nbsp;flask</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>설치완료 된 flask의 버전은 아래처럼 확인할 수 있다.</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">flask&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">-</span><span style="color:#0086b3"></span><span style="color:#ff3399">-</span>version</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p><img src="/image/flask_version.JPG" width="400"></p><p><br></p><h2 id="2-웹-구성"><a href="#2-웹-구성" class="headerlink" title="2. 웹 구성"></a>2. 웹 구성</h2><p>이제 Flask를 개발할 환경은 구축하였으니, 웹 애플리케이션의 구조를 설계해 볼 것이다.<br>여기서 프로토타입으로 구성해 볼 웬 애플리케이션은 간단하게 메인 페이지로 구성되고, 각 기능을 수행하는 서브 페이지로 이동하게 된다. 이후 사용자로 부터 입력값을 받아 딥러닝 기능 수행 후 그 결과값을 다시 웹으로 출력해주는 구조를 가진다. </p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">index&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(메인&nbsp;페이지)</div><div style="padding:0 6px; white-space:pre; line-height:130%">├──&nbsp;nst_get&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(user&nbsp;input&nbsp;받는&nbsp;페이지)</div><div style="padding:0 6px; white-space:pre; line-height:130%">└──&nbsp;nst_post&nbsp;&nbsp;&nbsp;&nbsp;(결과&nbsp;출력&nbsp;페이지)</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p><br></p><h4 id="1-폴더-구성"><a href="#1-폴더-구성" class="headerlink" title="1) 폴더 구성"></a>1) 폴더 구성</h4><p>우선 효율적인 웹 개발을 위하여 flask 폴더 내에 몇 개의 폴더를 설치하여 기능별로 관리한다. </p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div><div style="line-height:130%">4</div><div style="line-height:130%">5</div><div style="line-height:130%">6</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%">pyflask/</div><div style="padding:0 6px; white-space:pre; line-height:130%">├──&nbsp;static/</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;└──&nbsp;images/</div><div style="padding:0 6px; white-space:pre; line-height:130%">├──&nbsp;templates/</div><div style="padding:0 6px; white-space:pre; line-height:130%">├──&nbsp;venv/</div><div style="padding:0 6px; white-space:pre; line-height:130%">└──&nbsp;neural_style_transfer.py</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><ul><li>static/images : 사용자로부터 받을 이미지를 저장할 경로</li><li>templates : html 파일 </li><li>neural_style_transfer.py : neural style transfer를 수행할 딥러닝 코드</li></ul><p><br></p><h4 id="2-HTML-템플릿"><a href="#2-HTML-템플릿" class="headerlink" title="2) HTML 템플릿"></a>2) HTML 템플릿</h4><p>우선 화면 구성을 위하여 HTML 템플릿을 아래와 같이 최대한 간단하게 작성하였다.<br>(지면상 CSS와 JS코드는 제거하였는데 전체 코드는 <a href="https://github.com/jaehyeongAN/PyFlask_DL-service" target="_blank" rel="noopener">github</a>에서 확인할 수 있다.)</p><ul><li><p>index.html (메인 페이지)</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div><div style="line-height:130%">4</div><div style="line-height:130%">5</div><div style="line-height:130%">6</div><div style="line-height:130%">7</div><div style="line-height:130%">8</div><div style="line-height:130%">9</div><div style="line-height:130%">10</div><div style="line-height:130%">11</div><div style="line-height:130%">12</div><div style="line-height:130%">13</div><div style="line-height:130%">14</div><div style="line-height:130%">15</div><div style="line-height:130%">16</div><div style="line-height:130%">17</div><div style="line-height:130%">18</div><div style="line-height:130%">19</div><div style="line-height:130%">20</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">!DOCTYPE</span>&nbsp;<span style="color:#a8ff58">html</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">html</span>&nbsp;<span style="color:#a8ff58">lang</span>=<span style="color:#ffd500">"ko"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">head</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">charset</span>=<span style="color:#ffd500">"UTF-8"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"viewport"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">content</span>=<span style="color:#ffd500">"width=device-width,&nbsp;initial-scale=1.0"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">http-equiv</span>=<span style="color:#ffd500">"X-UA-Compatible"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">content</span>=<span style="color:#ffd500">"ie=edge"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">title</span><span style="color:#f0f0f0">&gt;</span>Flask&nbsp;Index<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">title</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">head</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">body</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h1</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Flask&nbsp;for&nbsp;Deep&nbsp;ConvNet<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h1</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">ul</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">li</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">a</span>&nbsp;<span style="color:#a8ff58">href</span>=<span style="color:#ffd500">"/nst_get"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Neural&nbsp;Style&nbsp;Transfer<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">a</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">li</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">li</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">a</span>&nbsp;<span style="color:#a8ff58">href</span>=<span style="color:#ffd500">"#"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Obejct&nbsp;Detection<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">a</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">li</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">ul</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">body</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">footer</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">'center'</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Powerd&nbsp;by&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">strong</span><span style="color:#f0f0f0">&gt;</span>©&nbsp;2019&nbsp;JaeHyeong<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">strong</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">footer</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">html</span><span style="color:#f0f0f0">&gt;</span></div></div><div style="text-align:right;margin-top:-13px;margin-right:5px;font-size:9px;font-style:italic"><a href="http://colorscripter.com/info#e" target="_blank" style="color:#4f4f4ftext-decoration:none">Colored by Color Scripter</a></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>— a태그 링크에 /nst_get을 명시하여 클릭 시 nst_get.html로 이동<br><br></p></li><li><p>nst_get.html (user input 받는 페이지)</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div><div style="line-height:130%">4</div><div style="line-height:130%">5</div><div style="line-height:130%">6</div><div style="line-height:130%">7</div><div style="line-height:130%">8</div><div style="line-height:130%">9</div><div style="line-height:130%">10</div><div style="line-height:130%">11</div><div style="line-height:130%">12</div><div style="line-height:130%">13</div><div style="line-height:130%">14</div><div style="line-height:130%">15</div><div style="line-height:130%">16</div><div style="line-height:130%">17</div><div style="line-height:130%">18</div><div style="line-height:130%">19</div><div style="line-height:130%">20</div><div style="line-height:130%">21</div><div style="line-height:130%">22</div><div style="line-height:130%">23</div><div style="line-height:130%">24</div><div style="line-height:130%">25</div><div style="line-height:130%">26</div><div style="line-height:130%">27</div><div style="line-height:130%">28</div><div style="line-height:130%">29</div><div style="line-height:130%">30</div><div style="line-height:130%">31</div><div style="line-height:130%">32</div><div style="line-height:130%">33</div><div style="line-height:130%">34</div><div style="line-height:130%">35</div><div style="line-height:130%">36</div><div style="line-height:130%">37</div><div style="line-height:130%">38</div><div style="line-height:130%">39</div><div style="line-height:130%">40</div><div style="line-height:130%">41</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">!DOCTYPE</span>&nbsp;<span style="color:#a8ff58">html</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">html</span>&nbsp;<span style="color:#a8ff58">lang</span>=<span style="color:#ffd500">"ko"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">head</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">charset</span>=<span style="color:#ffd500">"UTF-8"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"viewport"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">content</span>=<span style="color:#ffd500">"width=device-width,&nbsp;initial-scale=1.0"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">http-equiv</span>=<span style="color:#ffd500">"X-UA-Compatible"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">content</span>=<span style="color:#ffd500">"ie=edge"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">title</span><span style="color:#f0f0f0">&gt;</span>Flask&nbsp;image&nbsp;get<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">title</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">head</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">body</span><span style="color:#f0f0f0">&gt;</span>&nbsp;&nbsp;&nbsp;&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h1</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Neural&nbsp;Sytle&nbsp;Transfer<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h1</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">form</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">action</span>=<span style="color:#ffd500">"/nst_post"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">method</span>=<span style="color:#ffd500">"POST"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">enctype</span>=<span style="color:#ffd500">"multipart/form-data"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h2</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Reference&nbsp;Images<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">table</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img1"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/rain_princess.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img2"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/the_stary_night.JPG"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img3"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/scream.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img3"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/zentangle_art.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"rain_princess.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"the_stary_night.JPG"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"scream.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"zentangle_art.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">table</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h2</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Target&nbsp;Image<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">div</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">'view_area'</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">div</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"file"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"user_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"user_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"userIMgage"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">onchange</span>=<span style="color:#ffd500">"previewImage(this,'view_area')"</span><span style="color:#a8ff58">/</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"submit"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"확인"</span><span style="color:#a8ff58">/</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">form</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">body</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">html</span><span style="color:#f0f0f0">&gt;</span>&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div></div><div style="text-align:right;margin-top:-13px;margin-right:5px;font-size:9px;font-style:italic"><a href="http://colorscripter.com/info#e" target="_blank" style="color:#4f4f4ftext-decoration:none">Colored by Color Scripter</a></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>— 이미지를 Flask로 넘겨주는 페이지이므로 form 태그의 POST 방식을 수행<br>— neural style transfer 학습을 위한 reference 이미지 경로를 지정하여 표시<br>— 사용자로부터 이미지 파일을 입력 받음<br>— 확인 버튼을 통해 선택한 reference 이미지와 사용자 이미지를 전송<br><br></p></li><li><p>nst_post.html (결과 출력 페이지)</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div><div style="line-height:130%">4</div><div style="line-height:130%">5</div><div style="line-height:130%">6</div><div style="line-height:130%">7</div><div style="line-height:130%">8</div><div style="line-height:130%">9</div><div style="line-height:130%">10</div><div style="line-height:130%">11</div><div style="line-height:130%">12</div><div style="line-height:130%">13</div><div style="line-height:130%">14</div><div style="line-height:130%">15</div><div style="line-height:130%">16</div><div style="line-height:130%">17</div><div style="line-height:130%">18</div><div style="line-height:130%">19</div><div style="line-height:130%">20</div><div style="line-height:130%">21</div><div style="line-height:130%">22</div><div style="line-height:130%">23</div><div style="line-height:130%">24</div><div style="line-height:130%">25</div><div style="line-height:130%">26</div><div style="line-height:130%">27</div><div style="line-height:130%">28</div><div style="line-height:130%">29</div><div style="line-height:130%">30</div><div style="line-height:130%">31</div><div style="line-height:130%">32</div><div style="line-height:130%">33</div><div style="line-height:130%">34</div><div style="line-height:130%">35</div><div style="line-height:130%">36</div><div style="line-height:130%">37</div><div style="line-height:130%">38</div><div style="line-height:130%">39</div><div style="line-height:130%">40</div><div style="line-height:130%">41</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">!DOCTYPE</span>&nbsp;<span style="color:#a8ff58">html</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">html</span>&nbsp;<span style="color:#a8ff58">lang</span>=<span style="color:#ffd500">"ko"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">head</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">charset</span>=<span style="color:#ffd500">"UTF-8"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"viewport"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">content</span>=<span style="color:#ffd500">"width=device-width,&nbsp;initial-scale=1.0"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">meta</span>&nbsp;<span style="color:#a8ff58">http-equiv</span>=<span style="color:#ffd500">"X-UA-Compatible"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">content</span>=<span style="color:#ffd500">"ie=edge"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">title</span><span style="color:#f0f0f0">&gt;</span>Flask&nbsp;image&nbsp;get<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">title</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">head</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">body</span><span style="color:#f0f0f0">&gt;</span>&nbsp;&nbsp;&nbsp;&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h1</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Neural&nbsp;Sytle&nbsp;Transfer<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h1</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">form</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">action</span>=<span style="color:#ffd500">"/nst_post"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">method</span>=<span style="color:#ffd500">"POST"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">enctype</span>=<span style="color:#ffd500">"multipart/form-data"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h2</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Reference&nbsp;Images<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">table</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img1"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/rain_princess.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img2"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/the_stary_night.JPG"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img3"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/scream.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">img</span>&nbsp;<span style="color:#a8ff58">class</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"refer_img3"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">src</span>=<span style="color:#ffd500">"./static/images/zentangle_art.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"rain_princess.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"the_stary_night.JPG"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"scream.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"radio"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"refer_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"zentangle_art.jpg"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">td</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">tr</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">table</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">h2</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span>Target&nbsp;Image<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">h2</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">div</span>&nbsp;<span style="color:#a8ff58">align</span>=<span style="color:#ffd500">"center"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">'view_area'</span><span style="color:#a8ff58"></span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">div</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"file"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">name</span>=<span style="color:#ffd500">"user_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">id</span>=<span style="color:#ffd500">"user_img"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"userIMgage"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">onchange</span>=<span style="color:#ffd500">"previewImage(this,'view_area')"</span><span style="color:#a8ff58">/</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">input</span>&nbsp;<span style="color:#a8ff58">type</span>=<span style="color:#ffd500">"submit"</span><span style="color:#a8ff58"></span>&nbsp;<span style="color:#a8ff58">value</span>=<span style="color:#ffd500">"확인"</span><span style="color:#a8ff58">/</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">form</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span><span style="color:#f0f0f0">&lt;</span><span style="color:#ff3399">br</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">body</span><span style="color:#f0f0f0">&gt;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#f0f0f0">&lt;</span><span style="color:#f0f0f0">/</span><span style="color:#ff3399">html</span><span style="color:#f0f0f0">&gt;</span>&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div></div><div style="text-align:right;margin-top:-13px;margin-right:5px;font-size:9px;font-style:italic"><a href="http://colorscripter.com/info#e" target="_blank" style="color:#4f4f4ftext-decoration:none">Colored by Color Scripter</a></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>— Flask로 부터 넘겨 받은 결과 이미지를 받아서 출력 </p></li></ul><p><br></p><h4 id="3-Neural-Style-Transfer-수행-코드-작성"><a href="#3-Neural-Style-Transfer-수행-코드-작성" class="headerlink" title="3) Neural Style Transfer 수행 코드 작성"></a>3) Neural Style Transfer 수행 코드 작성</h4><p>전체 코드는 <a href="https://github.com/jaehyeongAN/PyFlask_DL-service/blob/master/flask_deep/neural_style_transfer.py" target="_blank" rel="noopener">github</a> 참조 </p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div><div style="line-height:130%">4</div><div style="line-height:130%">5</div><div style="line-height:130%">6</div><div style="line-height:130%">7</div><div style="line-height:130%">8</div><div style="line-height:130%">9</div><div style="line-height:130%">10</div><div style="line-height:130%">11</div><div style="line-height:130%">12</div><div style="line-height:130%">13</div><div style="line-height:130%">14</div><div style="line-height:130%">15</div><div style="line-height:130%">16</div><div style="line-height:130%">17</div><div style="line-height:130%">18</div><div style="line-height:130%">19</div><div style="line-height:130%">20</div><div style="line-height:130%">21</div><div style="line-height:130%">22</div><div style="line-height:130%">23</div><div style="line-height:130%">24</div><div style="line-height:130%">25</div><div style="line-height:130%">26</div><div style="line-height:130%">27</div><div style="line-height:130%">28</div><div style="line-height:130%">29</div><div style="line-height:130%">30</div><div style="line-height:130%">31</div><div style="line-height:130%">32</div><div style="line-height:130%">33</div><div style="line-height:130%">34</div><div style="line-height:130%">35</div><div style="line-height:130%">36</div><div style="line-height:130%">37</div><div style="line-height:130%">38</div><div style="line-height:130%">39</div><div style="line-height:130%">40</div><div style="line-height:130%">41</div><div style="line-height:130%">42</div><div style="line-height:130%">43</div><div style="line-height:130%">44</div><div style="line-height:130%">45</div><div style="line-height:130%">46</div><div style="line-height:130%">47</div><div style="line-height:130%">48</div><div style="line-height:130%">49</div><div style="line-height:130%">50</div><div style="line-height:130%">51</div><div style="line-height:130%">52</div><div style="line-height:130%">53</div><div style="line-height:130%">54</div><div style="line-height:130%">55</div><div style="line-height:130%">56</div><div style="line-height:130%">57</div><div style="line-height:130%">58</div><div style="line-height:130%">59</div><div style="line-height:130%">60</div><div style="line-height:130%">61</div><div style="line-height:130%">62</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">def</span>&nbsp;preprocess_image(image_path):</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;load_img(image_path,&nbsp;target_size<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>(img_height,&nbsp;img_width))&nbsp;<span style="color:#999999">#&nbsp;(400,&nbsp;381)</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;img_to_array(img)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;(400,&nbsp;381,&nbsp;3)</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;np.expand_dims(img,&nbsp;axis<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#c10aff">0</span>)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;(1,&nbsp;400,&nbsp;381,&nbsp;3)</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;vgg19.preprocess_input(img)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#ff3399">return</span>&nbsp;img&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;(&nbsp;중략&nbsp;)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">def</span>&nbsp;main(refer_img_path,&nbsp;target_img_path):</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;style_reference_image_path&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">'flask_deep/static/'</span><span style="color:#0086b3"></span><span style="color:#ff3399">+</span>&nbsp;refer_img_path</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;target_image_path&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">'flask_deep/static/'</span><span style="color:#0086b3"></span><span style="color:#ff3399">+</span>&nbsp;target_img_path</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;모든&nbsp;이미지를&nbsp;fixed-size(400pixel)로&nbsp;변경</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;width,&nbsp;height&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;load_img(target_image_path).size</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;global&nbsp;img_height;&nbsp;global&nbsp;img_width;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;img_height&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#c10aff">400</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;img_width&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#4be6fa">int</span>(width&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">*</span>&nbsp;img_height&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">/</span>&nbsp;height)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;target_image&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;K.constant(preprocess_image(target_image_path))&nbsp;<span style="color:#999999">#&nbsp;creates&nbsp;img&nbsp;to&nbsp;a&nbsp;constant&nbsp;tensor</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;style_reference_image&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;K.constant(preprocess_image(style_reference_image_path))</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;combination_image&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;K.placeholder((<span style="color:#c10aff">1</span>,&nbsp;img_height,&nbsp;img_width,&nbsp;<span style="color:#c10aff">3</span>))&nbsp;<span style="color:#999999">#&nbsp;생성된&nbsp;이미지를&nbsp;담을&nbsp;placeholder</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;3개의&nbsp;이미지를&nbsp;하나의&nbsp;배치로&nbsp;합침</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;input_tensor&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;K.concatenate([target_image,&nbsp;style_reference_image,&nbsp;combination_image],&nbsp;axis<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#c10aff">0</span>)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;3개&nbsp;이미지의&nbsp;배치를&nbsp;입력으로&nbsp;받는&nbsp;VGGNet&nbsp;생성</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;model&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;vgg19.VGG19(input_tensor<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>input_tensor,&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;weights<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#ffd500">'imagenet'</span>,&nbsp;<span style="color:#999999">#&nbsp;pre-trained&nbsp;ImageNet&nbsp;가중치&nbsp;로드&nbsp;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;include_top<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#4be6fa">False</span>)&nbsp;<span style="color:#999999">#&nbsp;FC&nbsp;layer&nbsp;제외&nbsp;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;(&nbsp;중략&nbsp;)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;evaluator&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;Evaluator()</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;refer_img_name&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;refer_img_path.split(<span style="color:#ffd500">'.'</span>)[<span style="color:#c10aff">0</span>].split(<span style="color:#ffd500">'/'</span>)[<span style="color:#0086b3"></span><span style="color:#ff3399">-</span><span style="color:#c10aff">1</span>]</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;result_prefix&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">'flask_deep/static/images/nst_result_'</span><span style="color:#0086b3"></span><span style="color:#ff3399">+</span>refer_img_name</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;iterations&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#c10aff">30</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;뉴럴&nbsp;스타일&nbsp;트랜스퍼의&nbsp;손실을&nbsp;최소화하기&nbsp;위해&nbsp;생성된&nbsp;이미지에&nbsp;대해&nbsp;L-BFGS&nbsp;최적화를&nbsp;수행</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;preprocess_image(target_image_path)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;x.flatten()</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#ff3399">for</span>&nbsp;i&nbsp;<span style="color:#ff3399">in</span>&nbsp;<span style="color:#4be6fa">range</span>(iterations):</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;start_time&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;time.time()</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x,&nbsp;min_val,&nbsp;info&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;fmin_l_bfgs_b(evaluator.loss,&nbsp;x,</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fprime<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>evaluator.grads,&nbsp;maxfun<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#c10aff">20</span>)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;생성된&nbsp;현재&nbsp;이미지를&nbsp;저장</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;x.copy().reshape((img_height,&nbsp;img_width,&nbsp;<span style="color:#c10aff">3</span>))</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;deprocess_image(img)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;fname&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;result_prefix&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">+</span>&nbsp;<span style="color:#ffd500">'.png'</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;end_time&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;time.time()</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;save_img(fname,&nbsp;img)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#ff3399">return</span>&nbsp;fname</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">if</span>&nbsp;__name__&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">"__main__"</span>:</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;main()</div></div><div style="text-align:right;margin-top:-13px;margin-right:5px;font-size:9px;font-style:italic"><a href="http://colorscripter.com/info#e" target="_blank" style="color:#4f4f4ftext-decoration:none">Colored by Color Scripter</a></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p><br></p><h4 id="4-Flask-app-파일-생성"><a href="#4-Flask-app-파일-생성" class="headerlink" title="4) Flask app 파일 생성"></a>4) Flask app 파일 생성</h4><p>Flask 애플리케이션 실행을 위한 _<em>init_<em>.py 파일을 생성한다. 여기서 Flask 파라미터로 전달되는 __name\</em></em> 파라미터는 Flask 애플리케이션을 구분하기 위한 구분자로 사용된다.<br>app.debug 를 True로 지정할 경우 코드 수정 시 바로바로 디버깅이 가능하게 해준다.</p><p>@app.route는 페이지 URL과 함수를 연결해주는 역할을 하며 아래와 같이 @app.route 데코레이터 지정 후 render_template(‘URL’)을 통해 연결할 페이지 경로를 입력하면 해당 경로를 웹 브라우저로 전달해주게 된다. </p><ul><li><p>_<em>init_</em>.py</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div><div style="line-height:130%">4</div><div style="line-height:130%">5</div><div style="line-height:130%">6</div><div style="line-height:130%">7</div><div style="line-height:130%">8</div><div style="line-height:130%">9</div><div style="line-height:130%">10</div><div style="line-height:130%">11</div><div style="line-height:130%">12</div><div style="line-height:130%">13</div><div style="line-height:130%">14</div><div style="line-height:130%">15</div><div style="line-height:130%">16</div><div style="line-height:130%">17</div><div style="line-height:130%">18</div><div style="line-height:130%">19</div><div style="line-height:130%">20</div><div style="line-height:130%">21</div><div style="line-height:130%">22</div><div style="line-height:130%">23</div><div style="line-height:130%">24</div><div style="line-height:130%">25</div><div style="line-height:130%">26</div><div style="line-height:130%">27</div><div style="line-height:130%">28</div><div style="line-height:130%">29</div><div style="line-height:130%">30</div><div style="line-height:130%">31</div><div style="line-height:130%">32</div><div style="line-height:130%">33</div><div style="line-height:130%">34</div><div style="line-height:130%">35</div><div style="line-height:130%">36</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">import</span>&nbsp;os,&nbsp;sys</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">from</span>&nbsp;flask&nbsp;<span style="color:#ff3399">import</span>&nbsp;Flask,&nbsp;escape,&nbsp;request,&nbsp;&nbsp;Response,&nbsp;g,&nbsp;make_response</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">from</span>&nbsp;flask.templating&nbsp;<span style="color:#ff3399">import</span>&nbsp;render_template</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">from</span>&nbsp;werkzeug&nbsp;<span style="color:#ff3399">import</span>&nbsp;secure_filename</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">from</span>&nbsp;.&nbsp;<span style="color:#ff3399">import</span>&nbsp;neural_style_transfer</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">app&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;Flask(__name__)</div><div style="padding:0 6px; white-space:pre; line-height:130%">app.debug&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#4be6fa">True</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#999999">#&nbsp;Main&nbsp;page</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">@app.route(<span style="color:#ffd500">'/'</span>)</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">def</span>&nbsp;index():</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#ff3399">return</span>&nbsp;render_template(<span style="color:#ffd500">'index.html'</span>)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">@app.route(<span style="color:#ffd500">'/nst_get'</span>)</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">def</span>&nbsp;nst_get():</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#ff3399">return</span>&nbsp;render_template(<span style="color:#ffd500">'nst_get.html'</span>)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">@app.route(<span style="color:#ffd500">'/nst_post'</span>,&nbsp;methods<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>[<span style="color:#ffd500">'GET'</span>,<span style="color:#ffd500">'POST'</span>])</div><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">def</span>&nbsp;nst_post():</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#ff3399">if</span>&nbsp;request.method&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">'POST'</span>:</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;Reference&nbsp;Image</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;refer_img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;request.form[<span style="color:#ffd500">'refer_img'</span>]</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;refer_img_path&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">'static/images/'</span><span style="color:#0086b3"></span><span style="color:#ff3399">+</span><span style="color:#4be6fa">str</span>(refer_img)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;User&nbsp;Image&nbsp;(target&nbsp;image)</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;user_img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;request.files[<span style="color:#ffd500">'user_img'</span>]</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;user_img.save(<span style="color:#ffd500">'./flask_deep/static/images/'</span><span style="color:#0086b3"></span><span style="color:#ff3399">+</span><span style="color:#4be6fa">str</span>(user_img.filename))</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;user_img_path&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">'./static/images/'</span><span style="color:#0086b3"></span><span style="color:#ff3399">+</span><span style="color:#4be6fa">str</span>(user_img.filename)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#999999">#&nbsp;Neural&nbsp;Style&nbsp;Transfer&nbsp;</span></div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transfer_img&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;neural_style_transfer.main(refer_img_path,&nbsp;user_img_path)</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transfer_img_path&nbsp;<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>&nbsp;<span style="color:#ffd500">'./static/images/'</span><span style="color:#0086b3"></span><span style="color:#ff3399">+</span><span style="color:#4be6fa">str</span>(transfer_img.split(<span style="color:#ffd500">'/'</span>)[<span style="color:#0086b3"></span><span style="color:#ff3399">-</span><span style="color:#c10aff">1</span>])</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#ff3399">return</span>&nbsp;render_template(<span style="color:#ffd500">'nst_post.html'</span>,&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;refer_img<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>refer_img_path,&nbsp;user_img<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>user_img_path,&nbsp;transfer_img<span style="color:#0086b3"></span><span style="color:#ff3399">=</span>transfer_img_path)</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>— index에서 nst_get 링크 클릭 시 nst_get.html로 경로 이동<br>— nst_get.html에서 POST방식을 통해 전달받은 이미지를 nst_post 함수에서 request 메소드를 통해 넘겨받음<br>— reference 이미지와 user 이미지 경로를 neural style transfer를 수행하는 딥러닝 메소드로 전달<br>— neural style transfer 딥러닝 코드에서 모델 수행 후 받은 결과값을 nst_post.html로 전달 </p></li></ul><p><br></p><h2 id="3-웹-실행"><a href="#3-웹-실행" class="headerlink" title="3. 웹 실행"></a>3. 웹 실행</h2><h4 id="1-Flask-서버-실행"><a href="#1-Flask-서버-실행" class="headerlink" title="1) Flask 서버 실행"></a>1) Flask 서버 실행</h4><p>Flask 서버 실행을 위해 프로젝트 폴더 상위에 아래와 같은 파이썬 코드를 생성하였다.</p><div class="colorscripter-code" style="color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important; position:relative !important;overflow:auto"><table class="colorscripter-code-table" style="margin:0;padding:0;border:none;background-color:#272727;border-radius:4px;" cellspacing="0" cellpadding="0"><tr><td style="padding:6px;border-right:2px solid #4f4f4f"><div style="margin:0;padding:0;word-break:normal;text-align:right;color:#aaa;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="line-height:130%">1</div><div style="line-height:130%">2</div><div style="line-height:130%">3</div></div></td><td style="padding:6px 0;text-align:left"><div style="margin:0;padding:0;color:#f0f0f0;font-family:Consolas, 'Liberation Mono', Menlo, Courier, monospace !important;line-height:130%"><div style="padding:0 6px; white-space:pre; line-height:130%"><span style="color:#ff3399">from</span>&nbsp;pyflask&nbsp;<span style="color:#ff3399">import</span>&nbsp;app</div><div style="padding:0 6px; white-space:pre; line-height:130%">&nbsp;</div><div style="padding:0 6px; white-space:pre; line-height:130%">app.run(host<span style="color:#0086b3"></span><span style="color:#ff3399">=</span><span style="color:#ffd500">'127.0.0.1'</span>)</div></div></td><td style="vertical-align:bottom;padding:0 2px 4px 0"><a href="http://colorscripter.com/info#e" target="_blank" style="text-decoration:none;color:white"><span style="font-size:9px;word-break:normal;background-color:#4f4f4f;color:white;border-radius:10px;padding:1px">cs</span></a></td></tr></table></div><p>위 코드는 _<em>init_</em>.py에서 app 애플리케이션을 실행하게 해주며, 위 파이썬 파일 실행 시 아래와 같이 flask 서버가 실행되게 된다. 이후 브라우저에서 <a href="http://127.0.0.1:5000" target="_blank" rel="noopener">http://127.0.0.1:5000</a> 입력 시 위에서 만든 화면을 확인할 수 있다.</p><p><img src="/image/flask_run.JPG"></p><h4 id="2-웹-화면"><a href="#2-웹-화면" class="headerlink" title="2) 웹 화면"></a>2) 웹 화면</h4><ul><li><p>메인 페이지<br><img src="/image/flask_index.JPG"></p></li><li><p>사용자 입력 페이지<br><img src="/image/flask_get.JPG"></p></li><li><p>결과 출력 페이지<br><img src="/image/flask_result.JPG"></p></li></ul><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>Flask는 이번에 간단한 애플리케이션을 적용해보기 위해서 처음 사용해보았다. 이전에 Spring 프레임워크를 통해 프로젝트를 해본 적은 있는데 사용안하지 너무 오래되다보니 까먹기도 했고 환경 구성하는 것도 일이어서 좀 가벼운 Flask를 사용해보게 되었다.</p><p>일단 기본적으로 html/css 그리고 python만 기초적으로 알아도 누구나 쉽고 간단하게 웹 화면을 구성해볼 수 있다는 장점이 있는 것 같다. 근데 확실히 큰 프로젝트 성으로 여러사람이 복잡한 화면을 구성할 때는 작업 관리가 쉽지 않을 것 같다는 생각이 든다. 시간나면 Django도 공부해봐야할 것 같다. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;Java의 Spring처럼 Python에서도 웹 프레임워크를 제공한다. 그 중 가장 인기 있는 것이 Dj
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="flask" scheme="https://jaehyeongan.github.io/tags/flask/"/>
    
      <category term="webframework" scheme="https://jaehyeongan.github.io/tags/webframework/"/>
    
      <category term="webdevelopment" scheme="https://jaehyeongan.github.io/tags/webdevelopment/"/>
    
      <category term="django" scheme="https://jaehyeongan.github.io/tags/django/"/>
    
      <category term="neuralstyletransfer" scheme="https://jaehyeongan.github.io/tags/neuralstyletransfer/"/>
    
  </entry>
  
  <entry>
    <title>R-CNN(Regions with CNN features) 논문 리뷰</title>
    <link href="https://jaehyeongan.github.io/2019/10/10/R-CNN/"/>
    <id>https://jaehyeongan.github.io/2019/10/10/R-CNN/</id>
    <published>2019-10-10T14:56:28.000Z</published>
    <updated>2020-12-10T14:54:43.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro "></a>Intro </h2><p>오늘은 초기 Object Detection 발전에 가장 많은 영향을 미친 논문인 Ross Girshick의 <a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">Rich feature hierarchies for accurate object detection and semantic segmentation</a> 즉, <strong>R-CNN</strong>에 대한 논문 리뷰를 간단히 하고자 한다.</p><p>우선 Obejct Detection이란 이미지가 무엇인지 판단하는 Classification과 이미지 내의 물체의 위치 정보를 찾는 Localization을 수행하는 것을 말한다. 이를 통해 영상 내의 객체가 사람인지 동물인지 물건인지 등을 구별하여 각 객체가 어디에 위치하는지 표시하는 것이 가능하다. </p><hr><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>지난 몇 년 동안 <em>PASCAL VOC</em> 데이터셋에서 Object Detection의 가장 좋은 성능을 내는 것은 high-level context의 복잡한 앙상블 모델이었다. 하지만 이 논문에서는 VOC 2012 데이터를 기준으로 이전 모델에 비해 mAP(mean average precision)가 30%이상 향상된 더 간단하고 확장 가능한 detection 알고리즘을 소개하였다.<br>이 알고리즘은 크게 두 가지 핵심 인사이트를 가지고 있는데 다음과 같다.</p><blockquote><ol><li>객체를 localize 및 segment하기 위해 bottom-up방식의 region proposal(지역 제안)에  Convolutional Neural Network를 적용</li><li>domain-specific fine-tuning을 통한 supervised pre-training을 적용</li></ol></blockquote><p>저자는 해당 모델을 R-CNN(Regions with CNN features)이라고 명시하였으며, 그 이유는 CNN과 Region proposal이 결합되었기 때문이라고 한다. </p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>지난 10년간 다양한 visual recognition 작업에서는 주로 <em>SIFT와 HOG(gradient 기반의 특징점 추출 알고리즘)</em>가 가장 많이 사용되었는데, 이는 2010 ~ 2012년의 PASCAL VOC obeject detection에서 일반적으로 인정되는 방법이었다. 하지만 이후 back-propagation이 가능한 SGD(Stochastic Gradient Descent)기반의 CNN(Convolutional Neural Networks)이 등장하기 시작하였고 SIFT와 HOG와 같은 알고리즘과 비교하여 PASCAL VOC object detection에서 굉장한 성능을 보이게 되었다.<br>Image Classification과 다르게 detection은 이미지내에서 객체를 localizing하는 것이 요구되는데 이를 위해, 논문의 모델은 sliding-window 방식을 적용하였고, 높은 공간 해상도(high spartial resolution)을 유지하기 위해 5개의 Convolutional 레이어를 적용하였다.<br>우선 간단하게 R-CNN은 아래와 같은 프로세스로 작동한다.<br><img src="/image/rcnn.JPG" width="800"></p><blockquote><p><strong>R-CNN 프로세스</strong></p><ol><li>Input 이미지로부터 2,000개의 독립적인 region proposal을 생성</li><li>CNN을 통해 각 proposal 마다 고정된 길이의 feature vector를 추출(CNN 적용 시 서로 다른 region shape에 영향을 받지 않기 위해 fixed-size로 이미지를 변경)</li><li>이후, 각 region 마다 category-specific linear SVM을 적용하여 classification을 수행</li></ol></blockquote><p><br></p><h2 id="2-Object-detection-with-R-CNN"><a href="#2-Object-detection-with-R-CNN" class="headerlink" title="2. Object detection with R-CNN"></a>2. Object detection with R-CNN</h2><p>이 논문의 object detection은 크게 3가지 모듈로 구성되어 있다.</p><p><strong>1. category-independent한 region proposals를 생성</strong><br><strong>2. 각 region으로부터 feature vector를 추출하기 위한 large CNN</strong><br><strong>3. classification을 위한 linear SVMs</strong><br>이제 아래에서 본격적으로 각 모듈에 대해 설명하고 PASCAL VOC2010-12에 대한 결과를 소개한다.<br><br></p><h3 id="Region-proposals"><a href="#Region-proposals" class="headerlink" title="Region proposals"></a>Region proposals</h3><p>카테고리 독립적인 region proposal을 생성하기 위한 방법은 여러가지가 있는데 해당 논문에서는 이전 detection 작업들과 비교하기 위하여 <strong>Selective Search</strong>라는 최적의 region proposal를 제안하는 기법을 사용하여 독립적인 region proposal을 추출하였다. selective search는 아래와 같은 프로세스로 이루어진다.</p><blockquote><p><strong>Selective Search</strong></p><ol><li>이미지의 초기 세그먼트를 정하여, 수많은 region 영역을 생성</li><li>greedy 알고리즘을 이용하여 각 region을 기준으로 주변의 유사한 영역을 결합</li><li>결합되어 커진 region을 최종 region proposal로 제안 </li></ol></blockquote><p><br></p><h3 id="Feature-extraction"><a href="#Feature-extraction" class="headerlink" title="Feature extraction"></a>Feature extraction</h3><p>우선 위에서 언급한 Selective Search를 통해 도출 된 각 region proposal로부터 CNN을 사용하여 4096차원의 feature vector를 추출한다. 이후, feature들은 5개의 convolutional layer와 2개의 fully connected layer로 전파되는데, 이때 CNN의 입력으로 사용되기 위해 각 region은 227x227 RGB의 고정된 사이즈로 변환되게 된다.</p><p><img src="/image/rcnn2.JPG" width="600"><br><br></p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>학습에 사용되는 CNN 모델의 경우 ILSVRC 2012 데이터 셋으로 미리 학습된 <strong>pre-trained CNN(AlexNet)</strong>모델을 사용한다.<br><br></p><h3 id="Domain-specific-fine-tuning"><a href="#Domain-specific-fine-tuning" class="headerlink" title="Domain-specific fine-tuning"></a>Domain-specific fine-tuning</h3><p>Classification에 최적화된 CNN 모델을 새로운 Detection 작업 그리고 VOC 데이터셋에 적용하기 위해 오직 VOC의 region proposals를 통해 SGD(stochastic gradient descent)방식으로 CNN 파라미터를 업데이트 한다. 이후 CNN을 통해 나온 feature map은 SVM을 통해 classification 및 bounding regreesion이 진행되게 되는데, 여기서 SVM 학습을 위해 NMS(non-maximum suppresion)과 IoU(inter-section-over-union)이라는 개념이 활용된다. </p><p>IoU는 Area of Overlap(교집합) / Area of Union(합집합)으로 계산되며, 간단히 말해 전체 bounding box 영역 중 겹치는 부분의 비율을 나타내는데 NMS 알고리즘이 이 IoU 점수를 활용하여 겹치는 박스를 모두 제거하고 가장 적합한 박스만 남기게 된다. NMS의 과정을 간단히 살펴보면 아래와 같은 프로세로 진행된다.</p><blockquote><p><strong>NMS(Non-maximum suppresion)</strong></p><ol><li>예측한 bounding box들의 예측 점수를 내림차순으로 정렬</li><li>높은 점수의 박스부터 시작하여 나머지 박스들 간의 IoU를 계산</li><li>IoU값이 지정한 threhold보다 높은 박스를 제거</li><li>최적의 박스만 남을 떄까지 위 과정을 반복</li></ol></blockquote><p>해당 논문에서는 SVM 학습을 위한 라벨로서 IoU를 활용하였고 IoU 가 0.5이상인 것들을 positive 객체로 보고 나머지는 negative로 분류하여 학습하게 된다. 각 SGD iteration마다 32개의 positive window와 96개의 backgroud window 총 128개의 배치로 학습이 진행된다.</p><p><img src="/image/rcnn3.png" width="450"></p><p><br></p><h2 id="3-Results-on-PASCAL-VOC-2010-12"><a href="#3-Results-on-PASCAL-VOC-2010-12" class="headerlink" title="3. Results on PASCAL VOC 2010-12"></a>3. Results on PASCAL VOC 2010-12</h2><p><img src="/image/rcnn4.JPG" width="1000"></p><p>위 테이블은 VOC 2010 테스트 데이터에 대한 각 모델별 결과이다. 맨 오른쪽에서 mAP를 확인할 수 있는데, 논문에서는 결과를 비교하는데 같은 region proposal 알고리즘을 적용한 UVA모델과 mAP를 비교한다.<br>위 표를 보면 UVA 모델의 mAP는 35.1%이고, R-CNN의 mAP는 <strong>53.7%</strong>인 것을 확인할 수 있으며 이것은 높은 증가율이라고 저자는 말한다. 또한 VOC 2011/12 데이터 셋 또한 53.3% mAP 높은 성능을 나타냈다.<br><br></p><h2 id="4-Problems"><a href="#4-Problems" class="headerlink" title="4. Problems"></a>4. Problems</h2><p>R-CNN의 가장 큰 문제는 복잡한 프로세스로 인한 과도한 연상량에 있다. 최근에는 고성능 GPU가 많이 보급 되었기 때문에 deep한 neural net이라도 GPU연산을 통해 빠른 처리가 가능하다. 하지만 R-CNN은  selective search 알고리즘를 통한 region proposal 작업 그리고 NMS 알고리즘 작업 등은 CPU 연산에 의해 이루어 지기 때문에 굉장히 많은 연산량 및 시간이 소모된다.<br>또한  SVM  예측 시 region에 대한 classification  및 bounding box에 대한 regression 작업이 함께 작동하다 보니 모델 예측 부분에서도 연산 및 시간이 많이 소모되어 real-time 분석이 어렵다는 단점이 있다. </p><p>R-CNN의 이러한 한계들로 인해, 추후 프로세스 및 연산 측면에서 보완된 모델이 나오게 되는데 그것이 바로 <a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">Fast R-CNN</a>과 <a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">Faster R-CNN</a>이다. </p><p><img src="/image/rcnn_time.png" width="600"></p><p>위 그림은 R-CNN, SPP-Net, Fast R-CNN, Faster R-CNN의 실행 속도 차이를 나타내는데 Faster R-CNN이 이전 모델보다 비교가 안될 정도로 훠얼씬 빠르다는 것을 알 수 있다. (성능도 더 좋아졌다.)<br>아래에서 Fast R-CNN과 Faster R-CNN에 대해 간단하게 집고 넘어가 보도록 한다.</p><p><br></p><h2 id="5-Fast-R-CNN-amp-Faster-R-CNN"><a href="#5-Fast-R-CNN-amp-Faster-R-CNN" class="headerlink" title="5. Fast R-CNN &amp; Faster R-CNN"></a>5. Fast R-CNN &amp; Faster R-CNN</h2><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p><img src="/image/fastrcnn.JPG" width="600"><br>Fast R-CNN의 R-CNN의 문제를 해결하기 위해 나온 모델이다.<br>동작 방식은 R-CNN과 유사하게 region proposal이 작동하지만, RCNN과 다르게 <strong>Fast R-CNN은 먼저 전체 이미지가 ConvNet의 input으로 입력이 된다.</strong> 이미지는 ConvNet을 통과하며 feature map을 추출하게 되고, 이 feature map은 selectice search 기반의 region proposal을 통해 RoI(Regions of Interest)를 뽑아낸다. </p><p>이후 선택 된 Region들은 RoI Pooling layer를 거치게 되는데, 이 과정은 추후 예측을 위해 region들을 다운 사이즈하여 모두 같은 고정된 크기로 변환해주는 역할을 한다. 마지막 과정으로  fully connected layer를 거치며 Softmax Classification과 Bounding Box Regression이 수행된다. </p><p>위의 과정은 하나의 ConvNet모델에 의해 동시에 수행이 되기 때문에 RCNN에 비하여 훨씬 빠르게 작동하는 장점이 있다. 하지만 결국 Fast RCNN 또한 많은 연산을 필요로 하는 Selective Search 기법이 작동을 하므로 큰 데이터 셋에 적용하는데는 한계가 있다.</p><p><br></p><h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p><img src="/image/fasterrcnn.JPG" width="500"><br>Faster R-CNN은 R-CNN과 Fast R-CNN이 region proposal로 인한 과도한 연산 문제를 해결하기 위해 나온 모델이다. 기존 region proposal에 사용되었던 selective search는 연산량을 늘리고 시간을 많이 소모하는 주요 원인이었다. 그래서 Faster R-CNN에서는 selective search 알고리즘을 없애고 <strong>Region Proposal Networks(RPN)</strong>라는 뉴럴 네트워크를 추가하여 region proposal을 예측하도록 했다.  </p><p>그 후, 예측된 region proposal은 Fast R-CNN과 유사하게 RoI Pooling layer를 거치며 모든 region을 같은 크기로 고정 후, Classification 및 Bounding Box Regreesion이 수행된다.</p><p><br></p><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>paper</p><ul><li>R-Rich feature hierarchies for accurate object detection and semantic segmentation(<a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">https://arxiv.org/abs/1311.2524</a>)</li><li>Fast R-CNN(<a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">https://arxiv.org/abs/1504.08083</a>)</li><li>Faster R-CNN(<a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">https://arxiv.org/abs/1506.01497</a>)</li></ul><p>blog</p><ul><li><a href="https://reniew.github.io/10/" target="_blank" rel="noopener">https://reniew.github.io/10/</a></li><li><a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e" target="_blank" rel="noopener">https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e</a><br><a href="https://blog.lunit.io/2017/06/01/r-cnns-tutorial/" target="_blank" rel="noopener">https://blog.lunit.io/2017/06/01/r-cnns-tutorial/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro &quot;&gt;&lt;/a&gt;Intro &lt;/h2&gt;&lt;p&gt;오늘은 초기 Object Detection 발전에 가장 많은 영향을 미친 논문인 Ross Girshi
      
    
    </summary>
    
    
      <category term="selectivesearch" scheme="https://jaehyeongan.github.io/tags/selectivesearch/"/>
    
      <category term="rcnn" scheme="https://jaehyeongan.github.io/tags/rcnn/"/>
    
      <category term="fastrcnn" scheme="https://jaehyeongan.github.io/tags/fastrcnn/"/>
    
      <category term="fasterrcnn" scheme="https://jaehyeongan.github.io/tags/fasterrcnn/"/>
    
      <category term="nms" scheme="https://jaehyeongan.github.io/tags/nms/"/>
    
      <category term="regionproposals" scheme="https://jaehyeongan.github.io/tags/regionproposals/"/>
    
      <category term="iou" scheme="https://jaehyeongan.github.io/tags/iou/"/>
    
      <category term="voc" scheme="https://jaehyeongan.github.io/tags/voc/"/>
    
  </entry>
  
  <entry>
    <title>합성곱 신경망(ConvNet, Convolutional Neural Network)</title>
    <link href="https://jaehyeongan.github.io/2019/09/23/basic-convnet/"/>
    <id>https://jaehyeongan.github.io/2019/09/23/basic-convnet/</id>
    <published>2019-09-23T14:18:01.000Z</published>
    <updated>2020-12-10T14:50:21.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro "></a>Intro </h2><p>현재 ConvNet 기반의 모델은 단순 이미지 인식을 넘어 Object Detection, Semantic Segmentation 까지 딥러닝 알고리즘 중 가장 활발히 연구되고 성과를 내고 있는 분야이다. 우선 각 분야별 적용되고 있는 주요 모델을 간단히 살펴보면 아래와 같다.</p><blockquote><div class="table-container"><table><thead><tr><th>Classification</th><th>Image Detection</th><th>Semantic Segentation</th></tr></thead><tbody><tr><td>VGG Net</td><td>RCNN</td><td>FCN</td></tr><tr><td>GoogLeNet</td><td>Fast RCNN</td><td>DeepLab</td></tr><tr><td>ResNet</td><td>Faster RCNN</td><td>U-Net</td></tr><tr><td>MobileNet</td><td>YOLO</td><td>ReSeg</td></tr><tr><td>ShuffleNet</td><td>SDD</td></tr></tbody></table></div></blockquote><p>이 글에서는 위의 훌륭한 모델들이 가장 기본으로 하는 ConvNet의 구조 및 학습 방법에 대해 간단히 알려보려고 한다.</p><hr><h2 id="합성곱-신경망-Convolutional-Neural-Network-ConvNet"><a href="#합성곱-신경망-Convolutional-Neural-Network-ConvNet" class="headerlink" title="합성곱 신경망(Convolutional Neural Network, ConvNet)"></a>합성곱 신경망(Convolutional Neural Network, ConvNet)</h2><p>합성곱 신경망은 합성곱 연산을 사용하는 신경망 중 하나로서, 주로 음성 인식이나 시각적 이미지를 분석하는데 사용된다. 합성곱 신경망이 일반 신경망과 다른 점은 일반적인 신경망들이 이미지 데이터를 원본 그대로 1차원 신경망인 Fully-Connected layer(FC layer 혹은 Dense layer)에 입력되어 전체 특성을 학습하고 처리하는 데 반해, <strong>합성곱 신경망은 FC layer를 거치기 전에 Convolution 및 Poolling과 같은 데이터의 주요 특징 벡터를 추출하는 과정을 거친 후 FC layer로 입력되게 된다.</strong><br>그렇기 때문에 대부분의 이미지 인식 분야는 딥러닝 기반의 합성곱 신경망이 주를 이루고 있다.<br><br></p><h2 id="ConvNet의-구조"><a href="#ConvNet의-구조" class="headerlink" title="ConvNet의 구조"></a>ConvNet의 구조</h2><p><img src="/image/convnet.jpg" width="700"></p><p>합성곱 신경망은 기본적으로 위와 같은 구조로 이루어져 있다. 위 ConvNet을 크게 3덩어리로 짤라서 보면 아래와 같다.</p><blockquote><p><strong><em>1. Input layer</em></strong><br><strong><em>2. Convolutional layer ~ Max pooling layer</em></strong><br><strong><em>3. Fully-connected layer ~ Output layers로</em></strong></p></blockquote><p>위 구조를 간단히 설명하면 위에서도 말했듯이 ConvNet은 단순 FC Layer로만 구성되어 있지 않다. Convolutional Layer와 Pooling Layer라는 과정을 거치게 되는데 이는 Input Image의 주요 특징 벡터를 추출하는 과정이라고 할 수 있다. 그 후 이렇게 추출된 주요 특징 벡터들은 그제야 FC Layer를 거치며 1차원 벡터로 변환되고 마지막 Output layer에서 활성화 함수인 Softmax함수를 통해 각 해당 클래스의 확률로 출력되게 된다. 아래에서 각 과정을 좀 더 상세히 살펴보겠다.<br><br></p><h3 id="1-Input-Layer"><a href="#1-Input-Layer" class="headerlink" title="1. Input Layer"></a>1. Input Layer</h3><p>Input Layer는 입력된 이미지 데이터가 최초로 거치게 되는 Layer이다. 모두가 알고 있듯이 이미지는 단순 1차원의 데이터가 아니다. 이미지는 기본적으로 <strong><em>(높이, 넓이, 채널)</em></strong>의 크기를 갖는 3차원의 크기를 가지며, 여기서 채널(channels)의 경우 Gray Scale(1)이냐 RGB(3)이냐 에 따라 크기가 달라지게 된다. (채널의 컬러 공간은 Gray, RGB, HSV, CMYK 등 다양하다)<br><img src="/image/cnn_img_shape.png" width="550"></p><p>위와 같은 형태는 높이 4, 넓이 4, 채널 RGB를 갖고 있으므로 위 이미지의 shape은 (4, 4, 3)으로 표현할 수 있으며, </p><p><img src="/image/mnist_shape.png" width="150"><br>이미지 인식의 교과서라 할 수 있는 위 MNIST 손글씨 데이터 셋의 경우 높이 28, 넓이 28, 채널 Gray를 가지고 있으므로 (28, 28, 1)의 shape을 가졌다고 말할 수 있다. 또한 다른 말로 특성 맵(Feature Map)이라고도 한다.<br><br></p><h3 id="2-Convolutional-Layer"><a href="#2-Convolutional-Layer" class="headerlink" title="2. Convolutional Layer"></a>2. Convolutional Layer</h3><p>Convolutional Layer와 FC Layer의 경우 근본적은 차이가 존재하는데, Dense 층의 경우 특성 공간에 있는 전역 패턴(입력된 이미지의 모든 픽셀에 걸친 패턴)을 학습하는 반면 합성곱 층의 경우 지역 패턴을 학습하게 된다.</p><h4 id="2-1-kernel"><a href="#2-1-kernel" class="headerlink" title="2.1 kernel"></a>2.1 kernel</h4><p>Convolutional Layer에서는 Input Image의 크기인 특성 맵(Feature Map)을 입력으로 받게 되는데 지역 패턴 학습을 위하여 이러한 특성 맵에  <strong>커널(kernel) 혹은 필터(Filter)</strong>라 불리는 정사각 행렬을 적용하며 합성곱 연산을 수행하게 된다.<br>커널의 경우 3 x 3, 5 x 5크기로 적용되는 것이 일반적이며 <strong>스트라이드(Stride)</strong>라고 불리는 지정된 간격에 따라 순차적으로 이동하게 된다.<br><img src="/image/cnn_kernel.gif" width="500"></p><p>위 그림의 경우 Image의 크기는 (5, 5, 1)의 크기를 가지고 있으며, 현재 3 x 3크기의 kernel이 1 Stride의 간격으로 이동하며 합성곱 연산을 수행하는 것을 보여준다. 만약 커널이 2개의 크기만큼 이동하고 있다면 2 Stride 간격으로 이동한다고 할 수 있다. </p><p>이렇게 커널은 스트라이드 간격만큼 순회하며 모든 채널의 합성곱의 합을 새로운 특성 맵으로 만들게 되며, 결국 위 그림의 경우 커널과 스트라이드의 상호작용으로 인해 원본 (5, 5, 1) 크기의 Feature Map아 (3, 3, 1)크기의 Feature Map의 크기로 줄어들게 되었다.</p><blockquote><p><strong><em>커널과 스트라이드의 경우 크기가 클 수 록 좀더 빨리 이미지를 처리할 수 있지만, 넓은 특성을 큰 보폭으로 이동하는 만큼 주요 특성을 놓칠 수 있다는 단점이 존재한다.</em></strong></p></blockquote><p><br></p><h4 id="2-2-Padding"><a href="#2-2-Padding" class="headerlink" title="2.2 Padding"></a>2.2 Padding</h4><p>합성곱 연산을 수행할 경우 단점이 존재하는데, 바로 위에서 살펴보았듯이 kernel과 stride의 작용으로 인해 원본 크기가 줄어든다는 것이다. 따라서 이렇게 Feature Map의 크기가 작아지는 것을 방지하기 위해서 Padding이란 기법을 이용하게 되는데, 쉽게 말해 단순히 원본 이미지에 0이라는 padding값을 채워 넣어 이미지를 확장한 후 합성곱 연산을 적용하는 것을 말한다. </p><p><img src="/image/cnn_padding.gif" width="400"></p><p>위 그림을 보면 위에서 살펴본 바와 같이 똑같은 (5, 5, 1)크기의 이미지 데이터가 놓여있다. 다른 점은 사방으로 빈 공간(0)이 1칸씩 더 채워져 있다는 것인데 이것이 바로 padding이다. 이후 위와 똑같은 3 x 3 크기의 커널을 적용하게 되는데 출력되는 feature map의 크기는 (3, 3, 1)이 아닌 원본 이미지와 똑같은 (5, 5, 1)크기의 feature map이다. </p><p>이렇듯, <strong>원본 이미지의 크기를 줄이지 않으면서 합성곱 연산을 수행가능하게 해주는 것이 바로 padding의 역할</strong>이라고 할 수 있다.<br><br></p><h4 id="2-3-ReLU-Activation-Function"><a href="#2-3-ReLU-Activation-Function" class="headerlink" title="2.3 ReLU Activation Function"></a>2.3 ReLU Activation Function</h4><p>합성곱 연산을 거친 Feature Map은 활성화 함수를 거치게 되는데, 많은 활성화 함수 중 가장 널리 사용되고 있는 것은 ReLU 함수 이다.</p><p><img src="/image/cnn_sigmoid_relu.png" width="500"></p><p>일반적으로 Sigmoid 함수의 경우 값을 0 ~ 1사이로 정규화시키는데 레이어가 깊어질 수 록 0.xxx의 값이 계속 미분되게 되면 값이 점차 0으로 수렴하게 되어 결국 weight값이 희미해지는 gradient vanishing문제가 발생하게 된다.<br>하지만 ReLU의 경우 0미만의 값은 0으로 출력하고 0이상의 값은 그대로 출력하기 때문에 이러한 문제에 덜 민감하고 그렇기 때문에 깊은 레이어에서도 효율적인 역전파(Back Propagation)가 가능하다. </p><p>이러한 이유로 합성곱 연산을 통해 출력된 feature map의 경우 일반적으로 ReLU 활성화 함수를 거치게 되며, ReLU 함수가 양의 값만을 활성화하며 특징을 좀 더 두드러지게 표현해주게 된다.<br><br></p><h3 id="3-Pooling-Layer"><a href="#3-Pooling-Layer" class="headerlink" title="3. Pooling Layer"></a>3. Pooling Layer</h3><p>Convolutional Layer와 유사하게 feature map의 차원을 다운 샘플링하여 연산량을 감소시키고 주요한 특징 벡터를 추출하여 학습을 효과적으로 하는 것이 pooling layer의 역할이라고 할 수 있다. </p><p>풀링 연산에는 대표적으로 두 가지가 사용된다.</p><ul><li><strong>Max Pooling : 각 커널에서 다루는 이미지 패치에서 최대값을 추출</strong></li><li><strong>Average Pooling: 각 커널에서 다루는 이미지 패치에서 모든 값의 평균을 반환</strong><br><img src="/image/cnn_pooling.png" width="600"></li></ul><p>하지만 대부분의 ConvNet에서는 Avg Pooling이 아닌 <strong><em>Max Pooling</em></strong>이 사용된다. Avg Pooling의 경우 각 커널의 값을 평균화시키기 때문에 주요한 가중치를 갖는 value의 특성이 희미해질 수 있는 문제가 있기 때문이다. </p><p>또한 Pooling 사이즈의 경우 Stride와 같은 크기로 설정하여 모든 원소가 한번씩 처리되도록 하는것이 일반적이며, <strong>보통 Max Pooling의 경우 2 x 2커널과 2 stride를 사용하여 feature map을 절반 크기로 다운샘플링하게 된다.</strong><br><br></p><h3 id="4-Fully-Connected-Layer"><a href="#4-Fully-Connected-Layer" class="headerlink" title="4. Fully Connected Layer"></a>4. Fully Connected Layer</h3><p>위에서 설명한 Convolutional Layer - ReLU Activation Function - Pooling Layer의 과정을 거치며 차원이 축소 된 feature map은 최종적으로 Fully Connected Layer라는 완전 연결 층으로 전달되게 된다. </p><p><img src="/image/cnn_fclayer.png" width="500"></p><p>이 부분에서는 이미지의 <strong>3차원 벡터는 1차원으로 Flatten</strong>되게 되고 신경망에서 흔히 사용되는 활성화 함수(relu)와 함께 Output Layer로 학습이 진행된다.<br><strong>Output Layer는 Softmax 활성화 함수</strong>가 사용되는데, Softmax 함수는 입력받은 값을 모두 0 ~ 1사이의 값으로 정규화하하고 이렇게 정규화된 값들의 총합은 항상 1이되는 특성을 가지는 함수이다.</p><blockquote><p><img src="/image/cnn_softmax.png" width="430"></p></blockquote><p>따라서 마지막 Output layer의 softmax함수를 통해 이미지가 각 레이블에 속할 확률값이 레이블마다 각각 출력되게 되고 이중 가장 높은 확률값을 가지는 레이블이 최종 예측치로 선정되게 된다.<br><br></p><h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><ul><li><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" target="_blank" rel="noopener">https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53</a></li><li><a href="https://sonofgodcom.wordpress.com/2018/12/31/cnn%EC%9D%84-%EC%9D%B4%ED%95%B4%ED%95%B4%EB%B3%B4%EC%9E%90-fully-connected-layer%EB%8A%94-%EB%AD%94%EA%B0%80/" target="_blank" rel="noopener">https://sonofgodcom.wordpress.com/2018/12/31/cnn%EC%9D%84-%EC%9D%B4%ED%95%B4%ED%95%B4%EB%B3%B4%EC%9E%90-fully-connected-layer%EB%8A%94-%EB%AD%94%EA%B0%80/</a></li><li><a href="https://medium.com/dataseries/basic-overview-of-convolutional-neural-network-cnn-4fcc7dbb4f17" target="_blank" rel="noopener">https://medium.com/dataseries/basic-overview-of-convolutional-neural-network-cnn-4fcc7dbb4f17</a></li><li><a href="https://de-novo.org/2018/05/27/convnet-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/" target="_blank" rel="noopener">https://de-novo.org/2018/05/27/convnet-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/</a></li><li><a href="https://reniew.github.io/10/" target="_blank" rel="noopener">https://reniew.github.io/10/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro &quot;&gt;&lt;/a&gt;Intro &lt;/h2&gt;&lt;p&gt;현재 ConvNet 기반의 모델은 단순 이미지 인식을 넘어 Object Detection, Seman
      
    
    </summary>
    
    
      <category term="cnn" scheme="https://jaehyeongan.github.io/tags/cnn/"/>
    
      <category term="image" scheme="https://jaehyeongan.github.io/tags/image/"/>
    
      <category term="deeplearing" scheme="https://jaehyeongan.github.io/tags/deeplearing/"/>
    
      <category term="convnet" scheme="https://jaehyeongan.github.io/tags/convnet/"/>
    
      <category term="convolutional" scheme="https://jaehyeongan.github.io/tags/convolutional/"/>
    
      <category term="kernel" scheme="https://jaehyeongan.github.io/tags/kernel/"/>
    
      <category term="padding" scheme="https://jaehyeongan.github.io/tags/padding/"/>
    
      <category term="maxpooling" scheme="https://jaehyeongan.github.io/tags/maxpooling/"/>
    
      <category term="relu" scheme="https://jaehyeongan.github.io/tags/relu/"/>
    
  </entry>
  
  <entry>
    <title>[Kaggle] 분자 특성 예측(Predicting Molecular Properties)</title>
    <link href="https://jaehyeongan.github.io/2019/09/06/molecular-prediction/"/>
    <id>https://jaehyeongan.github.io/2019/09/06/molecular-prediction/</id>
    <published>2019-09-06T14:20:52.000Z</published>
    <updated>2021-02-07T14:57:14.051Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>최근 kaggle에서 굉장히 눈에 띄는 competition이 있었으니 바로, <a href="https://www.kaggle.com/c/champs-scalar-coupling" target="_blank" rel="noopener"><strong>Predicting Molecular Properties</strong></a>라는 이름의 대회였다. 해당 competition은 브리스톨 대학교, 카디프 대학교, 임페리얼 칼리지 및 리즈 대학교로 이루어진 <em>CHAMPS(CHemistry And Mathematics in Phase Space)</em> 에 의해 주최되었으며, 수상하는 팀에게는 대학 연구 프로그램과 협력할 수 있는 기회가 주어진다고 한다. </p><p align="center"><img src="/image/kaggle_molecular.JPG" width="700"></p><h4 id="예측-대상"><a href="#예측-대상" class="headerlink" title="예측 대상"></a>예측 대상</h4><p>우선 해당 대회의 도전과제는 소제목 및 Description을 통해 파악할 수 있다.</p><blockquote><p><strong><em>Can you measure the magnetic interactions between a pair of atoms?</em></strong><br><strong><em>In this competition, you will develop an algorithm that can predict the magnetic interaction between two atoms in a molecule</em></strong></p></blockquote><p>이번 대회를 통해 우리가 예측 해야 하는 것은 바로 분자 설계 시 한 쌍의 원자 간 결합으로 인해 발생하는 <strong>결합상수(Coupling Constant)</strong>를 예측하는 것이다.<br>결합 상수라는 것은 물리적 상호작용(여기서는 원자 간)의 세기를 나타내는 상수로서, 결합상수가 1일 때 완전결합이라고 한다. 아래에서 좀 더 자세히 살펴보겠지만, 제공되는 데이터에는 분자 및 원자에 대한 정보가 있으며 두 원자 간의 결합상수가 target value로 존재하고 있다. </p><h4 id="학습-전략"><a href="#학습-전략" class="headerlink" title="학습 전략"></a>학습 전략</h4><p>처음 제공된 데이터를 보았을 때 train, test 외에 추가로 제공되는 데이터를 어떻게 활용해야 할지 난감했다. 그 이유는 structures 데이터를 제외하고는 모두 train 데이터에 대한 정보 밖에 없었기 떄문이다. 모델을 학습하고 예측할 때 당연히 train set과 test set의 차원의 크기가 같아야 했기 때문에 train에 대한 정보만 있는 데이터를 활용하는 것이 의미가 없다고 판단되었다. 그래서 최대한 활용할 수 있는 데이터만 사용하였으며 몇 가지 파생변수를 만들어 부족한 차원을 채워주었다.</p><p>모델 학습을 위해서는 <strong><em>LightGBM</em></strong>이라는 최근 캐글에서 가장 인기 있는 Gradient Boosting 기반의 모델을 사용하였다. 해당 데이터에는 <em>type</em> 이라는 분자의 타입을 구분하는 칼럼이 존재하는데, 처음 모델을 만들 때는 type 구분 없이 전체를 학습시켰으나 성능이 기대만큼 잘 나오지 않았다. 그래서 feature를 늘려야 하나 고민하던 중 우연히 Nanashi라는 사람의 <a href="https://www.kaggle.com/jesucristo/single-lgbm-2-242-top54" target="_blank" rel="noopener">kernel</a>에서 전체 분자를 학습시키지 않고 분자의 type별로 따로 학습 및 예측을 진행하는 것을 보게 되었다. score를 보니 상당히 높은 score를 가지고 있었고 시도해볼 만 한 가치가 있다고 판단되어 이번 모델에 벤치마킹하여 적용하였다.</p><h4 id="평가-방법"><a href="#평가-방법" class="headerlink" title="평가 방법"></a>평가 방법</h4><p>이번 대회에서는 Evaluation을 위해 평균절대오차(MAE, Mean Absolute Error)에 log값을 씌운 점수로 평가를 진행하게 된다. 공식 metric은 아래와 같으며, 완벽하게 예측했을 때 최종 점수는 -20.7232이다.</p><blockquote><p><img src="/image/molecular-metric.JPG" alt="png"></p></blockquote><hr><p><em>!코드 작성은 Jupyter lab을 이용하였으며, 아래 작성된 코드는 ipynb파일을 markdown으로 변환 후 업로드한 것이다.</em><br><br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line"><span class="comment"># path</span></span><br><span class="line">path_dir = <span class="string">'C:/Users/USER/.kaggle/competitions/champs-scalar-coupling/'</span></span><br><span class="line">file_list = os.listdir(path_dir)</span><br><span class="line">file_list</span><br></pre></td></tr></table></figure><p><em>[‘dipole_moments.csv’,<br> ‘magnetic_shielding_tensors.csv’,<br> ‘mulliken_charges.csv’,<br> ‘potential_energy.csv’,<br> ‘sample_submission.csv’,<br> ‘scalar_coupling_contributions.csv’,<br> ‘structures.csv’,<br> ‘structures.zip’,<br> ‘test.csv’,<br> ‘train.csv’]</em></p><p><br></p><h2 id="1-Load-Train-Test-Data"><a href="#1-Load-Train-Test-Data" class="headerlink" title="1. Load Train/Test Data"></a>1. Load Train/Test Data</h2><p><strong>Columns</strong></p><ul><li>molecule_name : 분자 이름 </li><li>atom_index_0 / atom_index_1 : 원자 인덱스</li><li>type</li><li>Coupling Constant(결합상수) : 물리적 상호작용(여기서는 원자 간)의 세기를 나타내는 상수, 결합상수가 1일때 완전결합이라고 함</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_df = pd.read_csv(path_dir+<span class="string">'train.csv'</span>)</span><br><span class="line">test_df = pd.read_csv(path_dir+<span class="string">'test.csv'</span>)   <span class="comment"># target = 'scalar_coupling_constant'</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Length of train set: &#123;&#125;'</span>.format(len(train_df)))</span><br><span class="line">print(<span class="string">'Length of test set: &#123;&#125;'</span>.format(len(test_df)))</span><br></pre></td></tr></table></figure><p><em>Length of train set: 4658147</em><br><em>Length of test set: 2505542</em></p><p><br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Unique molecule of train set: &#123;&#125;'</span>.format(len(train_df[<span class="string">'molecule_name'</span>].unique())))</span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure><p><em>Unique molecule of train set: 85003</em><br><img src="/image/molecular-tb1.JPG" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Unique molecule of test set: &#123;&#125;'</span>.format(len(test_df[<span class="string">'molecule_name'</span>].unique())))</span><br><span class="line">test_df.head()</span><br></pre></td></tr></table></figure><p><em>Unique molecule of test set: 45772</em><br><img src="/image/molecular-tb2.JPG" alt="png"></p><p><br></p><h2 id="2-EDA"><a href="#2-EDA" class="headerlink" title="2. EDA"></a>2. EDA</h2><h4 id="2-1-Distribution-of-Target-‘scalar-coupling-constant’"><a href="#2-1-Distribution-of-Target-‘scalar-coupling-constant’" class="headerlink" title="2.1 Distribution of Target (‘scalar_coupling_constant’)"></a>2.1 Distribution of Target (‘scalar_coupling_constant’)</h4><ul><li>Min Value : -36.2186</li><li>Max Value : 204.88</li><li>대부분이 -20 ~ +20 사이에 존재</li><li>작은 분포로 80 ~ 100 사이에 존재</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Distribution of target</span></span><br><span class="line">print(<span class="string">'Min Value of Target : &#123;&#125;'</span>.format(train_df[<span class="string">'scalar_coupling_constant'</span>].min()))</span><br><span class="line">print(<span class="string">'Max Value of Target : &#123;&#125;'</span>.format(train_df[<span class="string">'scalar_coupling_constant'</span>].max()))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">11</span>, <span class="number">5</span>))</span><br><span class="line">sns.distplot(train_df[<span class="string">'scalar_coupling_constant'</span>])</span><br><span class="line">plt.title(<span class="string">'Distribution of scalar_coupling_constant'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><em>Min Value of Target : -36.2186</em><br><em>Max Value of Target : 204.88</em></p><p><img src="/image/molecular_output_7_1.png" alt="png"></p><h4 id="2-2-Distribution-of-‘scalar-coupling-constant’-by-type"><a href="#2-2-Distribution-of-‘scalar-coupling-constant’-by-type" class="headerlink" title="2.2 Distribution of ‘scalar_coupling_constant’ by type"></a>2.2 Distribution of ‘scalar_coupling_constant’ by type</h4><ul><li>‘1JHC’ type이 상대적으로 높은 scalar coupling 범위에 분포(+66.6 ~ +204.8) </li><li>‘2JHH’ type이 상대적으로 낮은 scalar coupling 범위에 분포(-35.1 ~ +11.8</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Distribution of 'scalar_coupling_constant' by type</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">13</span>))</span><br><span class="line"><span class="keyword">for</span> i, t <span class="keyword">in</span> enumerate(train_df[<span class="string">'type'</span>].unique()):</span><br><span class="line">    plt.subplot(<span class="number">4</span>,<span class="number">2</span>, i+<span class="number">1</span>)</span><br><span class="line">    sns.distplot(train_df[train_df[<span class="string">'type'</span>] == t][<span class="string">'scalar_coupling_constant'</span>])</span><br><span class="line">    plt.title(<span class="string">'Distribution of coupling constant by type '</span>+ t)</span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular_output_9_0.png" alt="png"></p><h4 id="2-3-Count-by-‘type’"><a href="#2-3-Count-by-‘type’" class="headerlink" title="2.3 Count by ‘type’"></a>2.3 Count by ‘type’</h4><ul><li>3JHC, 2JHC, 1JHC, 3JHH, 2JHH, 3JHN, 2JHN, 1JHN 순서로 높음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Count by 'type'</span></span><br><span class="line">type_index = train_df[<span class="string">'type'</span>].value_counts().index</span><br><span class="line">type_cnt = train_df[<span class="string">'type'</span>].value_counts()</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">11</span>, <span class="number">4</span>))</span><br><span class="line">sns.barplot(x=type_index, y=type_cnt)</span><br><span class="line">plt.xlabel(<span class="string">'type'</span>); plt.ylabel(<span class="string">'Count'</span>)</span><br><span class="line">plt.title(<span class="string">'Count by type'</span>)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular_output_11_0.png" alt="png"></p><h4 id="2-4-Count-by-atom-index-0-1"><a href="#2-4-Count-by-atom-index-0-1" class="headerlink" title="2.4 Count by atom index 0, 1"></a>2.4 Count by atom index 0, 1</h4><ul><li>atom index 0의 경우 9 ~ 18번이 가장 많이 분포</li><li>atom index 1의 경우 1 ~ 8번이 가장 많이 분포</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Count by atom index 0, 1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>]:</span><br><span class="line">    atom_index = train_df[<span class="string">'atom_index_'</span>+str(i)].value_counts().index</span><br><span class="line">    atom_cnt = train_df[<span class="string">'atom_index_'</span>+str(i)].value_counts()</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(<span class="number">11</span>, <span class="number">4</span>))</span><br><span class="line">    sns.barplot(x=atom_index, y=atom_cnt)</span><br><span class="line">    plt.xlabel(<span class="string">'atom index '</span>+str(i)); plt.ylabel(<span class="string">'Count'</span>)</span><br><span class="line">    plt.title(<span class="string">'Count by atom index '</span>+str(i))</span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular_output_13_0.png" alt="png"></p><p><img src="/image/molecular_output_13_1.png" alt="png"></p><p><br></p><h2 id="3-Load-Structures-Data"><a href="#3-Load-Structures-Data" class="headerlink" title="3. Load Structures Data"></a>3. Load Structures Data</h2><p><strong>Columns</strong></p><ul><li>molecule_name</li><li>atom_index</li><li>atom</li><li>x, y, z axis of atom</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">structures_df = pd.read_csv(path_dir+<span class="string">'structures.csv'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Length of test set: &#123;&#125;'</span>.format(len(structures_df)))</span><br><span class="line">structures_df.head()</span><br></pre></td></tr></table></figure><p><strong>Length of test set: 2358657</strong><br><img src="/image/molecular-tb3.JPG" alt="png"></p><h4 id="3-1-3Dimension-plot-by-Molecule"><a href="#3-1-3Dimension-plot-by-Molecule" class="headerlink" title="3.1. 3Dimension plot by Molecule"></a>3.1. 3Dimension plot by Molecule</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> structures_df[<span class="string">'molecule_name'</span>].unique()[:<span class="number">4</span>]:</span><br><span class="line">    structures_molecule =structures_df[structures_df[<span class="string">'molecule_name'</span>] == name]</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line">    ax.scatter(structures_molecule[<span class="string">'x'</span>], structures_molecule[<span class="string">'y'</span>], structures_molecule[<span class="string">'z'</span>], s=<span class="number">200</span>, edgecolors=<span class="string">'white'</span>)</span><br><span class="line">    ax.set_title(str(name)+ <span class="string">' 3D plot'</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">'x'</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">'y'</span>)</span><br><span class="line">    ax.set_zlabel(<span class="string">'z'</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular_output_17_0.png" alt="png"></p><p><img src="/image/molecular_output_17_1.png" alt="png"></p><p><img src="/image/molecular_output_17_2.png" alt="png"></p><p><img src="/image/molecular_output_17_3.png" alt="png"></p><p><br></p><h2 id="4-Preprocessing"><a href="#4-Preprocessing" class="headerlink" title="4. Preprocessing"></a>4. Preprocessing</h2><h4 id="4-1-Merge-Train-amp-Test-Structures-Data"><a href="#4-1-Merge-Train-amp-Test-Structures-Data" class="headerlink" title="4.1. Merge Train&amp;Test - Structures Data"></a>4.1. Merge Train&amp;Test - Structures Data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapping_atom_index</span><span class="params">(df, atom_idx)</span>:</span></span><br><span class="line">    atom_idx = str(atom_idx)</span><br><span class="line">    df = pd.merge(df, structures_df,</span><br><span class="line">                  left_on  = [<span class="string">'molecule_name'</span>, <span class="string">'atom_index_'</span>+atom_idx],</span><br><span class="line">                  right_on = [<span class="string">'molecule_name'</span>,  <span class="string">'atom_index'</span>],</span><br><span class="line">                 how = <span class="string">'left'</span>)</span><br><span class="line">    </span><br><span class="line">    df = df.drop(<span class="string">'atom_index'</span>, axis=<span class="number">1</span>)</span><br><span class="line">    df = df.rename(columns=&#123;<span class="string">'atom'</span>: <span class="string">'atom_'</span>+atom_idx,</span><br><span class="line">                            <span class="string">'x'</span>: <span class="string">'x_'</span>+atom_idx,</span><br><span class="line">                            <span class="string">'y'</span>: <span class="string">'y_'</span>+atom_idx,</span><br><span class="line">                            <span class="string">'z'</span>: <span class="string">'z_'</span>+atom_idx&#125;)</span><br><span class="line">    <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_merge = mapping_atom_index(train_df, <span class="number">0</span>)</span><br><span class="line">train_merge = mapping_atom_index(train_merge, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">test_merge = mapping_atom_index(test_df, <span class="number">0</span>)</span><br><span class="line">test_merge = mapping_atom_index(test_merge, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_tmp = train_merge[[<span class="string">'id'</span>,<span class="string">'molecule_name'</span>,<span class="string">'type'</span>]]</span><br><span class="line">test_tmp = test_merge[[<span class="string">'id'</span>,<span class="string">'molecule_name'</span>,<span class="string">'type'</span>]]</span><br><span class="line"></span><br><span class="line">train_merge.head()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular-tb4.JPG" alt="png"></p><h4 id="4-2-Derived-variables-‘Distance’"><a href="#4-2-Derived-variables-‘Distance’" class="headerlink" title="4.2. Derived variables - ‘Distance’"></a>4.2. Derived variables - ‘Distance’</h4><ul><li>distance between <em>x axis</em> of atom index</li><li>distance between <em>y axis</em> of atom index</li><li>distance between <em>z axis</em> of atom index</li><li>distance between <em>atom</em></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist_between_atom</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="comment"># distance between axis of atom</span></span><br><span class="line">    df[<span class="string">'x_dist'</span>] = (df[<span class="string">'x_0'</span>] - df[<span class="string">'x_1'</span>])**<span class="number">2</span></span><br><span class="line">    df[<span class="string">'y_dist'</span>] = (df[<span class="string">'y_0'</span>] - df[<span class="string">'y_1'</span>])**<span class="number">2</span></span><br><span class="line">    df[<span class="string">'z_dist'</span>] = (df[<span class="string">'z_0'</span>] - df[<span class="string">'z_1'</span>])**<span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># distance between atom</span></span><br><span class="line">    df[<span class="string">'atom_dist'</span>] = (df[<span class="string">'x_dist'</span>]+df[<span class="string">'y_dist'</span>]+df[<span class="string">'z_dist'</span>])**<span class="number">0.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line">    </span><br><span class="line">train_dist = dist_between_atom(train_merge)</span><br><span class="line">test_dist = dist_between_atom(test_merge)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dist.head()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular-tb5.JPG" alt="png"></p><h4 id="4-3-Label-encoding"><a href="#4-3-Label-encoding" class="headerlink" title="4.3. Label encoding"></a>4.3. Label encoding</h4><ul><li>type, atom_0, atom_1</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Label encoding</span></span><br><span class="line">categorical_features = [<span class="string">'type'</span>, <span class="string">'atom_0'</span>, <span class="string">'atom_1'</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> categorical_features:</span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    le.fit(list(train_dist[col].values) + list(test_dist[col].values))</span><br><span class="line">    train_dist[col] = le.transform(list(train_dist[col].values))</span><br><span class="line">    test_dist[col] = le.transform(list(test_dist[col].values))</span><br><span class="line"></span><br><span class="line">train_le = train_dist.copy()</span><br><span class="line">test_le = test_dist.copy()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_le.head()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular-tb6.JPG" alt="png"></p><h4 id="4-4-Standardization"><a href="#4-4-Standardization" class="headerlink" title="4.4. Standardization"></a>4.4. Standardization</h4><ul><li>z = (x - u) / s</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train</span></span><br><span class="line">train_data = train_le.drop([<span class="string">'id'</span>,<span class="string">'molecule_name'</span>,<span class="string">'scalar_coupling_constant'</span>], axis=<span class="number">1</span>)</span><br><span class="line">train_target = train_le[<span class="string">'scalar_coupling_constant'</span>]</span><br><span class="line"><span class="comment"># test</span></span><br><span class="line">test_data = test_le.drop([<span class="string">'id'</span>,<span class="string">'molecule_name'</span>,], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># z-score standardization</span></span><br><span class="line">train_scale = (train_data - train_data.mean()) / train_data.std()</span><br><span class="line">train_scale = train_scale.fillna(<span class="number">0</span>)</span><br><span class="line">test_scale = (test_data - train_data.mean()) / train_data.std()</span><br></pre></td></tr></table></figure><h4 id="4-5-Variable-Correlations"><a href="#4-5-Variable-Correlations" class="headerlink" title="4.5. Variable Correlations"></a>4.5. Variable Correlations</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_corr = train_scale.copy()</span><br><span class="line">train_corr[<span class="string">'scalar_coupling_constant'</span>] = train_target</span><br><span class="line">corrmat = train_corr.corr()</span><br><span class="line">top_corr_features = corrmat.index[abs(corrmat[<span class="string">'scalar_coupling_constant'</span>]) &gt;= <span class="number">0.1</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">sns.heatmap(train_corr[top_corr_features].corr(), annot=<span class="keyword">True</span>, cmap=<span class="string">"RdYlGn"</span>)</span><br><span class="line">plt.title(<span class="string">'Variable Correlations'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular_output_33_0.png" alt="png"></p><h2 id="5-Training-Model"><a href="#5-Training-Model" class="headerlink" title="5. Training Model"></a>5. Training Model</h2><h4 id="5-1-Training-by-‘type’-through-LightGBM"><a href="#5-1-Training-by-‘type’-through-LightGBM" class="headerlink" title="5.1. Training by ‘type’ through LightGBM"></a>5.1. Training by ‘type’ through LightGBM</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_scale = train_scale.drop(<span class="string">'type'</span>, axis=<span class="number">1</span>)</span><br><span class="line">train_scale[<span class="string">'type'</span>] = train_tmp[<span class="string">'type'</span>]</span><br><span class="line">train_scale[<span class="string">'scalar_coupling_constant'</span>] = train_target</span><br><span class="line"></span><br><span class="line">test_scale = test_scale.drop(<span class="string">'type'</span>, axis=<span class="number">1</span>)</span><br><span class="line">test_scale[[<span class="string">'id'</span>, <span class="string">'type'</span>]] = test_tmp[[<span class="string">'id'</span>, <span class="string">'type'</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">score_by_type = []    <span class="comment"># List of Validation score by type </span></span><br><span class="line">feature_importance_df = []</span><br><span class="line">test_pred_df = pd.DataFrame(columns=[<span class="string">'id'</span>, <span class="string">'scalar_coupling_constant'</span>])   <span class="comment"># Dataframe for submission</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract data by type</span></span><br><span class="line">types = train_tmp[<span class="string">'type'</span>].unique()</span><br><span class="line"><span class="keyword">for</span> typ <span class="keyword">in</span> types:</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'---Type of '</span>+str(typ)+<span class="string">'---'</span>)</span><br><span class="line">    train = train_scale[train_scale[<span class="string">'type'</span>] == typ]</span><br><span class="line">    target = train[<span class="string">'scalar_coupling_constant'</span>]</span><br><span class="line">    train = train.drop([<span class="string">'type'</span>,<span class="string">'scalar_coupling_constant'</span>], axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Split train set / valid set</span></span><br><span class="line">    x_train, x_val, y_train, y_val = train_test_split(train, target, random_state=<span class="number">42</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># LightGBM</span></span><br><span class="line">    categorical_features = [<span class="string">'atom_0'</span>,<span class="string">'atom_1'</span>]</span><br><span class="line">    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)</span><br><span class="line">    lgb_val = lgb.Dataset(x_val, y_val, categorical_feature=categorical_features)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Parameters of LightGBM</span></span><br><span class="line">    params = &#123;<span class="string">'num_leaves'</span>: <span class="number">128</span>,</span><br><span class="line">              <span class="string">'min_child_samples'</span>: <span class="number">79</span>,</span><br><span class="line">              <span class="string">'objective'</span>: <span class="string">'regression'</span>,</span><br><span class="line">              <span class="string">'max_depth'</span>: <span class="number">9</span>,</span><br><span class="line">              <span class="string">'learning_rate'</span>: <span class="number">0.1</span>,</span><br><span class="line">              <span class="string">"boosting_type"</span>: <span class="string">"gbdt"</span>,</span><br><span class="line">              <span class="string">"subsample_freq"</span>: <span class="number">1</span>,</span><br><span class="line">              <span class="string">"subsample"</span>: <span class="number">0.9</span>,</span><br><span class="line">              <span class="string">"bagging_seed"</span>: <span class="number">11</span>,</span><br><span class="line">              <span class="string">"metric"</span>: <span class="string">'mae'</span>,</span><br><span class="line">              <span class="string">"verbosity"</span>: <span class="number">-1</span>,</span><br><span class="line">              <span class="string">'reg_alpha'</span>: <span class="number">0.13</span>,</span><br><span class="line">              <span class="string">'reg_lambda'</span>: <span class="number">0.36</span>,</span><br><span class="line">              <span class="string">'colsample_bytree'</span>: <span class="number">1.0</span></span><br><span class="line">             &#125;</span><br><span class="line">    <span class="comment"># Training</span></span><br><span class="line">    lgb_model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_val], </span><br><span class="line">                          num_boost_round=<span class="number">20000</span>,    <span class="comment"># Number of boosting iterations.</span></span><br><span class="line">                          early_stopping_rounds=<span class="number">500</span>,    <span class="comment"># early stopping for valid set</span></span><br><span class="line">                          verbose_eval=<span class="number">2500</span>)    <span class="comment"># eval metric on the valid set is printed at 1000 each boosting</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Feature Importances</span></span><br><span class="line">    feature_importance = lgb_model.feature_importance()</span><br><span class="line">    df_fi = pd.DataFrame(&#123;<span class="string">'columns'</span>:x_train.columns, <span class="string">'importances'</span>:feature_importance&#125;)</span><br><span class="line">    df_fi = df_fi[df_fi[<span class="string">'importances'</span>] &gt; <span class="number">0</span>].sort_values(by=[<span class="string">'importances'</span>], ascending=<span class="keyword">False</span>)</span><br><span class="line">    feature_importance_df.append(df_fi)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Predict Validation set</span></span><br><span class="line">    score_by_type.append(list(lgb_model.best_score[<span class="string">'valid_1'</span>].values()))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Predict Test set</span></span><br><span class="line">    test = test_scale[test_scale[<span class="string">'type'</span>] == typ]</span><br><span class="line">    test_id = test[<span class="string">'id'</span>]</span><br><span class="line">    test = test.drop([<span class="string">'id'</span>,<span class="string">'type'</span>], axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    test_preds = lgb_model.predict(test)</span><br><span class="line">    test_pred_df = pd.concat([test_pred_df, pd.DataFrame(&#123;<span class="string">'id'</span>:test_id, <span class="string">'scalar_coupling_constant'</span>:test_preds&#125;)], axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><em>—-Type of 1JHC—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 2.77031    valid_1’s l1: 3.67976<br>[5000]    training’s l1: 2.19648    valid_1’s l1: 3.59536<br>[7500]    training’s l1: 1.81083    valid_1’s l1: 3.56509<br>[10000]    training’s l1: 1.52513    valid_1’s l1: 3.55207<br>[12500]    training’s l1: 1.30189    valid_1’s l1: 3.54733<br>Early stopping, best iteration is:<br>[12398]    training’s l1: 1.31009    valid_1’s l1: 3.54716<br>—-Type of 2JHH—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 0.599486    valid_1’s l1: 0.930904<br>[5000]    training’s l1: 0.429952    valid_1’s l1: 0.920848<br>Early stopping, best iteration is:<br>[6444]    training’s l1: 0.363731    valid_1’s l1: 0.919744<br>—-Type of 1JHN—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 0.574269    valid_1’s l1: 1.869<br>Early stopping, best iteration is:<br>[2790]    training’s l1: 0.51238    valid_1’s l1: 1.86748<br>—-Type of 2JHN—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 0.493351    valid_1’s l1: 1.29156<br>[5000]    training’s l1: 0.245368    valid_1’s l1: 1.26562<br>[7500]    training’s l1: 0.136667    valid_1’s l1: 1.25931<br>[10000]    training’s l1: 0.0806357    valid_1’s l1: 1.25729<br>[12500]    training’s l1: 0.0501038    valid_1’s l1: 1.25649<br>[15000]    training’s l1: 0.0325061    valid_1’s l1: 1.25602<br>Early stopping, best iteration is:<br>[16603]    training’s l1: 0.025108    valid_1’s l1: 1.25588<br>—-Type of 2JHC—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 1.45707    valid_1’s l1: 1.78894<br>[5000]    training’s l1: 1.22333    valid_1’s l1: 1.74951<br>[7500]    training’s l1: 1.0595    valid_1’s l1: 1.734<br>[10000]    training’s l1: 0.931867    valid_1’s l1: 1.72621<br>[12500]    training’s l1: 0.827693    valid_1’s l1: 1.7222<br>[15000]    training’s l1: 0.740337    valid_1’s l1: 1.72091<br>[17500]    training’s l1: 0.665914    valid_1’s l1: 1.7203<br>Early stopping, best iteration is:<br>[17624]    training’s l1: 0.662523    valid_1’s l1: 1.72024<br>—-Type of 3JHH—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 0.750457    valid_1’s l1: 1.084<br>[5000]    training’s l1: 0.549578    valid_1’s l1: 1.04283<br>[7500]    training’s l1: 0.427516    valid_1’s l1: 1.02508<br>[10000]    training’s l1: 0.343351    valid_1’s l1: 1.01595<br>[12500]    training’s l1: 0.281535    valid_1’s l1: 1.01117<br>[15000]    training’s l1: 0.234395    valid_1’s l1: 1.00805<br>[17500]    training’s l1: 0.197292    valid_1’s l1: 1.00612<br>[20000]    training’s l1: 0.167506    valid_1’s l1: 1.00516<br>Did not meet early stopping. Best iteration is:<br>[20000]    training’s l1: 0.167506    valid_1’s l1: 1.00516<br>—-Type of 3JHC—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 1.14564    valid_1’s l1: 1.35361<br>[5000]    training’s l1: 0.957949    valid_1’s l1: 1.28948<br>[7500]    training’s l1: 0.830959    valid_1’s l1: 1.2569<br>[10000]    training’s l1: 0.735763    valid_1’s l1: 1.23707<br>[12500]    training’s l1: 0.65866    valid_1’s l1: 1.22372<br>[15000]    training’s l1: 0.594712    valid_1’s l1: 1.2142<br>[17500]    training’s l1: 0.540621    valid_1’s l1: 1.2074<br>[20000]    training’s l1: 0.493743    valid_1’s l1: 1.20232<br>Did not meet early stopping. Best iteration is:<br>[20000]    training’s l1: 0.493743    valid_1’s l1: 1.20232<br>—-Type of 3JHN—-<br>Training until validation scores don’t improve for 500 rounds.<br>[2500]    training’s l1: 0.231975    valid_1’s l1: 0.513043<br>[5000]    training’s l1: 0.127354    valid_1’s l1: 0.502675<br>[7500]    training’s l1: 0.0764305    valid_1’s l1: 0.49964<br>[10000]    training’s l1: 0.0486108    valid_1’s l1: 0.498466<br>[12500]    training’s l1: 0.0325766    valid_1’s l1: 0.498049<br>[15000]    training’s l1: 0.0228697    valid_1’s l1: 0.497765<br>[17500]    training’s l1: 0.0167369    valid_1’s l1: 0.497581<br>[20000]    training’s l1: 0.0128106    valid_1’s l1: 0.497526<br>Did not meet early stopping. Best iteration is:<br>[20000]    training’s l1: 0.0128106    valid_1’s l1: 0.497526</em></p><h4 id="5-2-Validation-MAE-by-type"><a href="#5-2-Validation-MAE-by-type" class="headerlink" title="5.2. Validation MAE by type"></a>5.2. Validation MAE by type</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> typ, score <span class="keyword">in</span> zip(types, score_by_type):</span><br><span class="line">    print(<span class="string">'Type &#123;&#125; valid MAE  : &#123;&#125;'</span>.format(str(typ), score))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'\nAverage of valid MAE  : &#123;&#125;'</span>.format(np.mean(score_by_type)))</span><br></pre></td></tr></table></figure><p><em>Type 1JHC valid MAE  : [3.5471584407190475]<br>Type 2JHH valid MAE  : [0.9197439377103146]<br>Type 1JHN valid MAE  : [1.8674786631630775]<br>Type 2JHN valid MAE  : [1.255876548899015]<br>Type 2JHC valid MAE  : [1.7202390170123096]<br>Type 3JHH valid MAE  : [1.0051635344922942]<br>Type 3JHC valid MAE  : [1.2023186835296467]<br>Type 3JHN valid MAE  : [0.4975260038664571]</em></p><p><em>Average of valid MAE  : 1.5019381036740203</em><br><br>    </p><h4 id="5-3-Feature-Importances-Plot-by-Type"><a href="#5-3-Feature-Importances-Plot-by-Type" class="headerlink" title="5.3. Feature Importances Plot by Type"></a>5.3. Feature Importances Plot by Type</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> typ, df_fi <span class="keyword">in</span> zip(types, feature_importance_df):</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">    ax = sns.barplot(df_fi[<span class="string">'columns'</span>], df_fi[<span class="string">'importances'</span>])</span><br><span class="line">    ax.set_xticklabels(df_fi[<span class="string">'columns'</span>], rotation=<span class="number">80</span>, fontsize=<span class="number">13</span>)</span><br><span class="line">    plt.title(<span class="string">'Type '</span>+str(typ)+<span class="string">' feature importance'</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/molecular_output_41_0.png" alt="png"></p><p><img src="/image/molecular_output_41_1.png" alt="png"></p><p><img src="/image/molecular_output_41_2.png" alt="png"></p><p><img src="/image/molecular_output_41_3.png" alt="png"></p><p><img src="/image/molecular_output_41_4.png" alt="png"></p><p><img src="/image/molecular_output_41_5.png" alt="png"></p><p><img src="/image/molecular_output_41_6.png" alt="png"></p><p><img src="/image/molecular_output_41_7.png" alt="png"></p><h4 id="5-4-Save-prediction-of-test-set-to-csv"><a href="#5-4-Save-prediction-of-test-set-to-csv" class="headerlink" title="5.4. Save prediction of test set to *.csv"></a>5.4. Save prediction of test set to *.csv</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_pred_df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/image/molecular-tb7.JPG" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_pred_df.to_csv(<span class="string">'lgb_submission.csv'</span>, index=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><p><br></p><h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><p><em>kaggle kernels</em></p><ul><li><a href="https://www.kaggle.com/jesucristo/single-lgbm-2-242-top54" target="_blank" rel="noopener">https://www.kaggle.com/jesucristo/single-lgbm-2-242-top54</a></li><li><a href="https://www.kaggle.com/super13579/simple-eda-and-lightgbm" target="_blank" rel="noopener">https://www.kaggle.com/super13579/simple-eda-and-lightgbm</a></li><li><a href="https://www.kaggle.com/artgor/molecular-properties-eda-and-models" target="_blank" rel="noopener">https://www.kaggle.com/artgor/molecular-properties-eda-and-models</a></li></ul><p><em>blog/docs</em></p><ul><li><a href="https://gorakgarak.tistory.com/1285" target="_blank" rel="noopener">https://gorakgarak.tistory.com/1285</a></li><li><a href="https://towardsdatascience.com/understanding-gradient-boosting-machines-using-xgboost-and-lightgbm-parameters-3af1f9db9700" target="_blank" rel="noopener">https://towardsdatascience.com/understanding-gradient-boosting-machines-using-xgboost-and-lightgbm-parameters-3af1f9db9700</a></li><li><a href="https://lightgbm.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://lightgbm.readthedocs.io/en/latest/</a></li></ul><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>처음 예측 모델을 위해서 Neural Net을 이용하였었는데 default parameter의 Random Forest 알고리즘보다도 훨씬 낮은 성능을 보였다. 어느 글에서 말하길, 딥러닝이 항상 좋은 성능을 내지 않는다고 한다.<br>이런 Structured tabular 형태의 데이터에 neural net은 over-fitting 하는 경우가 많으며, 거의 대부분의 경우 <strong>xgboost</strong>나 <strong>lightgbm</strong>과 같은 gradient boosting 계열의 알고리즘이 잘 작동한다고 한다.(파라미터값을 잘 optimize 했을 때..)</p><p>앞으로 gbm 계열의 알고리즘에 대해 좀더 공부해봐야할 것 같다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;최근 kaggle에서 굉장히 눈에 띄는 competition이 있었으니 바로, &lt;a href=&quot;https
      
    
    </summary>
    
    
      <category term="kaggle" scheme="https://jaehyeongan.github.io/tags/kaggle/"/>
    
      <category term="molecular" scheme="https://jaehyeongan.github.io/tags/molecular/"/>
    
      <category term="atom" scheme="https://jaehyeongan.github.io/tags/atom/"/>
    
      <category term="couplingconstant" scheme="https://jaehyeongan.github.io/tags/couplingconstant/"/>
    
      <category term="competitions" scheme="https://jaehyeongan.github.io/tags/competitions/"/>
    
      <category term="lightgbm" scheme="https://jaehyeongan.github.io/tags/lightgbm/"/>
    
      <category term="eda" scheme="https://jaehyeongan.github.io/tags/eda/"/>
    
  </entry>
  
  <entry>
    <title>데이터 분석을 위한 기초 시각화 with Python</title>
    <link href="https://jaehyeongan.github.io/2019/08/13/Basic-Visualization-Analytics/"/>
    <id>https://jaehyeongan.github.io/2019/08/13/Basic-Visualization-Analytics/</id>
    <published>2019-08-13T14:00:16.000Z</published>
    <updated>2020-12-10T14:50:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>데이터를 분석하려는데 데이터의 row와 columns 수가 많은 수백 차원 데이터의 경우 데이터를 파악하기가 쉽지 않다. 그렇기에 인간이 이해할 수 있는 정도의 차원으로 줄여 데이터를 개략적으로 파악하는 것이 필요하고, 역시 인간은 읽고, 듣는 것 보다는 눈으로 보는게 확실히 기억에 오래남고 이해하기 쉽기 때문에 데이터를 시각화하여 분석하는 것이 필요하다.</p><p>이번에는 데이터 분석에 앞서 기초적이지만 필수적으로 살펴보아 할 시각화 방법에 대해 살펴볼 것이며, 목록은 아래와 같다.</p><blockquote><ul><li><em>변수 별 데이터 분포(Data Distribution)</em></li><li><em>타겟 별 2차원 및 3차원 시각화(2D and 3D plot)</em></li><li><em>변수 간 상관관계(Corrleation)</em></li><li><em>변수 중요도(Featrue Importances)</em></li></ul></blockquote><hr><p>예제로 사용 할 데이터로 <a href="https://www.kaggle.com/uciml/breast-cancer-wisconsin-data" target="_blank" rel="noopener">Breast Cancer Wisconsin Dataset</a>이다. 많이들 알다시피 유방암에 대해 양성/음성을 예측하기 위한 데이터셋이며, 총 569 row와 31 columns을 가지고 있다. </p><h2 id="0-Load-Data"><a href="#0-Load-Data" class="headerlink" title="0. Load Data"></a>0. Load Data</h2><p>우선 데이터를 로드 시킨 후 분석에 불필요한 칼럼은 제외시킨다.<br>데이터는 아래와 같은 형태로 되어 있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"></span><br><span class="line">cancer = pd.read_csv(<span class="string">'./input/data.csv'</span>)</span><br><span class="line">cancer.drop([<span class="string">'id'</span>,<span class="string">'Unnamed: 32'</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">cancer.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/image/cancer_head.JPG" width="1200"><br><br></p><p>이 데이터에서 예측해야하는 타겟 칼럼은 <strong>‘diagnosis’</strong>이며, ‘M’은 malignant로 양성을 의미하며, ‘B’는 Benign으로 음성을 의미한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cancer[<span class="string">'diagnosis'</span>].unique() <span class="comment"># array(['M', 'B'], dtype=object)</span></span><br></pre></td></tr></table></figure></p><p><br></p><h2 id="1-Column-distribution-by-target"><a href="#1-Column-distribution-by-target" class="headerlink" title="1. Column distribution by target"></a>1. Column distribution by target</h2><p>먼저 시각화 해 볼 것은 칼럼 별로 데이터 분포를 시각화해 보는 것이다. 이를 통해 각 칼럼 별로 데이터가 어떻게 분포되어 있는지를 파악할 수 있고, 우리가 예측하고자 하는 타겟(diagnosis)별로 분포가 어떻게 다르게 나타나는지도 파악이 가능하다. </p><p>seaborn의 distplot을 통해 타겟 칼럼인 diagnosis별로 6번째 칼럼까지만 출력해보았다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line">font_name = font_manager.FontProperties(fname=<span class="string">"c:/Windows/Fonts/malgun.ttf"</span>).get_name()</span><br><span class="line">rc(<span class="string">'font'</span>, family=font_name) <span class="comment"># 한글 출력 설정 부분</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> cnt, col <span class="keyword">in</span> enumerate(cancer):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">        sns.distplot(cancer[col][cancer[<span class="string">'diagnosis'</span>]==<span class="string">'M'</span>])</span><br><span class="line">        sns.distplot(cancer[col][cancer[<span class="string">'diagnosis'</span>]==<span class="string">'B'</span>])</span><br><span class="line">        plt.legend([<span class="string">'malignant'</span>,<span class="string">'benign'</span>], loc=<span class="string">'best'</span>)</span><br><span class="line">        plt.title(<span class="string">'histogram of features '</span>+str(col))</span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> cnt &gt;= <span class="number">6</span>: <span class="comment"># 6개 칼럼까지만 출력</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p><p><img src="/image/cancer_distplot.png" width="900"></p><p>위의 그림으로 보았을 때 radius_mean, area_mean, perimeter_mean 칼럼이 양성일때와 음성일때 분포가 크게 다른 것을 알 수 있고, 특히 area_mean 칼럼은 분포가 넓게 퍼져있는 것을 알 수 있다.<br><br></p><h2 id="2-2-Dimension-Plot"><a href="#2-2-Dimension-Plot" class="headerlink" title="2. 2 Dimension Plot"></a>2. 2 Dimension Plot</h2><p>이번에는 지난 글에서 살펴보았던 <a href="https://jaehyeongan.github.io/2019/05/27/Dimension-Reduction/">차원축소(Dimensionality Reduction)</a> 기법을 이용하여 2차원으로 데이터를 시각화하는 방법에 대해 알아보겠다.</p><p>우선 데이터 스케일 및 차원축소 기법인 PCA(Principal Component Analysis)를 적용하여 데이터를 2차원으로 변환시켜준 후, 타겟(음성/양성)별로 데이터를 구분하여 출력하였다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data Scaling</span></span><br><span class="line">X = cancer.drop([<span class="string">'diagnosis'</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = cancer[<span class="string">'diagnosis'</span>]</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">cancer_scale = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot 2D</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">pca2 = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">data_pca2 = pca2.fit_transform(cancer_scale)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plt.scatter(data_pca2[:,<span class="number">0</span>], data_pca2[:,<span class="number">1</span>], c=cancer[<span class="string">'diagnosis'</span>], s=<span class="number">40</span>, edgecolors=<span class="string">'white'</span>)</span><br><span class="line">plt.title(<span class="string">"2D of Target distribution by diagnosis"</span>)</span><br><span class="line">plt.xlabel(<span class="string">'pcomp 1'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'pcomp 2'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/cancer_2dplot.png" width="700"></p><p>2차원으로 표현해본 결과 양성일때와 음성일 때 극명하게 분포가 나뉘는 것을 확인해볼 수 있다.<br><br></p><h2 id="3-3-Dimension-Plot"><a href="#3-3-Dimension-Plot" class="headerlink" title="3. 3 Dimension Plot"></a>3. 3 Dimension Plot</h2><p>위와 같은 방식으로 PCA를 이용하여 데이터를 3차원으로 변환 후 데이터를 타겟(양성/음성) 별로 시각화 한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line">pca3 = PCA(n_components=<span class="number">3</span>)</span><br><span class="line">data_pca3 = pca3.fit_transform(cancer_scale)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line">ax.scatter(data_pca3[:,<span class="number">0</span>], data_pca3[:,<span class="number">1</span>], data_pca3[:,<span class="number">2</span>], c=cancer[<span class="string">'diagnosis'</span>], s=<span class="number">60</span>, edgecolors=<span class="string">'white'</span>)</span><br><span class="line">ax.set_title(<span class="string">'3D of Target distribution by diagnosis'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'pcomp 1'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'pcomp 2'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'pcomp 3'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/cancer_3dplot.png" width="700"><br><br></p><h2 id="4-Corrleation-Heatmap"><a href="#4-Corrleation-Heatmap" class="headerlink" title="4. Corrleation Heatmap"></a>4. Corrleation Heatmap</h2><p>이번에는 상관관계 분석을 통해 변수 간 상관관계가 얼마나 있는지 파악해본다. 이러한 상관관계 분석을 통해 타겟 값을 제외한 특정 두 변수가 상관관계가 0.9 이상일 경우 두 변수 중 하나를 제거해주는 것이 좋으며, 또한 어떤 변수가 타겟 값과 높은 상관성을 가지는지 파악하는데도 유용하게 사용된다.</p><p>corr()함수를 적용하여 변수간 상관관계 분석 후, 상관관계가 0.3이상인 변수만 출력하였다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line">font_name = font_manager.FontProperties(fname=<span class="string">"c:/Windows/Fonts/malgun.ttf"</span>).get_name()</span><br><span class="line">rc(<span class="string">'font'</span>, family=font_name) <span class="comment"># 한글 출력 설정 부분</span></span><br><span class="line"></span><br><span class="line">cancer_tmp = cancer.copy()</span><br><span class="line">cancer_tmp[<span class="string">'diagnosis'</span>] = cancer[<span class="string">'diagnosis'</span>].replace(&#123;<span class="string">'M'</span>:<span class="number">1</span>, <span class="string">'B'</span>:<span class="number">0</span>&#125;)</span><br><span class="line">corrmat = cancer_tmp.corr()</span><br><span class="line">top_corr_features = corrmat.index[abs(corrmat[<span class="string">"diagnosis"</span>])&gt;=<span class="number">0.3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">13</span>,<span class="number">10</span>))</span><br><span class="line">g = sns.heatmap(cancer[top_corr_features].corr(), annot=<span class="keyword">True</span>, cmap=<span class="string">"RdYlGn"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/cancer_correaltion.png" width="750"><br><br></p><h2 id="5-Feature-Importances"><a href="#5-Feature-Importances" class="headerlink" title="5. Feature Importances"></a>5. Feature Importances</h2><p>머신러닝 및 딥러닝 예측 후 어떻게 이러한 결과가 나왔는지 의문이 들 때가 있다. 그럴 땐 변수 중요도를 통해 어떤 변수가 예측 성능에 주요하게 영향을 미쳤는지 파악할 수 있다. </p><p>RandomForest 알고리즘을 통해 feature importances를 뽑아낸 후 상위 중요도 별로 중요도가 0이상만 출력하였다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line">font_name = font_manager.FontProperties(fname=<span class="string">"c:/Windows/Fonts/malgun.ttf"</span>).get_name()</span><br><span class="line">rc(<span class="string">'font'</span>, family=font_name) <span class="comment"># 한글 출력 설정 부분</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># RandomForest</span></span><br><span class="line">clf = RandomForestClassifier(random_state=<span class="number">42</span>, max_depth=<span class="number">6</span>)</span><br><span class="line">clf.fit(X, y)</span><br><span class="line">feature_importance = clf.feature_importances_</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">df_fi = pd.DataFrame(&#123;<span class="string">'columns'</span>:X.columns, <span class="string">'importances'</span>:feature_importance&#125;)</span><br><span class="line">df_fi = df_fi[df_fi[<span class="string">'importances'</span>] &gt; <span class="number">0</span>] <span class="comment"># importance가 0이상인 것만 </span></span><br><span class="line">df_fi = df_fi.sort_values(by=[<span class="string">'importances'</span>], ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">15</span>,<span class="number">7</span>))</span><br><span class="line">ax = sns.barplot(df_fi[<span class="string">'columns'</span>], df_fi[<span class="string">'importances'</span>])</span><br><span class="line">ax.set_xticklabels(df_fi[<span class="string">'columns'</span>], rotation=<span class="number">80</span>, fontsize=<span class="number">13</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="/image/cancer_fi.png" width="1000"><br>변수 중요도 출력결과 concave_points_worst가 0.175로 가장 중요한 예측 변수이며, 그 뒤로 perimeter_worst, perimeter_mean, radius_word가 주요 예측 변수로 나타났다.</p><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>이번에는 기초적인 데이터 시각화를 알아보았는데, 데이터 시각화는 데이터와 상황에 따라 그때 그때 시각화해야하는 요소가 다르고 다양하기 때문에, 상황에 따라 원하는 그림을 그리며 자신만의 인사이트를 찾아나가면 될 듯 하다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;데이터를 분석하려는데 데이터의 row와 columns 수가 많은 수백 차원 데이터의 경우 데이터를 파악하
      
    
    </summary>
    
    
      <category term="visualization" scheme="https://jaehyeongan.github.io/tags/visualization/"/>
    
      <category term="analytics" scheme="https://jaehyeongan.github.io/tags/analytics/"/>
    
      <category term="matplotlib" scheme="https://jaehyeongan.github.io/tags/matplotlib/"/>
    
      <category term="seaborn" scheme="https://jaehyeongan.github.io/tags/seaborn/"/>
    
      <category term="sklearn" scheme="https://jaehyeongan.github.io/tags/sklearn/"/>
    
      <category term="pca" scheme="https://jaehyeongan.github.io/tags/pca/"/>
    
      <category term="correaltion" scheme="https://jaehyeongan.github.io/tags/correaltion/"/>
    
      <category term="featureimportances" scheme="https://jaehyeongan.github.io/tags/featureimportances/"/>
    
      <category term="breastcancer" scheme="https://jaehyeongan.github.io/tags/breastcancer/"/>
    
  </entry>
  
  <entry>
    <title>[Kaggle] 보스턴 주택 가격 예측(House Prices: Advanced Regression Techniques)</title>
    <link href="https://jaehyeongan.github.io/2019/07/08/Kaggle-challenge-%EB%B3%B4%EC%8A%A4%ED%84%B4-%EC%A7%91%EA%B0%92-%EC%98%88%EC%B8%A1-House-Prices-Advanced-Regression-Techniques/"/>
    <id>https://jaehyeongan.github.io/2019/07/08/Kaggle-challenge-보스턴-집값-예측-House-Prices-Advanced-Regression-Techniques/</id>
    <published>2019-07-08T12:59:56.000Z</published>
    <updated>2021-02-07T14:57:00.417Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>캐글의 고전적인 문제이며 머신러닝을 공부하는 사람이라면 누구나 한번쯤 다뤄봤을 Boston house price Dataset을 통해 regression하는 과정을 소개하려 한다. 정식 competition 명칭은 <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" target="_blank" rel="noopener">‘House Prices: Advanced Regression Techniques’</a>이며, 현재 누구나 submission을 제출할 수 있다.<br><img src="/image/kaggle_boston_house.JPG" width="700"> </p><p>위에서 말했듯이 boston house price데이터셋은 왠만한 머신러닝 공부하는 사람들은 한번쯤 봤을 것이며, 대부분의 머신러닝 입문 교재에도 꼭 한번씩은 소개가 되는 데이터셋이다. 하지만, 대부분의 교재나 강의에서는 이미 feature engineering을 거친 아주 잘 정형화 된(모델에 바로 적용 가능한)데이터셋을 사용하며 데이터 처리 과정은 생략하는 경우가 대부분인 것 같다. 하지만 boston house price 데이터셋은 <strong>무려 81개의 다양한 칼럼 변수</strong>를 가지고 있으며, 각 칼럼 특성에 맞는 전처리가 필요하다. </p><p>따라서, 여기서는 boston house price 데이터셋에 어떻게 적절한 feature engineering을 적용하고, 최근 kaggle에서 가장 인기 있는 모델인 <strong>XGBoost 모델</strong>을 어떻게 적용하였는지 소개한다.</p><hr><h2 id="Import-Library"><a href="#Import-Library" class="headerlink" title="Import Library"></a>Import Library</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure><h1 id="1-Load-Data"><a href="#1-Load-Data" class="headerlink" title="1. Load Data"></a>1. Load Data</h1><ul><li>데이터의 경우 train, test set이 분리되어 제공되며 test set에 대한 예측결과가 추후 submission으로 제출된다.</li><li>train 데이터의 경우 1,460건, test 데이터가 1459건이며 총 81개의 칼럼을 가진다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># laod data</span></span><br><span class="line">train_df = pd.read_csv(<span class="string">'house_train.csv'</span>)</span><br><span class="line">test_df = pd.read_csv(<span class="string">'house_test.csv'</span>)</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Id</th>      <th>MSSubClass</th>      <th>MSZoning</th>      <th>LotFrontage</th>      <th>LotArea</th>      <th>Street</th>      <th>Alley</th>      <th>LotShape</th>      <th>LandContour</th>      <th>Utilities</th>      <th>...</th>      <th>PoolArea</th>      <th>PoolQC</th>      <th>Fence</th>      <th>MiscFeature</th>      <th>MiscVal</th>      <th>MoSold</th>      <th>YrSold</th>      <th>SaleType</th>      <th>SaleCondition</th>      <th>SalePrice</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>1</td>      <td>60</td>      <td>RL</td>      <td>65.0</td>      <td>8450</td>      <td>Pave</td>      <td>NaN</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>...</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>2</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>      <td>208500</td>    </tr>    <tr>      <th>1</th>      <td>2</td>      <td>20</td>      <td>RL</td>      <td>80.0</td>      <td>9600</td>      <td>Pave</td>      <td>NaN</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>...</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>5</td>      <td>2007</td>      <td>WD</td>      <td>Normal</td>      <td>181500</td>    </tr>    <tr>      <th>2</th>      <td>3</td>      <td>60</td>      <td>RL</td>      <td>68.0</td>      <td>11250</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>...</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>9</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>      <td>223500</td>    </tr>    <tr>      <th>3</th>      <td>4</td>      <td>70</td>      <td>RL</td>      <td>60.0</td>      <td>9550</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>...</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>2</td>      <td>2006</td>      <td>WD</td>      <td>Abnorml</td>      <td>140000</td>    </tr>    <tr>      <th>4</th>      <td>5</td>      <td>60</td>      <td>RL</td>      <td>84.0</td>      <td>14260</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>...</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>12</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>      <td>250000</td>    </tr>  </tbody></table><p>5 rows × 81 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set index</span></span><br><span class="line">train_df.set_index(<span class="string">'Id'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">test_df.set_index(<span class="string">'Id'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">len_train_df = len(train_df)</span><br><span class="line">len_test_df = len(test_df)</span><br></pre></td></tr></table></figure><p><br></p><h1 id="2-Feature-Selection-Variables-of-Corrleation-gt-0-3"><a href="#2-Feature-Selection-Variables-of-Corrleation-gt-0-3" class="headerlink" title="2. Feature Selection - Variables of Corrleation &gt;= 0.3"></a>2. Feature Selection - Variables of Corrleation &gt;= 0.3</h1><ul><li>고려해야 할 변수가 많을 땐 각 독립변수와 종속변수 간의 <strong>상관관계(Corrleation)</strong>을 검토해보는 것이 좋다. </li><li>모든 변수를 사용하는 것도 좋지만 그 중 좀더 의미 있는 변수만을 골라내어 모델을 구축하는 것이 모델의 예측 정확도를 높이는 방법이다.</li><li>corr()함수를 통해 dataframe내의 모든 변수간의 상관관계를 그린 후 상관관계가 0.3이상인 변수만 heatmap으로 출력하였다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">corrmat = train_df.corr()</span><br><span class="line">top_corr_features = corrmat.index[abs(corrmat[<span class="string">"SalePrice"</span>])&gt;=<span class="number">0.3</span>]</span><br><span class="line">top_corr_features</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;LotFrontage&#39;, &#39;OverallQual&#39;, &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;MasVnrArea&#39;,       &#39;BsmtFinSF1&#39;, &#39;TotalBsmtSF&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;GrLivArea&#39;,       &#39;FullBath&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Fireplaces&#39;, &#39;GarageYrBlt&#39;, &#39;GarageCars&#39;,       &#39;GarageArea&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;, &#39;SalePrice&#39;],      dtype=&#39;object&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># heatmap</span></span><br><span class="line">plt.figure(figsize=(<span class="number">13</span>,<span class="number">10</span>))</span><br><span class="line">g = sns.heatmap(train_df[top_corr_features].corr(),annot=<span class="keyword">True</span>,cmap=<span class="string">"RdYlGn"</span>)</span><br></pre></td></tr></table></figure><p><img src="/image/output_6_0.png" width="700"> </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># feature selection</span></span><br><span class="line"><span class="comment"># train_df = train_df[top_corr_features]</span></span><br><span class="line"><span class="comment"># test_df = test_df[top_corr_features.drop(['SalePrice'])]</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split y_label</span></span><br><span class="line">train_y_label = train_df[<span class="string">'SalePrice'</span>] <span class="comment"># target 값을 미리 분리하였음.</span></span><br><span class="line">train_df.drop([<span class="string">'SalePrice'</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><p><br></p><h1 id="3-Concat-train-amp-test-set"><a href="#3-Concat-train-amp-test-set" class="headerlink" title="3. Concat train &amp; test set"></a>3. Concat train &amp; test set</h1><ul><li>train과 test 셋에 동일한 feature engineering을 적용해주기 위해 우선 두개의 데이터 셋을 하나로 합쳐주었다.</li><li>합쳐주니 2,919개로 데이터가 늘었다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># concat train &amp; test</span></span><br><span class="line">boston_df = pd.concat((train_df, test_df), axis=<span class="number">0</span>)</span><br><span class="line">boston_df_index = boston_df.index</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Length of Boston Dataset : '</span>,len(boston_df))</span><br><span class="line">boston_df.head()</span><br></pre></td></tr></table></figure><pre><code>Length of Boston Dataset :  2919</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MSSubClass</th>      <th>MSZoning</th>      <th>LotFrontage</th>      <th>LotArea</th>      <th>Street</th>      <th>Alley</th>      <th>LotShape</th>      <th>LandContour</th>      <th>Utilities</th>      <th>LotConfig</th>      <th>...</th>      <th>ScreenPorch</th>      <th>PoolArea</th>      <th>PoolQC</th>      <th>Fence</th>      <th>MiscFeature</th>      <th>MiscVal</th>      <th>MoSold</th>      <th>YrSold</th>      <th>SaleType</th>      <th>SaleCondition</th>    </tr>    <tr>      <th>Id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>60</td>      <td>RL</td>      <td>65.0</td>      <td>8450</td>      <td>Pave</td>      <td>NaN</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Inside</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>2</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>    </tr>    <tr>      <th>2</th>      <td>20</td>      <td>RL</td>      <td>80.0</td>      <td>9600</td>      <td>Pave</td>      <td>NaN</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>FR2</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>5</td>      <td>2007</td>      <td>WD</td>      <td>Normal</td>    </tr>    <tr>      <th>3</th>      <td>60</td>      <td>RL</td>      <td>68.0</td>      <td>11250</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Inside</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>9</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>    </tr>    <tr>      <th>4</th>      <td>70</td>      <td>RL</td>      <td>60.0</td>      <td>9550</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Corner</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>2</td>      <td>2006</td>      <td>WD</td>      <td>Abnorml</td>    </tr>    <tr>      <th>5</th>      <td>60</td>      <td>RL</td>      <td>84.0</td>      <td>14260</td>      <td>Pave</td>      <td>NaN</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>FR2</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>0</td>      <td>12</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>    </tr>  </tbody></table><p>5 rows × 79 columns</p></div><p><br></p><h1 id="4-Check-NaN-ratio-and-Remove-null-ratio-gt-0-5"><a href="#4-Check-NaN-ratio-and-Remove-null-ratio-gt-0-5" class="headerlink" title="4. Check NaN ratio and Remove null ratio &gt;= 0.5"></a>4. Check NaN ratio and Remove null ratio &gt;= 0.5</h1><ul><li>데이터를 처리할 때 항상 Null값을 어떻게 처리할지 고민해야 한다. 추후 모델에 입력되는 input값에는 절대 어떠한 Null 값이 있어서는 안되며 있더라도 에러가 발생하기 때문에 미리 꼭 처리해주어야 한다.</li><li>우선 각 칼럼별로 <strong>Null값 비율이 50%이상인 칼럼을 찾아 해당 칼럼을 제거</strong>해주었다. </li><li>보통 null값 처리를 위해 평균, 최대값, 최소값 등으로 대체하곤 하는데 위와 같이 대부분의 칼럼이 Null인 데이터는 차라리 없애주는 것이 좋다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># check null </span></span><br><span class="line">check_null = boston_df.isna().sum() / len(boston_df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># columns of null ratio &gt;= 0.5</span></span><br><span class="line">check_null[check_null &gt;= <span class="number">0.5</span>]</span><br></pre></td></tr></table></figure><pre><code>Alley          0.932169PoolQC         0.996574Fence          0.804385MiscFeature    0.964029dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># remove columns of null ratio &gt;= 0.5</span></span><br><span class="line">remove_cols = check_null[check_null &gt;= <span class="number">0.5</span>].keys()</span><br><span class="line">boston_df = boston_df.drop(remove_cols, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">boston_df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MSSubClass</th>      <th>MSZoning</th>      <th>LotFrontage</th>      <th>LotArea</th>      <th>Street</th>      <th>LotShape</th>      <th>LandContour</th>      <th>Utilities</th>      <th>LotConfig</th>      <th>LandSlope</th>      <th>...</th>      <th>OpenPorchSF</th>      <th>EnclosedPorch</th>      <th>3SsnPorch</th>      <th>ScreenPorch</th>      <th>PoolArea</th>      <th>MiscVal</th>      <th>MoSold</th>      <th>YrSold</th>      <th>SaleType</th>      <th>SaleCondition</th>    </tr>    <tr>      <th>Id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>60</td>      <td>RL</td>      <td>65.0</td>      <td>8450</td>      <td>Pave</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Inside</td>      <td>Gtl</td>      <td>...</td>      <td>61</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>    </tr>    <tr>      <th>2</th>      <td>20</td>      <td>RL</td>      <td>80.0</td>      <td>9600</td>      <td>Pave</td>      <td>Reg</td>      <td>Lvl</td>      <td>AllPub</td>      <td>FR2</td>      <td>Gtl</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>5</td>      <td>2007</td>      <td>WD</td>      <td>Normal</td>    </tr>    <tr>      <th>3</th>      <td>60</td>      <td>RL</td>      <td>68.0</td>      <td>11250</td>      <td>Pave</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Inside</td>      <td>Gtl</td>      <td>...</td>      <td>42</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>9</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>    </tr>    <tr>      <th>4</th>      <td>70</td>      <td>RL</td>      <td>60.0</td>      <td>9550</td>      <td>Pave</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>Corner</td>      <td>Gtl</td>      <td>...</td>      <td>35</td>      <td>272</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>2006</td>      <td>WD</td>      <td>Abnorml</td>    </tr>    <tr>      <th>5</th>      <td>60</td>      <td>RL</td>      <td>84.0</td>      <td>14260</td>      <td>Pave</td>      <td>IR1</td>      <td>Lvl</td>      <td>AllPub</td>      <td>FR2</td>      <td>Gtl</td>      <td>...</td>      <td>84</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>12</td>      <td>2008</td>      <td>WD</td>      <td>Normal</td>    </tr>  </tbody></table><p>5 rows × 75 columns</p></div><p><br></p><h1 id="5-Check-Object-amp-Numeric-variables"><a href="#5-Check-Object-amp-Numeric-variables" class="headerlink" title="5. Check Object &amp; Numeric variables"></a>5. Check Object &amp; Numeric variables</h1><ul><li>해당 데이터 셋에는 수치형 데이터만 있는 것이 아니다. [성별: 남자, 여자], [학급: 햇님반, 꽃님반, 달님반]과 같은 카테고리형 데이터도 존재한다. </li><li>이러한 카테고리형 데이터는 각 칼럼을 0과 1로 변환해주는 one-hot encoding을 적용해주어 수치값과 가중치를 달리해주어야 한다.</li><li>수치형 데이터와 카테고리형 데이터를 구분하기 위해 <strong>select_dtypes()</strong>를 이용하였다. parameter값으로 include와 exclude를 적용할 수 있는데 이를 통해 데이터를 분리한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split object &amp; numeric</span></span><br><span class="line">boston_obj_df = boston_df.select_dtypes(include=<span class="string">'object'</span>)<span class="comment"># 카테고리형</span></span><br><span class="line">boston_num_df = boston_df.select_dtypes(exclude=<span class="string">'object'</span>)<span class="comment"># 수치형</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Object type columns:\n'</span>,boston_obj_df.columns)</span><br><span class="line">print(<span class="string">'---------------------------------------------------------------------------------'</span>)</span><br><span class="line">print(<span class="string">'Numeric type columns:\n'</span>,boston_num_df.columns)</span><br></pre></td></tr></table></figure><pre><code>Object type columns: Index([&#39;MSZoning&#39;, &#39;Street&#39;, &#39;LotShape&#39;, &#39;LandContour&#39;, &#39;Utilities&#39;,       &#39;LotConfig&#39;, &#39;LandSlope&#39;, &#39;Neighborhood&#39;, &#39;Condition1&#39;, &#39;Condition2&#39;,       &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;RoofStyle&#39;, &#39;RoofMatl&#39;, &#39;Exterior1st&#39;,       &#39;Exterior2nd&#39;, &#39;MasVnrType&#39;, &#39;ExterQual&#39;, &#39;ExterCond&#39;, &#39;Foundation&#39;,       &#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;, &#39;BsmtFinType2&#39;,       &#39;Heating&#39;, &#39;HeatingQC&#39;, &#39;CentralAir&#39;, &#39;Electrical&#39;, &#39;KitchenQual&#39;,       &#39;Functional&#39;, &#39;FireplaceQu&#39;, &#39;GarageType&#39;, &#39;GarageFinish&#39;, &#39;GarageQual&#39;,       &#39;GarageCond&#39;, &#39;PavedDrive&#39;, &#39;SaleType&#39;, &#39;SaleCondition&#39;],      dtype=&#39;object&#39;)---------------------------------------------------------------------------------Numeric type columns: Index([&#39;MSSubClass&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;OverallQual&#39;, &#39;OverallCond&#39;,       &#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;MasVnrArea&#39;, &#39;BsmtFinSF1&#39;, &#39;BsmtFinSF2&#39;,       &#39;BsmtUnfSF&#39;, &#39;TotalBsmtSF&#39;, &#39;1stFlrSF&#39;, &#39;2ndFlrSF&#39;, &#39;LowQualFinSF&#39;,       &#39;GrLivArea&#39;, &#39;BsmtFullBath&#39;, &#39;BsmtHalfBath&#39;, &#39;FullBath&#39;, &#39;HalfBath&#39;,       &#39;BedroomAbvGr&#39;, &#39;KitchenAbvGr&#39;, &#39;TotRmsAbvGrd&#39;, &#39;Fireplaces&#39;,       &#39;GarageYrBlt&#39;, &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;WoodDeckSF&#39;, &#39;OpenPorchSF&#39;,       &#39;EnclosedPorch&#39;, &#39;3SsnPorch&#39;, &#39;ScreenPorch&#39;, &#39;PoolArea&#39;, &#39;MiscVal&#39;,       &#39;MoSold&#39;, &#39;YrSold&#39;],      dtype=&#39;object&#39;)</code></pre><p><br></p><h1 id="6-Change-object-type-to-dummy-variables"><a href="#6-Change-object-type-to-dummy-variables" class="headerlink" title="6. Change object type to dummy variables"></a>6. Change object type to dummy variables</h1><ul><li>위에서 분리한 카테고리형 데이터에 one-hot encoding을 적용하기 위해 pandas의 <strong>pd.get_dummies()</strong>를 적용하였다. one-hot encoding 적용시 [남자, 여자]의 경우 [[1,0], [0,1]]과 같은 형태로 변환된다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">boston_dummy_df = pd.get_dummies(boston_obj_df, drop_first=<span class="keyword">True</span>)</span><br><span class="line">boston_dummy_df.index = boston_df_index</span><br><span class="line">boston_dummy_df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MSZoning_FV</th>      <th>MSZoning_RH</th>      <th>MSZoning_RL</th>      <th>MSZoning_RM</th>      <th>Street_Pave</th>      <th>LotShape_IR2</th>      <th>LotShape_IR3</th>      <th>LotShape_Reg</th>      <th>LandContour_HLS</th>      <th>LandContour_Low</th>      <th>...</th>      <th>SaleType_ConLI</th>      <th>SaleType_ConLw</th>      <th>SaleType_New</th>      <th>SaleType_Oth</th>      <th>SaleType_WD</th>      <th>SaleCondition_AdjLand</th>      <th>SaleCondition_Alloca</th>      <th>SaleCondition_Family</th>      <th>SaleCondition_Normal</th>      <th>SaleCondition_Partial</th>    </tr>    <tr>      <th>Id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>5</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>  </tbody></table><p>5 rows × 200 columns</p></div><p><br></p><h1 id="7-Impute-NaN-of-numeric-data-to-‘mean’"><a href="#7-Impute-NaN-of-numeric-data-to-‘mean’" class="headerlink" title="7. Impute NaN of numeric data to ‘mean’"></a>7. Impute NaN of numeric data to ‘mean’</h1><ul><li>4번쨰 과정에서 null값이 50%이상인 변수들을 제거해주었었는데, 그 이하로 null값이 있는 데이터를 마저 처리해주어야 한다. </li><li>여기서는 각 칼럼의 null값을 해당하는 각 변수들의 <strong>평균(mean)으로 대체(imputation)</strong>해주었다.</li><li>평균값 대체를 위하여 scikit-learn의 <strong>Imputer 함수</strong>를 이용하였으며, strategy 값에 대체해주고자 하는 이름을 넣어주면 해당 값으로 처리한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"></span><br><span class="line">imputer = Imputer(strategy=<span class="string">'mean'</span>)</span><br><span class="line">imputer.fit(boston_num_df)</span><br><span class="line">boston_num_df_ = imputer.transform(boston_num_df)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">boston_num_df = pd.DataFrame(boston_num_df_, columns=boston_num_df.columns, index=boston_df_index)</span><br><span class="line">boston_num_df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MSSubClass</th>      <th>LotFrontage</th>      <th>LotArea</th>      <th>OverallQual</th>      <th>OverallCond</th>      <th>YearBuilt</th>      <th>YearRemodAdd</th>      <th>MasVnrArea</th>      <th>BsmtFinSF1</th>      <th>BsmtFinSF2</th>      <th>...</th>      <th>GarageArea</th>      <th>WoodDeckSF</th>      <th>OpenPorchSF</th>      <th>EnclosedPorch</th>      <th>3SsnPorch</th>      <th>ScreenPorch</th>      <th>PoolArea</th>      <th>MiscVal</th>      <th>MoSold</th>      <th>YrSold</th>    </tr>    <tr>      <th>Id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>60.0</td>      <td>65.0</td>      <td>8450.0</td>      <td>7.0</td>      <td>5.0</td>      <td>2003.0</td>      <td>2003.0</td>      <td>196.0</td>      <td>706.0</td>      <td>0.0</td>      <td>...</td>      <td>548.0</td>      <td>0.0</td>      <td>61.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>2.0</td>      <td>2008.0</td>    </tr>    <tr>      <th>2</th>      <td>20.0</td>      <td>80.0</td>      <td>9600.0</td>      <td>6.0</td>      <td>8.0</td>      <td>1976.0</td>      <td>1976.0</td>      <td>0.0</td>      <td>978.0</td>      <td>0.0</td>      <td>...</td>      <td>460.0</td>      <td>298.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>5.0</td>      <td>2007.0</td>    </tr>    <tr>      <th>3</th>      <td>60.0</td>      <td>68.0</td>      <td>11250.0</td>      <td>7.0</td>      <td>5.0</td>      <td>2001.0</td>      <td>2002.0</td>      <td>162.0</td>      <td>486.0</td>      <td>0.0</td>      <td>...</td>      <td>608.0</td>      <td>0.0</td>      <td>42.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>9.0</td>      <td>2008.0</td>    </tr>    <tr>      <th>4</th>      <td>70.0</td>      <td>60.0</td>      <td>9550.0</td>      <td>7.0</td>      <td>5.0</td>      <td>1915.0</td>      <td>1970.0</td>      <td>0.0</td>      <td>216.0</td>      <td>0.0</td>      <td>...</td>      <td>642.0</td>      <td>0.0</td>      <td>35.0</td>      <td>272.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>2.0</td>      <td>2006.0</td>    </tr>    <tr>      <th>5</th>      <td>60.0</td>      <td>84.0</td>      <td>14260.0</td>      <td>8.0</td>      <td>5.0</td>      <td>2000.0</td>      <td>2000.0</td>      <td>350.0</td>      <td>655.0</td>      <td>0.0</td>      <td>...</td>      <td>836.0</td>      <td>192.0</td>      <td>84.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>12.0</td>      <td>2008.0</td>    </tr>  </tbody></table><p>5 rows × 36 columns</p></div><p><br></p><h1 id="8-Merge-numeric-df-amp-dummies-df"><a href="#8-Merge-numeric-df-amp-dummies-df" class="headerlink" title="8. Merge numeric_df &amp; dummies_df"></a>8. Merge numeric_df &amp; dummies_df</h1><ul><li>위에서 각각 처리한 카테고리형 데이터와 수치형 데이터를 이제 최종적으로 다시 하나로 merge해준다. merge시 index 순서가 꼬이지 않게 left_index=True, right_index=True를 지정하여 merge를 수행한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">boston_df = pd.merge(boston_dummy_df, boston_num_df, left_index=<span class="keyword">True</span>, right_index=<span class="keyword">True</span>)</span><br><span class="line">boston_df.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>MSZoning_FV</th>      <th>MSZoning_RH</th>      <th>MSZoning_RL</th>      <th>MSZoning_RM</th>      <th>Street_Pave</th>      <th>LotShape_IR2</th>      <th>LotShape_IR3</th>      <th>LotShape_Reg</th>      <th>LandContour_HLS</th>      <th>LandContour_Low</th>      <th>...</th>      <th>GarageArea</th>      <th>WoodDeckSF</th>      <th>OpenPorchSF</th>      <th>EnclosedPorch</th>      <th>3SsnPorch</th>      <th>ScreenPorch</th>      <th>PoolArea</th>      <th>MiscVal</th>      <th>MoSold</th>      <th>YrSold</th>    </tr>    <tr>      <th>Id</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>1</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>548.0</td>      <td>0.0</td>      <td>61.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>2.0</td>      <td>2008.0</td>    </tr>    <tr>      <th>2</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>460.0</td>      <td>298.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>5.0</td>      <td>2007.0</td>    </tr>    <tr>      <th>3</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>608.0</td>      <td>0.0</td>      <td>42.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>9.0</td>      <td>2008.0</td>    </tr>    <tr>      <th>4</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>642.0</td>      <td>0.0</td>      <td>35.0</td>      <td>272.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>2.0</td>      <td>2006.0</td>    </tr>    <tr>      <th>5</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>...</td>      <td>836.0</td>      <td>192.0</td>      <td>84.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>12.0</td>      <td>2008.0</td>    </tr>  </tbody></table><p>5 rows × 236 columns</p></div><p><br></p><h1 id="9-Split-train-amp-validation-amp-test-set"><a href="#9-Split-train-amp-validation-amp-test-set" class="headerlink" title="9. Split train &amp; validation &amp; test set"></a>9. Split train &amp; validation &amp; test set</h1><ul><li>모델 학습 및 검증을 위해 데이터를 split한다.</li><li>여기서 test set의 경우 정답값이 없는 예측해야 하는 값이므로 검증을 위해 validation set을 train set의 20%만큼을 지정해주었다.</li><li>최종적으로 1,168개의 데이터로 학습 및 292개의 데이터로 검증 후 1,459개의 test셋을 예측한다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_df = boston_df[:len_train_df]</span><br><span class="line">test_df = boston_df[len_train_df:]</span><br><span class="line"></span><br><span class="line">train_df[<span class="string">'SalePrice'</span>] = train_y_label</span><br><span class="line"></span><br><span class="line">print(<span class="string">'train set length: '</span>,len(train_df))</span><br><span class="line">print(<span class="string">'test set length: '</span>,len(test_df))</span><br></pre></td></tr></table></figure><pre><code>train set length:  1460test set length:  1459</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train = train_df.drop([<span class="string">'SalePrice'</span>], axis=<span class="number">1</span>)</span><br><span class="line">y_train = train_df[<span class="string">'SalePrice'</span>]</span><br><span class="line"></span><br><span class="line">X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=<span class="number">0.2</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">X_test = test_df</span><br><span class="line">test_id_idx = test_df.index</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'X_train : '</span>,len(X_train))</span><br><span class="line">print(<span class="string">'X_val : '</span>,len(X_val))</span><br><span class="line">print(<span class="string">'X_test :'</span>,len(X_test))</span><br></pre></td></tr></table></figure><pre><code>X_train :  1168X_val :  292X_test : 1459</code></pre><p><br></p><h1 id="10-Training-by-XGBRegression-Model"><a href="#10-Training-by-XGBRegression-Model" class="headerlink" title="10. Training by XGBRegression Model"></a>10. Training by XGBRegression Model</h1><ul><li>모델 학습을 위해 최근 kaggle에서 가장 인기 있는 모델인 XGBoost 모델을 이용하였다. 해당 예측은 regression 예측이므로 <strong>XGBRegressor()</strong> 모델을 이용하였다.</li><li>최적의 모델 파라미터 설정을 위하여 GridSearch를 이용하였으며, 5번의 cross-validation으로 검증을 진행하였다.</li><li>학습 후 best<em>params</em>를 출력하면 최적의 파라미터 값이 출력된다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line">param = &#123;</span><br><span class="line">    <span class="string">'max_depth'</span>:[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">    <span class="string">'n_estimators'</span>:range(<span class="number">550</span>,<span class="number">700</span>,<span class="number">50</span>),</span><br><span class="line">    <span class="string">'colsample_bytree'</span>:[<span class="number">0.5</span>,<span class="number">0.7</span>,<span class="number">1</span>],</span><br><span class="line">    <span class="string">'colsample_bylevel'</span>:[<span class="number">0.5</span>,<span class="number">0.7</span>,<span class="number">1</span>],</span><br><span class="line">&#125;</span><br><span class="line">model = xgb.XGBRegressor()</span><br><span class="line">grid_search = GridSearchCV(estimator=model, param_grid=param, cv=<span class="number">5</span>, </span><br><span class="line">                           scoring=<span class="string">'neg_mean_squared_error'</span>,</span><br><span class="line">                           n_jobs=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">grid_search.fit(X_train, y_train)</span><br><span class="line">print(grid_search.best_params_)</span><br><span class="line">print(grid_search.best_estimator_)</span><br></pre></td></tr></table></figure><pre><code>{&#39;colsample_bylevel&#39;: 0.5, &#39;colsample_bytree&#39;: 0.7, &#39;max_depth&#39;: 3, &#39;n_estimators&#39;: 600}XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=0.5,             colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_delta_step=0,             max_depth=3, min_child_weight=1, missing=None, n_estimators=600,             n_jobs=1, nthread=None, objective=&#39;reg:linear&#39;, random_state=0,             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,             silent=True, subsample=1)</code></pre><p><br></p><h1 id="11-Prediction-amp-Score"><a href="#11-Prediction-amp-Score" class="headerlink" title="11. Prediction &amp; Score"></a>11. Prediction &amp; Score</h1><ul><li>검증을 위해 <strong>Mean Absolute Error(MAE)</strong> 지표를 활용하였다. MSE를 활용할 경우 error값이 클 경우 그에 제곱된 값이 출력되기 때문에 값이 너무 커져 보기 불편하다는 단점이 있다.<br><img src="/image/mae.png" width="400"> </li><li>검증 결과 validation mae 값이 14,000정도인데, 워낙 집 가격에 대한 값의 범위가 넓기 때문에 이 정도 error값은 심각한 정도는 아니며 납득할만한 수준이라고 할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error, mean_absolute_error</span><br><span class="line">pred_train = grid_search.predict(X_train)</span><br><span class="line">pred_val = grid_search.predict(X_val)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'train mae score: '</span>, mean_absolute_error(y_train, pred_train))</span><br><span class="line">print(<span class="string">'val mae score:'</span>, mean_absolute_error(y_val, pred_val))</span><br></pre></td></tr></table></figure><pre><code>train mae score:  4790.379391186858val mae score: 14178.155835295376</code></pre><p><br></p><ul><li>이후 validation set을 대상으로 예측을 수행한 후 실제 값과의 결과를 plotting하였다. </li><li>어느 정도 경향을 잘 예측하고 있는 것을 확인할 수 있다. </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">17</span>,<span class="number">7</span>))</span><br><span class="line">plt.plot(range(<span class="number">0</span>, len(y_val)), y_val,<span class="string">'o-'</span>, label=<span class="string">'Validation Actual'</span>)</span><br><span class="line">plt.plot(range(<span class="number">0</span>, len(pred_val)), pred_val, <span class="string">'-'</span>, label=<span class="string">'Validation Predict'</span>)</span><br><span class="line">plt.title(<span class="string">'Prediction of House Prices'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Prices'</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure><p><img src="/image/output_32_1.png" width="1050"> </p><p><br></p><h1 id="12-Predict-test-set-amp-Submit-submission-csv"><a href="#12-Predict-test-set-amp-Submit-submission-csv" class="headerlink" title="12. Predict test set &amp; Submit submission.csv"></a>12. Predict test set &amp; Submit submission.csv</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_y_pred = grid_search.predict(X_test)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">id_pred_df = pd.DataFrame()</span><br><span class="line">id_pred_df[<span class="string">'Id'</span>] = test_id_idx</span><br><span class="line">id_pred_df[<span class="string">'SalePrice'</span>] = test_y_pred</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">id_pred_df.to_csv(<span class="string">'submission.csv'</span>, index=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>실제 submission에서 성능 평가 시에는 Root Mean Squarred Error이용하는데, 제출 결과 0.12875로 총 4,465팀 중 1,867등을 기록하였다(상위 42%). 이번에는 단순히 테스트를 위해 머신러닝 모델만 적용해보았는데, LSTM 모델을 적용하면 확실히 더 낮은 error 값이 나올 것으로 기대된다.  </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;캐글의 고전적인 문제이며 머신러닝을 공부하는 사람이라면 누구나 한번쯤 다뤄봤을 Boston house p
      
    
    </summary>
    
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="kaggle" scheme="https://jaehyeongan.github.io/tags/kaggle/"/>
    
      <category term="regression" scheme="https://jaehyeongan.github.io/tags/regression/"/>
    
      <category term="bostonhouse" scheme="https://jaehyeongan.github.io/tags/bostonhouse/"/>
    
      <category term="price" scheme="https://jaehyeongan.github.io/tags/price/"/>
    
      <category term="xgboost" scheme="https://jaehyeongan.github.io/tags/xgboost/"/>
    
      <category term="featureengineering" scheme="https://jaehyeongan.github.io/tags/featureengineering/"/>
    
  </entry>
  
  <entry>
    <title>[Kaggle] 직소 악성 대화 분류(Jigsaw Unintended Bias in Toxicity Classification)</title>
    <link href="https://jaehyeongan.github.io/2019/07/04/Kaggle-challenge-%EC%A7%81%EC%86%8C-%EC%95%85%EC%84%B1-%EB%8C%93%EA%B8%80-%EB%B6%84%EB%A5%98-Jigsaw-Unintended-Bias-in-Toxicity/"/>
    <id>https://jaehyeongan.github.io/2019/07/04/Kaggle-challenge-직소-악성-댓글-분류-Jigsaw-Unintended-Bias-in-Toxicity/</id>
    <published>2019-07-03T15:11:36.000Z</published>
    <updated>2021-02-07T14:57:03.741Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>얼마 전 캐글에서 구글 Jigsaw/Conversation AI팀에 의해 <a href="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification" target="_blank" rel="noopener">‘Jigsaw Unintended Bias in Toxicity Classification’</a>라는 주제로 competition이 개최되어 호기심에 도전해보았다.<br><img src="/image/jigsaw_competition.JPG" width="700"> </p><p>Jigsaw라는 곳을 처음 들어봤는데 알아보니 구글의 자회사로 온라인 상의 욕설이나 선동적, 폭력적 대화를 잡아내는 기술을 연구하는 곳이었고,<br>Description상에 의한 이 Competition의 주요문제는 다음과 같았다. </p><blockquote><p><strong>현재 Jigsaw의 Conversation AI팀은 Perspective라는 제품을 통해 온라인 상의 악성 대화(위협, 외설, 모욕 등)를 잡아내고 있는데, 모델을 좀 더 정교하게 하여 낮은 에러율의 다양한 악성 대화를 잡아내는 모델을 만드는 것.</strong></p></blockquote><p>데이터의 경우 train데이터와 test데이터를 따로 제공하며, train 데이터의 경우 180만건 정도 되는데 텍스트 데이터 위주로 되어있다보니 사이즈가 상당히 컸다.<br>해당 competition의 결과 제출은 Kernels에 의해서만 가능한데, 데이터 사이즈가 크다보니 모델에 의한 학습도 굉장히 오래걸리고 kaggle내에서도 kernel 학습시간에 제한을 두기 때문에 모델을 정교하게 학습시키는 것이 쉽지 않았다.</p><p>코드 작성은 Jupyter notebook을 이용하였으며, 아래 작성된 코드는 ipynb파일을 markdown으로 변환하여 업로드하였다.</p><hr><h2 id="Import-Library"><a href="#Import-Library" class="headerlink" title="Import Library"></a>Import Library</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download(<span class="string">'stopwords'</span>)</span><br><span class="line">nltk.download(<span class="string">'punkt'</span>)</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords </span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize </span><br><span class="line">stop_words = set(stopwords.words(<span class="string">'english'</span>)) </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers, Model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> text, sequence</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping, ModelCheckpoint, ReduceLROnPlateau</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">print(os.listdir(<span class="string">"./input"</span>))</span><br></pre></td></tr></table></figure><pre><code>[&#39;test.csv&#39;, &#39;train.csv&#39;]</code></pre><h2 id="1-Load-Data"><a href="#1-Load-Data" class="headerlink" title="1. Load Data"></a>1. Load Data</h2><ul><li>데이터는 <strong>train 데이터가 180만건, test 데이터가 9만7천건 정도</strong>로 이루어져 있다.</li><li>train 데이터는 id, target, comment_text를 포함하여 총 45개의 칼럼으로 이루어져 있지만, test 데이터의 경우 id, target, comment_text 총 3개의 칼럼으로만 이루어져 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## load data</span></span><br><span class="line">train_data = pd.read_csv(<span class="string">'./input/train.csv'</span>)</span><br><span class="line">test_data = pd.read_csv(<span class="string">'./input/test.csv'</span>)</span><br><span class="line">print(train_data.shape)</span><br><span class="line">print(test_data.shape)</span><br></pre></td></tr></table></figure><pre><code>(1804874, 45)(97320, 2)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>id</th>      <th>target</th>      <th>comment_text</th>      <th>severe_toxicity</th>      <th>obscene</th>      <th>identity_attack</th>      <th>insult</th>      <th>threat</th>      <th>asian</th>      <th>atheist</th>      <th>...</th>      <th>article_id</th>      <th>rating</th>      <th>funny</th>      <th>wow</th>      <th>sad</th>      <th>likes</th>      <th>disagree</th>      <th>sexual_explicit</th>      <th>identity_annotator_count</th>      <th>toxicity_annotator_count</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>59848</td>      <td>0.000000</td>      <td>This is so cool. It's like, 'would you want yo...</td>      <td>0.000000</td>      <td>0.0</td>      <td>0.000000</td>      <td>0.00000</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>2006</td>      <td>rejected</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0</td>      <td>4</td>    </tr>    <tr>      <th>1</th>      <td>59849</td>      <td>0.000000</td>      <td>Thank you!! This would make my life a lot less...</td>      <td>0.000000</td>      <td>0.0</td>      <td>0.000000</td>      <td>0.00000</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>2006</td>      <td>rejected</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0</td>      <td>4</td>    </tr>    <tr>      <th>2</th>      <td>59852</td>      <td>0.000000</td>      <td>This is such an urgent design problem; kudos t...</td>      <td>0.000000</td>      <td>0.0</td>      <td>0.000000</td>      <td>0.00000</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>2006</td>      <td>rejected</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0</td>      <td>4</td>    </tr>    <tr>      <th>3</th>      <td>59855</td>      <td>0.000000</td>      <td>Is this something I'll be able to install on m...</td>      <td>0.000000</td>      <td>0.0</td>      <td>0.000000</td>      <td>0.00000</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>...</td>      <td>2006</td>      <td>rejected</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0</td>      <td>4</td>    </tr>    <tr>      <th>4</th>      <td>59856</td>      <td>0.893617</td>      <td>haha you guys are a bunch of losers.</td>      <td>0.021277</td>      <td>0.0</td>      <td>0.021277</td>      <td>0.87234</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>...</td>      <td>2006</td>      <td>rejected</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0.0</td>      <td>4</td>      <td>47</td>    </tr>  </tbody></table><p>5 rows × 45 columns</p></div><p><br></p><h2 id="2-Set-index-amp-target-label"><a href="#2-Set-index-amp-target-label" class="headerlink" title="2. Set index &amp; target label"></a>2. Set index &amp; target label</h2><ul><li>다른 커널을 보니 train 데이터의 다양한 칼럼을 활용하는 것 같던데 여기선 텍스트 데이터와 타겟 값만을 이용하여 학습 및 예측을 수행하였다.</li><li>id 값은 index로 지정해두었으며, target값의 경우 <a href="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data" target="_blank" rel="noopener">Data Description</a>의 설명에 따라 0.5이상은 positive 0.5미만은 negative 라벨로 분류하였다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_df = train_data[[<span class="string">'id'</span>,<span class="string">'comment_text'</span>,<span class="string">'target'</span>]]</span><br><span class="line">test_df = test_data.copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># set index</span></span><br><span class="line">train_df.set_index(<span class="string">'id'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">test_df.set_index(<span class="string">'id'</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># y_label</span></span><br><span class="line">train_y_label = np.where(train_df[<span class="string">'target'</span>] &gt;= <span class="number">0.5</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment"># Label 1 &gt;= 0.5 / Label 0 &lt; 0.5</span></span><br><span class="line">train_df.drop([<span class="string">'target'</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ratio by Class</span></span><br><span class="line">Counter(train_y_label)</span><br></pre></td></tr></table></figure><pre><code>Counter({0: 1660540, 1: 144334})</code></pre><p><br></p><h2 id="3-View-text-data"><a href="#3-View-text-data" class="headerlink" title="3. View text data"></a>3. View text data</h2><ul><li>comment_text 칼럼을 출력해보면 아래와 같이 다양한 주제의 대화 내용을 확인할 수 있다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data[<span class="string">'comment_text'</span>].head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><pre><code>0     This is so cool. It&#39;s like, &#39;would you want yo...1     Thank you!! This would make my life a lot less...2     This is such an urgent design problem; kudos t...3     Is this something I&#39;ll be able to install on m...4                  haha you guys are a bunch of losers.5                                  ur a sh*tty comment.6                           hahahahahahahahhha suck it.7                                   FFFFUUUUUUUUUUUUUUU8     The ranchers seem motivated by mostly by greed...9     It was a great show. Not a combo I&#39;d of expect...10                              Wow, that sounds great.11    This is a great story. Man. I wonder if the pe...12       This seems like a step in the right direction.13    It&#39;s ridiculous that these guys are being call...14    This story gets more ridiculous by the hour! A...15    I agree; I don&#39;t want to grant them the legiti...16    Interesting. I&#39;ll be curious to see how this w...17                      Awesome! I love Civil Comments!18    I&#39;m glad you&#39;re working on this, and I look fo...19    Angry trolls, misogynists and Racists&quot;, oh my....Name: comment_text, dtype: object</code></pre><p><br></p><h2 id="4-Remove-Punctuation-amp-Stopword"><a href="#4-Remove-Punctuation-amp-Stopword" class="headerlink" title="4. Remove Punctuation &amp; Stopword"></a>4. Remove Punctuation &amp; Stopword</h2><ul><li>가장 기본적인 텍스트 전처리를 위하여 간단히 텍스트 내의 <strong>punctuation</strong>과 <strong>stopwords</strong>를 제거하는 함수를 정의하였다.</li><li>워낙 데이터가 커서 함수 호출 시 처리 속도가 오래 걸린다. 그래서 속도를 위해 <strong>list comprehension</strong>과 <strong>lambda</strong>로 처리하였는데 그래도 처리까지 시간이 꽤 걸렸다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Clean Punctuation &amp; Stopwords</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">clean_text</span>:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, text)</span>:</span></span><br><span class="line">self.text = text</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove Punctuation</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rm_punct</span><span class="params">(text)</span>:</span></span><br><span class="line">punct = set([p <span class="keyword">for</span> p <span class="keyword">in</span> <span class="string">"/-'?!.,#$%\'()*+-/:;&lt;=&gt;@[\\]^_`&#123;|&#125;~`"</span> + <span class="string">'""“”’'</span> + <span class="string">'∞θ÷α•à−β∅³π‘₹´°£€\×™√²—–&amp;'</span>])</span><br><span class="line">text = [t <span class="keyword">for</span> t <span class="keyword">in</span> text <span class="keyword">if</span> t <span class="keyword">not</span> <span class="keyword">in</span> punct]</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="string">""</span>.join(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove Stopwords</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rm_stopwords</span><span class="params">(text)</span>:</span></span><br><span class="line">word_tokens = word_tokenize(text)   </span><br><span class="line">result = [w <span class="keyword">for</span> w <span class="keyword">in</span> word_tokens <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stop_words]</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="string">" "</span>.join(result)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># remove punctuation </span></span><br><span class="line">train_df[<span class="string">'comment_text'</span>] = train_df[<span class="string">'comment_text'</span>].apply(<span class="keyword">lambda</span> x: clean_text.rm_punct(x))</span><br><span class="line">test_df[<span class="string">'comment_text'</span>] = test_df[<span class="string">'comment_text'</span>].apply(<span class="keyword">lambda</span> x: clean_text.rm_punct(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove stopwords</span></span><br><span class="line">X_train = train_df[<span class="string">'comment_text'</span>].apply(<span class="keyword">lambda</span> x: clean_text.rm_stopwords(x))</span><br><span class="line">X_test = test_df[<span class="string">'comment_text'</span>].apply(<span class="keyword">lambda</span> x: clean_text.rm_stopwords(x))</span><br></pre></td></tr></table></figure><p><br></p><h2 id="5-Tokenize"><a href="#5-Tokenize" class="headerlink" title="5. Tokenize"></a>5. Tokenize</h2><ul><li>전처리된 데이터를 keras.Tokenizer를 이용하여 sequences 데이터로 변환한다.</li><li>Tokenizer의 처리 순서는 아래와 같다.<br>— Tokenizer 객체를 통해 데이터를 토큰화시킨 후 각 토큰에 고유 index를 부여하여 word index 생성<br>— texts_to_sequences()를 통해 word index를 기반으로 시퀀스 데이터 생성<br>— pad_sequences()를 통해 padding 추가 </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## tokenize</span></span><br><span class="line">max_words = <span class="number">100000</span></span><br><span class="line">tokenizer = text.Tokenizer(num_words=max_words) <span class="comment"># Tokenizer 객체생성</span></span><br><span class="line">tokenizer.fit_on_texts(X_train)<span class="comment"># 토큰 별 word index 생성</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># texts_to_sequences</span></span><br><span class="line">sequences_text_train = tokenizer.texts_to_sequences(X_train)</span><br><span class="line">sequences_text_test = tokenizer.texts_to_sequences(X_test)</span><br><span class="line"></span><br><span class="line">print(sequences_text_train[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>[[21, 2188, 39, 6, 3, 32, 1115, 116, 48, 91, 277, 26, 138], [323, 21, 3, 25, 107, 142, 144, 105, 7, 159, 125, 9, 28], [21, 9494, 2834, 94, 4342, 340, 1102, 4913], [241, 90, 384, 316, 5764, 1027, 164, 6388], [5230, 586, 998, 2593]]</code></pre><p><strong>texts_to_sequences()</strong>함수를 이용하면 토큰화 된 문자들이 위와 같이 고유 index 번호로 바뀐 채 sequnce 형태로 출력된다.<br><br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add padding</span></span><br><span class="line">max_len = max(len(l) <span class="keyword">for</span> l <span class="keyword">in</span> sequences_text_train)</span><br><span class="line">pad_train = sequence.pad_sequences(sequences_text_train, maxlen=max_len)</span><br><span class="line">pad_test = sequence.pad_sequences(sequences_text_test, maxlen=max_len)</span><br><span class="line"></span><br><span class="line">print(pad_train[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>array([[   0,    0,    0, ...,  277,   26,  138],       [   0,    0,    0, ...,  125,    9,   28],       [   0,    0,    0, ...,  340, 1102, 4913],       [   0,    0,    0, ..., 1027,  164, 6388],       [   0,    0,    0, ...,  586,  998, 2593]])</code></pre><p>max_len 값은 방금 위에서 sequence로 변환한 데이터 중 가장 많은 word 수를 가지는 데이터의 길이를 받은 것이고,<br>모든 데이터를 그 길이 만큼 맞춰주기 위하여 <strong>pad_seqences()</strong>함수를 통해 0값을 채워주게 된다.<br><br></p><h2 id="6-Embedding-LSTM-model"><a href="#6-Embedding-LSTM-model" class="headerlink" title="6. Embedding + LSTM model"></a>6. Embedding + LSTM model</h2><p><img src="/image/embedding_lstm.png" width="850"> </p><ul><li>예측을 위해서 embedding 레이어와 lstm 레이어를 연결하여 딥러닝 모델을 구축하였다.</li><li><strong>Embedding 레이어</strong>는 텍스트 데이터의 단어 사이의 의미관계를 학습하는데 효과적이므로 텍스트 데이터 학습시 많이 사용되며,</li><li>LSTM 모델은 <strong>양방향 LSTM(Bidirectional LSTM)</strong>으로 구축하여 시간적 의미와 상관없이 단어들 사이의 양방향적으로 의미 순서를 학습하도록 하였다.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Embedding_CuDNNLSTM_model</span><span class="params">(max_words, max_len)</span>:</span></span><br><span class="line">sequence_input = layers.Input(shape=(<span class="keyword">None</span>, ))</span><br><span class="line">x = layers.Embedding(max_words, <span class="number">128</span>, input_length=max_len)(sequence_input)</span><br><span class="line">x = layers.SpatialDropout1D(<span class="number">0.3</span>)(x)</span><br><span class="line">x = layers.Bidirectional(layers.CuDNNLSTM(<span class="number">64</span>, return_sequences=<span class="keyword">True</span>))(x)</span><br><span class="line">x = layers.Bidirectional(layers.CuDNNLSTM(<span class="number">64</span>, return_sequences=<span class="keyword">True</span>))(x)</span><br><span class="line"></span><br><span class="line">avg_pool1d = layers.GlobalAveragePooling1D()(x)</span><br><span class="line">max_pool1d = layers.GlobalMaxPool1D()(x)</span><br><span class="line"></span><br><span class="line">x = layers.concatenate([avg_pool1d, max_pool1d])</span><br><span class="line">x = layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x = layers.BatchNormalization()(x)</span><br><span class="line">output = layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(x)</span><br><span class="line"></span><br><span class="line">model = models.Model(sequence_input, output)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## embedding_lstm models </span></span><br><span class="line">model = Embedding_CuDNNLSTM_model(max_words, max_len)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model compile</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line"> loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>, auroc])</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><pre><code>__________________________________________________________________________________________________Layer (type)                    Output Shape         Param #     Connected to                     ==================================================================================================input_1 (InputLayer)            (None, None)         0                                            __________________________________________________________________________________________________embedding_1 (Embedding)         (None, 306, 128)     12800000    input_1[0][0]                    __________________________________________________________________________________________________spatial_dropout1d_1 (SpatialDro (None, 306, 128)     0           embedding_1[0][0]                __________________________________________________________________________________________________bidirectional_1 (Bidirectional) (None, 306, 128)     99328       spatial_dropout1d_1[0][0]        __________________________________________________________________________________________________bidirectional_2 (Bidirectional) (None, 306, 128)     99328       bidirectional_1[0][0]            __________________________________________________________________________________________________global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            __________________________________________________________________________________________________global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            __________________________________________________________________________________________________concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0]                                                                  global_max_pooling1d_1[0][0]     __________________________________________________________________________________________________dense_1 (Dense)                 (None, 32)           8224        concatenate_1[0][0]              __________________________________________________________________________________________________batch_normalization_1 (BatchNor (None, 32)           128         dense_1[0][0]                    __________________________________________________________________________________________________dense_2 (Dense)                 (None, 1)            33          batch_normalization_1[0][0]      ==================================================================================================Total params: 13,007,041Trainable params: 13,006,977Non-trainable params: 64__________________________________________________________________________________________________</code></pre><h4 id="Train-model"><a href="#Train-model" class="headerlink" title="Train model"></a>Train model</h4><ul><li>callback함수는 아래와 같이 사용<br>— ReduceLROnPlateau() : 초기에 학습률을 높게 지정한 후 일정 epoch동안 성능이 향상되지 않을 시 점차 learning rate를 줄여나감<br>— EarlyStopping() : 일정 epoch동안 성능 향상이 없을 시 학습을 조기 종료함.<br>— ModelCheckPoint() : epoch마다 학습 된 모델을 저장, save_best_only=True를 지정하여 성능이 가장 좋은 모델만 지정할 수 있음</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">auroc</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line"><span class="keyword">return</span> tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)</span><br></pre></td></tr></table></figure><p>해당 competition의 평가 모델의 경우 ROC-AUC를 사용하기 때문에 해당 평가지표로 검증하기 위해 acroc라는 함수를 정의.<br><br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># keras.callbacks</span></span><br><span class="line">callbacks_list = [</span><br><span class="line">ReduceLROnPlateau(</span><br><span class="line">monitor=<span class="string">'val_auroc'</span>, patience=<span class="number">2</span>, factor=<span class="number">0.1</span>, mode=<span class="string">'max'</span>),<span class="comment"># val_loss가 patience동안 향상되지 않으면 학습률을 0.1만큼 감소 (new_lr = lr * factor)</span></span><br><span class="line">EarlyStopping(</span><br><span class="line">patience=<span class="number">5</span>, monitor=<span class="string">'val_auroc'</span>, mode=<span class="string">'max'</span>, restore_best_weights=<span class="keyword">True</span>),</span><br><span class="line">ModelCheckpoint(</span><br><span class="line">filepath=<span class="string">'./input/best_embedding_lstm_model.h5'</span>, monitor=<span class="string">'val_auroc'</span>, mode=<span class="string">'max'</span>, save_best_only=<span class="keyword">True</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># model fit &amp; save</span></span><br><span class="line">model_path = <span class="string">'./input/best_embedding_lstm_model.h5'</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(model_path):</span><br><span class="line">model.load_weights(model_path)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">history = model.fit(pad_train, train_y_label,</span><br><span class="line">epochs=<span class="number">7</span>, batch_size=<span class="number">1024</span>,</span><br><span class="line">callbacks=callbacks_list, </span><br><span class="line">validation_split=<span class="number">0.3</span>, verbose=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>Train on 1263411 samples, validate on 541463 samplesEpoch 1/71263411/1263411 [==============================] - 579s 458us/step - loss: 0.1831 - acc: 0.9398 - auroc: 0.9263 - val_loss: 0.2086 - val_acc: 0.9169 - val_auroc: 0.9479Epoch 2/71263411/1263411 [==============================] - 577s 457us/step - loss: 0.1187 - acc: 0.9540 - auroc: 0.9600 - val_loss: 0.1792 - val_acc: 0.9356 - val_auroc: 0.9479Epoch 3/71263411/1263411 [==============================] - 577s 456us/step - loss: 0.1017 - acc: 0.9606 - auroc: 0.9717 - val_loss: 0.2070 - val_acc: 0.9359 - val_auroc: 0.9424Epoch 4/71263411/1263411 [==============================] - 576s 456us/step - loss: 0.0707 - acc: 0.9739 - auroc: 0.9866 - val_loss: 0.1806 - val_acc: 0.9386 - val_auroc: 0.9227Epoch 5/71263411/1263411 [==============================] - 576s 456us/step - loss: 0.0639 - acc: 0.9762 - auroc: 0.9890 - val_loss: 0.1942 - val_acc: 0.9345 - val_auroc: 0.9218Epoch 6/71263411/1263411 [==============================] - 577s 457us/step - loss: 0.0584 - acc: 0.9785 - auroc: 0.9908 - val_loss: 0.1988 - val_acc: 0.9374 - val_auroc: 0.9190</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot score by epochs</span></span><br><span class="line">auroc = history.history[<span class="string">'auroc'</span>]</span><br><span class="line">val_auroc = history.history[<span class="string">'val_auroc'</span>]</span><br><span class="line">epochs = range(<span class="number">1</span>, len(auroc)+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">7</span>,<span class="number">3</span>))</span><br><span class="line">plt.plot(epochs, auroc, <span class="string">'b'</span>, label=<span class="string">'auroc'</span>)</span><br><span class="line">plt.plot(epochs, val_auroc, <span class="string">'r'</span>, label=<span class="string">'validation auroc'</span>)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x1176f6fdba8&gt;]</code></pre><p><img src="/image/output_22_1.png" width="500" height="500"></p><p>결과를 보니검증 성능이 epoch이 증가할 수록 떨어지는 것으로 보아 모델이 <strong>과대적합</strong> 된 듯 함. dropout 비율을 더 높이거나, 레이어 수를 줄여야 할 것 같음.</p><h4 id="Predict-test-set"><a href="#Predict-test-set" class="headerlink" title="Predict test set"></a>Predict test set</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## predict test_set</span></span><br><span class="line">test_pred = model.predict(pad_test)</span><br></pre></td></tr></table></figure><h2 id="7-submit-submission-csv"><a href="#7-submit-submission-csv" class="headerlink" title="7. submit submission.csv"></a>7. submit submission.csv</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sample_result = pd.DataFrame()</span><br><span class="line">sample_result[<span class="string">'id'</span>] = test_df.index</span><br><span class="line">sample_result[<span class="string">'prediction'</span>] = test_pred</span><br><span class="line"></span><br><span class="line"><span class="comment">## submit sample_submission.csv</span></span><br><span class="line">sample_result.to_csv(<span class="string">'submission.csv'</span>, index=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>최종 제출 결과 91.1% 라는 검증 결과가 나와 상위 84%…. 문제를 제대로 이해를 안하고 시작해서 그런지 모델 수정으로는 이 이상 성능 향상이 되지 않았다. 다른 상위 커널을 살펴보니 대부분 <strong>feature engineering부분에서 텍스트 처리</strong>에 많은 노력을 기울인 것 같다.<br>더 수정해서 해보려고 했는데, 제출 기간이 아쉽게 종료가 되어 더 진행해보지는 않았다. </p><p>최근 <strong>정권우님이 쓰신 ‘머신러닝 탐구생활’</strong>이라는 책을 구매하였는데, 다양한 kaggle문제를 어떻게 접근해야 하는지, 또 최근 kaggle내에서 어떤 모델이 주로 사용되는지 트렌드를 살펴볼 수 있을 것 같아 열심히 읽어보는 중이다. 완독 후 다시 다른 캐글 문제에 도전해봐야겠다!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;얼마 전 캐글에서 구글 Jigsaw/Conversation AI팀에 의해 &lt;a href=&quot;https://
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="lstm" scheme="https://jaehyeongan.github.io/tags/lstm/"/>
    
      <category term="embedding" scheme="https://jaehyeongan.github.io/tags/embedding/"/>
    
      <category term="kaggle" scheme="https://jaehyeongan.github.io/tags/kaggle/"/>
    
      <category term="competition" scheme="https://jaehyeongan.github.io/tags/competition/"/>
    
      <category term="google" scheme="https://jaehyeongan.github.io/tags/google/"/>
    
      <category term="jigsaw" scheme="https://jaehyeongan.github.io/tags/jigsaw/"/>
    
      <category term="toxicity" scheme="https://jaehyeongan.github.io/tags/toxicity/"/>
    
      <category term="classification" scheme="https://jaehyeongan.github.io/tags/classification/"/>
    
      <category term="bidirectionallstm" scheme="https://jaehyeongan.github.io/tags/bidirectionallstm/"/>
    
  </entry>
  
  <entry>
    <title>[딥러닝을 위한 수학기초 03] 미분, 편미분</title>
    <link href="https://jaehyeongan.github.io/2019/06/25/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%88%98%ED%95%99%EA%B8%B0%EC%B4%88-3/"/>
    <id>https://jaehyeongan.github.io/2019/06/25/딥러닝을-위한-수학기초-3/</id>
    <published>2019-06-25T14:59:47.000Z</published>
    <updated>2021-02-07T14:58:12.524Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>본 글은 ‘처음 배우는 딥러닝 수학(한빛미디어)’이라는 책의 ‘chap.02 신경망을 위한 수학기초’ 를 정리한 글입니다.</p><hr><h3 id="1-미분"><a href="#1-미분" class="headerlink" title="1. 미분"></a>1. 미분</h3><ul><li>도함수: 어떤 함수 안에 포함도니 값 각각이 0에 한없이 가까워지는 극한값(미분계수)을 구하는 함수</li><li><p>y = f(x)의 도함수 f’(x)는 아래와 같이 정의<br><img src="/image/미분정의.JPG" width="250"> </p></li><li><p>f(x) = 3x일 때, 도함수 계산 과정<br><img src="/image/미분과정1.JPG" width="400"> </p></li><li><p>f(x) = x^2일떄, 도함수 계산 과정<br><img src="/image/미분과정2.JPG" width="450"></p></li><li><p>함수 f(x)의 도함수f’(x)를 구하는 것을 “함수 f(x)를 미분한다”라고 하며, 위와 같이 값을 계산할 수 있다면 미분 가능이라고 함<br><br></p></li></ul><h4 id="미분기호"><a href="#미분기호" class="headerlink" title="미분기호"></a>미분기호</h4><ul><li>y = f(x)의 도함수 f’(x)를 극한 개념이 아닌 분수로 표현하는 방법</li><li>f’(x) = dy/dx </li></ul><h4 id="미분-성질"><a href="#미분-성질" class="headerlink" title="미분 성질"></a>미분 성질</h4><ul><li><p>미분의 선형성<br><img src="/image/미분의선형성.JPG" width="250"></p><blockquote><p><em>함수 합의 미분은 각 함수를 미분한 합과 같다.</em><br><em>상수를 곱한 함수의 미분은 미분한 함수에 상수를 곱한 것과 같다.</em></p></blockquote></li></ul><p><br></p><h4 id="시그모이드-함수의-미분"><a href="#시그모이드-함수의-미분" class="headerlink" title="시그모이드 함수의 미분"></a>시그모이드 함수의 미분</h4><p> <img src="/image/시그모이드미분.JPG" width="200"></p><ul><li>위의 식을 이용하면 미분하지 않아도 시그모이드 함수의 도함수값을 sigma(x)의 값에서 얻을 수 있음.<br><img src="/image/시그모이드미분2.JPG" width="450"><br><br></li></ul><h4 id="최솟값의-필요조건"><a href="#최솟값의-필요조건" class="headerlink" title="최솟값의 필요조건"></a>최솟값의 필요조건</h4><p> <img src="/image/최솟값필요조건1.JPG" width="530"></p><blockquote><p><em>함수 f(x)가 x = 0일 때 최솟값이라면 f’(a)=0</em><br> <em>f’(a)=0는 함수 f(x)가 x = a에서 최솟값이 되기 위한 “필요”조건. 이는 접선의 기울기가 0이더라도 꼭 최솟값이라는 보장이 없다는 의미</em></p></blockquote><p> <img src="/image/최솟값필요조건2.JPG" width="650"></p><ul><li>경사하강법은 접선의 기울기가 낮은 쪽으로 계속 이동시켜서 최솟값을 구함</li><li>함수 전체의 최솟값과 값이 커지거나 작아질 때 발생하는 극솟값/극댓값을 혼동할 수 있으니, 경사하강법으로 최솟값을 구할 때 주의해야 함<br><br></li></ul><h3 id="2-편미분"><a href="#2-편미분" class="headerlink" title="2. 편미분"></a>2. 편미분</h3><h4 id="다변수-함수"><a href="#다변수-함수" class="headerlink" title="다변수 함수"></a>다변수 함수</h4><ul><li>독립변수가 2개 이상인 함수 </li></ul><h4 id="편미분"><a href="#편미분" class="headerlink" title="편미분"></a>편미분</h4><ul><li>다변수 함수의 경우 변수가 여러 개 있으므로 어떤 변수를 미분할지 명시해야 하는데, 이렇게 특정 변수를 명시해 미분하는 것을 편미분이라고 함 </li><li>z = f(x, y)일 때, 변수 x를 미분하고 y를 상수로 취급하는 것을 ‘x에 관한 편미분’이라고 함</li><li>x에 관한 편미분<br><img src="/image/편미분x.JPG" width="400"></li><li><p>y에 관한 편미분<br><img src="/image/편미분y.JPG" width="400"></p></li><li><p>z = wx+b에 관한 편미분<br><img src="/image/z=wx+b편미분.JPG" width="250"></p></li></ul><p><br></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;본 글은 ‘처음 배우는 딥러닝 수학(한빛미디어)’이라는 책의 ‘chap.02 신경망을 위한 수학기초’ 를
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="math" scheme="https://jaehyeongan.github.io/tags/math/"/>
    
      <category term="neuralnetwork" scheme="https://jaehyeongan.github.io/tags/neuralnetwork/"/>
    
      <category term="derivative" scheme="https://jaehyeongan.github.io/tags/derivative/"/>
    
      <category term="partialderivative" scheme="https://jaehyeongan.github.io/tags/partialderivative/"/>
    
  </entry>
  
  <entry>
    <title>[딥러닝을 위한 수학기초 02] 수열, 시그마, 벡터, 행렬</title>
    <link href="https://jaehyeongan.github.io/2019/06/20/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%88%98%ED%95%99%EA%B8%B0%EC%B4%88-2/"/>
    <id>https://jaehyeongan.github.io/2019/06/20/딥러닝을-위한-수학기초-2/</id>
    <published>2019-06-20T09:38:25.000Z</published>
    <updated>2021-02-07T14:57:54.698Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>본 글은 ‘처음 배우는 딥러닝 수학(한빛미디어)’이라는 책의 ‘chap.02 신경망을 위한 수학기초’ 를 정리한 글입니다.</p><hr><h3 id="1-수열"><a href="#1-수열" class="headerlink" title="1. 수열"></a>1. 수열</h3><ul><li>수열은 ‘숫자 열’을 의미, 예를 들어 2,4,6,8,10,.. 로 진행되면 짝수열이라는 수열임</li><li>수열에서 정렬하는 숫자 하나하나를 항이라고 함. 첫번째 항은 1항, 두번째 항은 2항, n번째 항은 n항</li><li>신경망의 수열은 유한개의 항 수를 갖는 수열로서 유한수열이라고 함</li></ul><h4 id="수열과-점화식"><a href="#수열과-점화식" class="headerlink" title="수열과 점화식"></a>수열과 점화식</h4><ul><li>점화식이란 이웃에 있는 항의 관계로 표현하는 수열의 귀납적 정의.</li><li>일반적으로 1항 A1과 인접한 2개의 항 An, An+1의 관계식으로 수열 {An}을 표현<br><p><br><img src="/image/점화식1.JPG" width="400"> </p></li></ul><h4 id="연립-점화식"><a href="#연립-점화식" class="headerlink" title="연립 점화식"></a>연립 점화식</h4><ul><li>여러 수열이 몇 가지 관계식으로 연결된 것을 연립 점화식이라고 함.</li><li>신경망에서는 모든 유닛의 입력과 출력이 연립 점화식으로 연결되어 있음<br><p><br><img src="/image/연립점화식.JPG" width="350"><br><br></p></li></ul><h3 id="2-시그마-기호"><a href="#2-시그마-기호" class="headerlink" title="2. 시그마 기호"></a>2. 시그마 기호</h3><ul><li>위에서 살펴본 수열의 합을 간결하게 표현하는 것이 시그마 기호.</li><li>1항부터 n항까지의 수열의 합을 시그마 기호로 나타내면 아래와 같음<br><img src="/image/시그마수열의합.JPG" width="350"> </li><li>시그마 기호에 있는 문자 k는 항 숫자를 의미.<br><br></li></ul><h4 id="시그마-기호의-특징-선형성"><a href="#시그마-기호의-특징-선형성" class="headerlink" title="시그마 기호의 특징 - 선형성"></a>시그마 기호의 특징 - 선형성</h4><ul><li>시그마 기호는 ‘선형성’이라는 특징을 가지고 있음.<br><img src="/image/시그마선형성.JPG" width="350"></li><li>위 식을 실제 수열로 전개하면 아래와 같음.<br><img src="/image/수열전개.JPG" width="550"><br><br></li></ul><h3 id="3-행렬"><a href="#3-행렬" class="headerlink" title="3. 행렬"></a>3. 행렬</h3><p>행렬(matrix)은 수와 식을 사각 형태로 나열한 것으로 다음과 같이 표현<br><img src="/image/행렬.JPG" width="150"></p><ul><li>가로줄은 행, 세로줄은 열</li><li>위 그림과 같이 3행, 3열로 구성된 행렬은 3x3행렬</li><li>정사각행렬이란 행과 열 수가 같은 행렬 </li><li>아래와 같이 하나의 열이나 행으로 구성된 행렬 X, Y를 차례로 열벡터, 행백터라고 함.<br><img src="/image/행열벡터.JPG" width="250"><br><br></li></ul><h4 id="행렬의-상등"><a href="#행렬의-상등" class="headerlink" title="행렬의 상등"></a>행렬의 상등</h4><ul><li>두 행렬 A, B는 대응하는 각 성분이 같을 때 상등이라고 하며, 기호로는 A = B로 표현</li><li>예를 들어, 행렬 A와 B가 아래와 같을 때,<br><img src="/image/행렬의상등.JPG" width="250"></li><li>이때 A = B가 되는 x, y, u, v는 2, 7, 1, 8<br><br></li></ul><h4 id="행렬의-합과-차-상수-배"><a href="#행렬의-합과-차-상수-배" class="headerlink" title="행렬의 합과 차, 상수 배"></a>행렬의 합과 차, 상수 배</h4><ul><li>두 행렬 A, B의 합 A+B, 차 A-B는 같은 위치 성분끼리의 합과 차로 정의</li><li>행렬의 상수 배는 각 성분에 해당 상수를 곱한 것으로 정의<br><img src="/image/행렬의합과차.JPG" width="500"><br><br></li></ul><h4 id="행렬의-곱셈"><a href="#행렬의-곱셈" class="headerlink" title="행렬의 곱셈"></a>행렬의 곱셈</h4><ul><li>행렬의 곱셈은 신경망 층 사이의 신호의 합 등을 계산할 때 이용되기 때문에 특히 중요</li><li><p>행렬의 곱셈은 다음과 같이 정의</p><blockquote><p><em>두 행렬 A, B의 곱 AB는 i행을 행벡터로, B의 j열을 열벡터로 생각했을 때, 행벡터와 열벡터의 내적을 i행 j열의 성분으로 하는 행렬</em></p></blockquote></li><li><p>행렬 곱셈의 예<br><img src="/image/행렬의곱.JPG" width="450"></p></li><li>위 예처럼 행렬 곱셈에서는 교환법칙이 성립하지 않음(AB ≠ BA)<br><br></li></ul><h4 id="아다마르-곱"><a href="#아다마르-곱" class="headerlink" title="아다마르 곱"></a>아다마르 곱</h4><ul><li>같은 행과 열 수를 갖는 행렬 A, B에서 같은 위치의 성분을 곱한 행렬을 ‘행렬 A, B의 아다마르 곱’이라고 함 </li><li>기호 AㅇB로 표현<br><img src="/image/아다마르곱.JPG" width="350"><br><br></li></ul><h4 id="전치행렬"><a href="#전치행렬" class="headerlink" title="전치행렬"></a>전치행렬</h4><ul><li>행렬 A의 i행 j열 값을 j행 i열로 바꿔 얻는 행렬을 행렬 A의 전치행렬(Transposed Matrix)라고 함<br><img src="/image/전치행렬.JPG" width="300"></li><li>행렬 A와 B가 아래와 같을 때 전치행렬 A와 행렬B의 곱셈구하는 식<br><img src="/image/전치행렬곱.JPG" width="600"></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;본 글은 ‘처음 배우는 딥러닝 수학(한빛미디어)’이라는 책의 ‘chap.02 신경망을 위한 수학기초’ 를
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="sigma" scheme="https://jaehyeongan.github.io/tags/sigma/"/>
    
      <category term="vector" scheme="https://jaehyeongan.github.io/tags/vector/"/>
    
      <category term="matrix" scheme="https://jaehyeongan.github.io/tags/matrix/"/>
    
      <category term="neuralnetwork" scheme="https://jaehyeongan.github.io/tags/neuralnetwork/"/>
    
  </entry>
  
  <entry>
    <title>[딥러닝을 위한 수학기초 01] 신경망의 필수 함수</title>
    <link href="https://jaehyeongan.github.io/2019/06/19/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9C%84%ED%95%9C-%EC%88%98%ED%95%99%EA%B8%B0%EC%B4%88-1/"/>
    <id>https://jaehyeongan.github.io/2019/06/19/딥러닝-위한-수학기초-1/</id>
    <published>2019-06-19T14:21:25.000Z</published>
    <updated>2021-02-07T14:57:44.318Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>본 글은 ‘처음 배우는 딥러닝 수학(한빛미디어)’이라는 책의 ‘chap.02 신경망을 위한 수학기초’ 를 정리한 글입니다.</p><hr><h3 id="1-1차-함수"><a href="#1-1차-함수" class="headerlink" title="1. 1차 함수"></a>1. 1차 함수</h3><p><img src="/image/1차함수.JPG" width="300"></p><ul><li>a를 기울기, b를 절편이라고 하며 두 변수 x, y가 위 식의 관계를 만족할 때 변수 y는 변수 x와 ‘1차 함수 관계’라고 함</li><li>1차함수를 그래프로 그리면 아래와 같은 직선으로 나타남<br><img src="/image/1차함수그래프.JPG" width="300"></li></ul><ul><li>y = 2x+1의 그래프라면, 절편은 1, 기울기는 2(아래 왼쪽)</li><li>y = -2x-1의 그래프라면, 절편은 -1, 기울기는 -2(아래 오른쪽)<br><img src="/image/1차함수그래프2.JPG" width="550"></li></ul><p>1차 함수는 독립변수가 여러 개일 때도 있음<br><img src="/image/1차함수2.JPG" width="500"></p><p>신경망에서 유닛이 받는 ‘가중 입력’은 1차 함수 관계로 표현. 예를 들어 아래층에서 3개의 입력 신호를 받은 유닛의 가중 입력 z는 아래와 같이 표현.<br><img src="/image/유닛가중입력.JPG" width="310"></p><ul><li>가중치 w1, w2, w3와 편향 b를 상수 파라미터라고 생각하면 가중 입력 z는 입력 x1, x2, x3과 1차함수 관계</li><li>또한 유닛이 받는 x1, x2, x3을 입력 데이터값으로 확정했다면 가중 입력 z는 가중치 w1, w2, w3 및 편향 b와 1차 함수 관계<br><br></li></ul><h3 id="2-2차-함수"><a href="#2-2차-함수" class="headerlink" title="2. 2차 함수"></a>2. 2차 함수</h3><p><img src="/image/2차함수.JPG" width="400"></p><p>2차 함수 그래프에서 중요한 것은 a가 양수일 때는 아래로 볼록한 그래프고, 최솟값이 존재한다는 점.<br> <img src="/image/2차함수그래프.JPG" width="310"><br><br></p><h3 id="3-단위-계단-함수"><a href="#3-단위-계단-함수" class="headerlink" title="3. 단위 계단 함수"></a>3. 단위 계단 함수</h3><p><img src="/image/단위계단함수.JPG" width="600"></p><ul><li>u(-1) = 0, u(1) = 1, u(0) = 1</li><li>단위 계단 함수는 원점에서 불연속 즉, ‘미분 불가능’</li><li>미분 불가능한 특성으로 인해 신경망의 활성화 함수로 잘 사용되지 않음.<br><br></li></ul><h3 id="4-지수함수와-시그모이드-함수"><a href="#4-지수함수와-시그모이드-함수" class="headerlink" title="4. 지수함수와 시그모이드 함수"></a>4. 지수함수와 시그모이드 함수</h3><p><img src="/image/지수함수.JPG" width="300"></p><ul><li>위와 같은 식을 지수함수라고 함.</li><li>상수 a는 지수함수의 밑(base)라고 하며, 밑의 값으로 특히 중요한 것은 자연상수 e</li><li>e = 2.718281828…</li></ul><p><img src="/image/시그모이드식.JPG" width="380"></p><ul><li>자연상수를 포함하는 지수함수를 분모로 갖는 함수가 시그모이드 함수</li><li>신경망에서 사용되는 대표적인 활성화 함수</li><li>시그모이드 함수는 아래와 같이 S자형태의 그래프로 그려짐<br><img src="/image/시그모이드그래프.JPG" width="400"><br><br></li></ul><h3 id="5-정규분포의-확률밀도함수"><a href="#5-정규분포의-확률밀도함수" class="headerlink" title="5. 정규분포의 확률밀도함수"></a>5. 정규분포의 확률밀도함수</h3><ul><li>신경망을 컴퓨터에서 설정할 때 가중치 및 편향의 초깃값을 설정해야 하는데 이 초기값을 구할 때 도움이 되는 것이 정규 분포임.</li><li>이 분포를 따르는 정규분포 난수를 초깃값으로 사용하면 신경망 계산 시 좋은 결과를 얻는다고 알려져 있음.</li><li><p>정규분포는 확률밀도함수 f(x)를 따르는 확률분포를 말함(아래 식)<br><img src="/image/정규분포식.JPG" width="300"></p></li><li><p>mu은 기댓값(평균값), sigma는 표준편차라고 하며 모두 상수임. 그래프는 종 모양<br><img src="/image/정규분포그래프.gif" width="350"></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;본 글은 ‘처음 배우는 딥러닝 수학(한빛미디어)’이라는 책의 ‘chap.02 신경망을 위한 수학기초’ 를
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="math" scheme="https://jaehyeongan.github.io/tags/math/"/>
    
      <category term="sigmoid" scheme="https://jaehyeongan.github.io/tags/sigmoid/"/>
    
      <category term="sigma" scheme="https://jaehyeongan.github.io/tags/sigma/"/>
    
      <category term="vector" scheme="https://jaehyeongan.github.io/tags/vector/"/>
    
      <category term="matrix" scheme="https://jaehyeongan.github.io/tags/matrix/"/>
    
  </entry>
  
  <entry>
    <title>아나콘다(Anaconda) 가상환경 만들기</title>
    <link href="https://jaehyeongan.github.io/2019/06/14/%EC%95%84%EB%82%98%EC%BD%98%EB%8B%A4-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD-%EB%A7%8C%EB%93%A4%EA%B8%B0/"/>
    <id>https://jaehyeongan.github.io/2019/06/14/아나콘다-가상환경-만들기/</id>
    <published>2019-06-13T15:29:09.000Z</published>
    <updated>2020-10-28T15:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>지난번에 <a href="https://jaehyeongan.github.io/2019/04/09/machine-learning-%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/">data science를 위해 아나콘다를 설치하는 법</a>을 알아보았는데, 실제 업무에서 여러 머신러닝 프로젝트를 동시에 수행할 경우 각 프로젝트가 요구하는 환경이 다를 수가 있다. 그런데 한 가지 환경에서 모두 진행할 경우 서로 dependency 에러가 발생하거나 환경이 꼬여버릴 수 있기 때문에 각각 독립된 환경을 만들어주는 것이 좋다.<br>이를 위해 아나콘다에서 독립된 가상환경을 어떻게 만드는지 간단히 알아보자.</p><hr><h2 id="Anaconda-가상환경-생성"><a href="#Anaconda-가상환경-생성" class="headerlink" title="Anaconda 가상환경 생성"></a>Anaconda 가상환경 생성</h2><p>anaconda prompt를 실행하여 아래와 같이 실행해보자.<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; conda info --envs</span><br><span class="line"></span><br><span class="line"># conda environments:</span><br><span class="line">#</span><br><span class="line">base                  *  C:\Users\nonam\Miniconda3</span><br></pre></td></tr></table></figure></p><p>위 명령어는 현재 본인의 아나콘다에 존재하는 환경 목록을 보여주는 명령어이다. base는 기본적인 아나콘다 환경을 말하며 아직 가상환경이 추가되지 않았기 때문에 base 환경만 나오게 된다. </p><h4 id="1-가상환경-추가"><a href="#1-가상환경-추가" class="headerlink" title="1. 가상환경 추가"></a>1. 가상환경 추가</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; conda create -n test_envs python=<span class="number">3</span>.<span class="number">6</span></span><br></pre></td></tr></table></figure><p>‘conda create -n’ 이라는 명령어를 통해 가상환경을 추가할 수 있으며 바로 뒤에 원하는 가상환경 이름을 적는다.<br>이후 ‘python= x.x’ 을 통해 가상환경의 python version을 설정해줄 수 있다.<br><br> </p><h4 id="2-가상환경-목록-확인"><a href="#2-가상환경-목록-확인" class="headerlink" title="2. 가상환경 목록 확인"></a>2. 가상환경 목록 확인</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; conda info --envs</span><br><span class="line"></span><br><span class="line"># conda environments:</span><br><span class="line">#</span><br><span class="line">base                  *  C:\Users\nonam\Miniconda3</span><br><span class="line">test_envs                C:\Users\nonam\Miniconda3\envs\test_envs</span><br></pre></td></tr></table></figure><p>이후 다시 목록을 확인하면 test_envs라는 이름의 환경이 새로 추가된 것을 확인할 수 있다.<br><br> </p><h4 id="3-가상환경-활성화"><a href="#3-가상환경-활성화" class="headerlink" title="3. 가상환경 활성화"></a>3. 가상환경 활성화</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; conda activate test_envs</span><br></pre></td></tr></table></figure><p>‘activate test_envs’와 같이 수행하면 해당 가상환경이 활성화가 되며,<br>원래 활성화 되어있던 (base)가 (test_envs)로 바뀌는 것을 확인할 수 있다.<br><br> </p><h4 id="4-가상환경-비활성화"><a href="#4-가상환경-비활성화" class="headerlink" title="4.  가상환경 비활성화"></a>4.  가상환경 비활성화</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; conda deactivate</span><br></pre></td></tr></table></figure><p>conda deactivate를 통해 현재 활성화 된 가상환경을 비활성화 시킨다.<br><br> </p><h4 id="5-가상환경-제거"><a href="#5-가상환경-제거" class="headerlink" title="5. 가상환경 제거"></a>5. 가상환경 제거</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; conda env remove -n test_env</span><br></pre></td></tr></table></figure><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>가끔 프로젝트를 수행하다보면 실행되는 모듈들이 python 버전에 따라 실행이 되는 것이 있고 안되는 것이 있기도 하고, 의존성 문제로 인해 잘 사용하던 다른 모듈들이 갑자기 다운그레이드 되거나 삭제되는 현상도 있으므로 이렇게 가상환경을 만들어 주어 독립된 환경에서 프로젝트를 수행하는 것이 좋을 것 같다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;지난번에 &lt;a href=&quot;https://jaehyeongan.github.io/2019/04/09/mac
      
    
    </summary>
    
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="anaconda" scheme="https://jaehyeongan.github.io/tags/anaconda/"/>
    
      <category term="miniconda" scheme="https://jaehyeongan.github.io/tags/miniconda/"/>
    
      <category term="datascience" scheme="https://jaehyeongan.github.io/tags/datascience/"/>
    
      <category term="envs" scheme="https://jaehyeongan.github.io/tags/envs/"/>
    
  </entry>
  
  <entry>
    <title>차원축소(Dimensionality Reduction)</title>
    <link href="https://jaehyeongan.github.io/2019/05/27/Dimension-Reduction/"/>
    <id>https://jaehyeongan.github.io/2019/05/27/Dimension-Reduction/</id>
    <published>2019-05-27T12:53:37.000Z</published>
    <updated>2020-12-10T14:51:17.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>많은 경우 머신러닝 문제는 훈련 샘플이 수천 심지어 수백만 개의 특성을 가지고 있다. 이는 모델의 학습을 느리게 할 뿐만 아니라 정교한 모델을 만들기 어렵게 하는데 이러한 문제를 차원의 저주(curse of dimensionality)라고 한다.<br>그리고 이러한 차원의 저주를 해결하기 위해 차원 축소 기법이 이용된다. </p><hr><h2 id="차원의-저주-curse-of-dimensionality"><a href="#차원의-저주-curse-of-dimensionality" class="headerlink" title="차원의 저주(curse of dimensionality)"></a>차원의 저주(curse of dimensionality)</h2><p>현재 우리는 3차원의 공간에 살고 있어 그 보다 큰 4차원, 5차원 이상의 공간을 머리속으로 떠올리기 힘들다.<br><img src="/image/curse_d.png" width="600"></p><p>즉, 차원(Dimensionality)이라는 것은 공간을 뜻하고 위 그림과 같이 1개의 점인 0차원 부터 시작하여 4차원까지 공간은 몇 개의 점과 선을 그리느냐에 따라 무수히 많은 차원을 가지게 된다.</p><p>예를 들어, 단위 면적에서 임의의 두 점을 선택하였을 경우 두 점 사이의 거리는 대략 0.52가 된다. 이를 3차원 큐브에 나타낼 경우 두 점사이의 거리는 0.66정도가 된다. 하지만 만약 1,000,000차원의 초입방체에서 두 점을 무작위로 선택할 경우는 어떨까? 평균 거리는 대략 428.25가 된다. </p><p>차원의 높아짐으로써 두 점 사이를 표현하는 거리가 고무줄처럼 늘어나버렸는데, 이렇듯 고차원의 공간은 사실상 데이터 간 거리가 먼 굉장히 희박한 상태라 할 수 있다. 이것을 데이터 관점에서 보자면 데이터의 사이즈와 크기가 바로 차원이 되며, 데이터의 변수의 크기가 차원의 크기가 되며 변수가 많으면 많을수록 데이터의 차원은 계속해서 커지는 것이다.<br><br></p><h4 id="고차원-데이터-셋의-모델-학습-문제"><a href="#고차원-데이터-셋의-모델-학습-문제" class="headerlink" title="고차원 데이터 셋의 모델 학습 문제"></a>고차원 데이터 셋의 모델 학습 문제</h4><p>데이터를 표현하는 특징과 수가 많을 경우 모델이 더 잘 학습하는 것이 아닐까라는 생각이 들지만, 위에서 말했듯이 차원의 정도가 너무 클 경우 오히려 데이터의 주요 특징들이 희박해지는 현상이 발생하게 되어 모델이 과대적합하게 되는 문제가 발생한다. </p><p>이를 해결하기 위한 한가지 해결책은 훈련 샘플의 밀도가 충분히 높아질 때까지 훈련 세트를 키우는 것인데, 실제로는 일정 밀도에 도달하기 위해 필요한 훈련 샘플 수는 차원 수가 커짐에 따라 기하급수적으로 늘어나게되는 문제가 있다. </p><p>따라서, 다른 해결책으로 차원을 저차원 공간에 펼치는 투영(projection)이나 차원을 축소하는 주성분 분석(PCA)등이 이용된다.<br><br></p><h2 id="차원-축소를-위한-방법"><a href="#차원-축소를-위한-방법" class="headerlink" title="차원 축소를 위한 방법"></a>차원 축소를 위한 방법</h2><h4 id="1-투영-projection"><a href="#1-투영-projection" class="headerlink" title="1. 투영(projection)"></a>1. 투영(projection)</h4><p>고차원 공간에 있는 훈렴 샘플을 저차원 공간으로 그대로 수직으로 투영하는 방법이며, 아래 그림과 같이 3차원 공간에 있는 샘플들은 사실 2차원 공간에 놓아도 데이터들의 특성이 많이 뭉개지지 않게 된다.<br><img src="/image/projection.png" width="700"><br><br></p><p>하지만, 투영하는 것이 모든 상황에 최적인 것은 아니다.<br><img src="/image/swiss_roll.png" width="350"><br>위 그림과 같이 데이터가 말려있을 경우 데이터를 그대로 투영하게 되면 어떻게 될까? 위 데이터 샘플을 그대로 수직으로 투영할 경우, 아래 왼쪽과 같은 그림이 된다.<br><img src="/image/swiss_roll_projection.png" width="600"></p><p>검정, 빨강, 노랑 샘플이 뭉개져버렸기 때문에 2차원에서는 표현을 잘 나타내지를 못하고 있다. 하지만 우리가 원하는 것은 바로 오른쪽과 같이 특성이 뭉개지지 않게 펼쳐진 그림일 것이다. 그리고 이렇게 구부려져 있는 데이터를 반듯이 펴기위해 사용되는 것이 바로 매니폴드 학습이다<br><br></p><h5 id="2-매니폴드-학습-manifold-learning"><a href="#2-매니폴드-학습-manifold-learning" class="headerlink" title="2. 매니폴드 학습(manifold learning)"></a>2. 매니폴드 학습(manifold learning)</h5><p>위에서 보았던 스위스 롤(swiss roll)데이터는 2D 매니폴드의 한 예였다. 한 가지 예를 더 들어 아래와 같은 데이터가 있다고 해보자.<br><img src="/image/manifold1.png" width="300"></p><p>위 데이터들 간의 거리를 직선상의 거리로 보았을 때 A와 C가 서로 가까울까, 아니면 A와 G가 서로 가까울까?<br>위 그림대로 보았을 때는 A와 C보다는 A와 G사이의 거리가 더 가까워 보인다. 하지만 위 데이터가 실은 아래의 그림을 구부려 놓은 그림이었다면 어떨까? 실제로는 어떤 점이 더 가까운가?<br><img src="/image/manifold2.png" width="350"></p><p>위와 같이, 저차원의 데이터가 고차원의 공간에서 휘어지거나 뒤틀려 있는 것을 매니폴드(manifold)라고 하며, 고차원 공간내에서 뒤틀려있는 데이터를 곧게 펴 유클리디안 거리(euclidean distance) 계산을 통해 데이터들 간의 거리를 찾는 학습을 매니폴드 학습(manifold learning)이라고 한다.<br><br></p><h5 id="3-주성분-분석-PCA"><a href="#3-주성분-분석-PCA" class="headerlink" title="3. 주성분 분석(PCA)"></a>3. 주성분 분석(PCA)</h5><p>주성분 분석(Principal Component Analysis)은 데이터의 차원을 축소하고자 할 떄 가장 인기 있게 사용되는 알고리즘이다. </p><p>주성분 분석이란 데이터를 가장 잘 표현하는 초평면을 찾아 분산을 최대로 보존하는 축을 찾는 것이다. 즉, 데이터를 가장 잘 표현하는 n개의 구간을 찾아 그것을 n개의 차원으로 축소하여 표현하는 방법이다.</p><p><img src="/image/pca.png" width="600"></p><blockquote><p>주성분을 찾는 과정</p><ol><li>데이터에 가장 가까운 초평면을 정의한 후, 데이터를 이 평면에 투영 </li><li>임의의 축을 선택 후, 데이터의 분산을 최대한 보존하는 축을 선택 </li><li>선택한 축을 기준으로 직교하는 축을 선택(두번째로 분산을 최대한 보존하는 축)</li><li>위 과정을 반복하며 찾으려는 차원 수만큼 수행 </li></ol></blockquote><p>위의 과정을 통해 찾은 i번째 축을 정의하는 단위 벡터를 i번째 주성분(PC, principal component)라고 하며, 이러한 주성분을 찾는 과정은 특이값 분해(SVD, Singular Value Decomposition)라는 표준 행렬 분해 기술을 통해 이루어 진다.<br><br></p><h2 id="scikit-learn에서-PCA-사용하기"><a href="#scikit-learn에서-PCA-사용하기" class="headerlink" title="scikit-learn에서 PCA 사용하기"></a>scikit-learn에서 PCA 사용하기</h2><p>사이킷런에서 pca를 사용하기 위해서는 sklearn의 preprocessing모듈에서 PCA모델을 이용하면 된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">3</span>)</span><br><span class="line">data_3d = pca.fit_transform(data)</span><br></pre></td></tr></table></figure></p><p>PCA모델의 중요 파라미터는 n_components인데 이것이 바로 축소할 차원의 수이다. 위의 과정은 3차원으로 축소하게 된다.</p><h4 id="breast-cancer-데이터셋에-PCA를-적용"><a href="#breast-cancer-데이터셋에-PCA를-적용" class="headerlink" title="breast cancer 데이터셋에 PCA를 적용"></a>breast cancer 데이터셋에 PCA를 적용</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">cancer = pd.read_csv(<span class="string">'breast_caner.csv'</span>)</span><br><span class="line">cancer.drop([<span class="string">'id'</span>,<span class="string">'diagnosis'</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>) <span class="comment"># 일단 필요없으므로 제외</span></span><br><span class="line"></span><br><span class="line">print(cancer.shape)</span><br><span class="line">print(cancer.head())</span><br></pre></td></tr></table></figure><p><img src="/image/pca_1.JPG" width="1300" height="700"></p><p>위 데이터는 총 30개의 차원을 가진 데이터셋이다. 이를 3개의 차원을 가진 데이터로 차원 축소를 해보려고 한다. 여기서 알아두어야 할 것은 보통 차원 축소를 하기 전에는 먼저 데이터를 정규화 한다는 것이다. 데이터 범위를 정규화 함으로써 데이터간 특성 비교를 쉽게하기 위해서다. </p><p>먼저 Standard Scaler를 통해 데이터를 정규화 한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">cancer_scaled = pd.DataFrame(scaler.fit_transform(cancer), columns=cancer.columns)</span><br><span class="line"></span><br><span class="line">print(cancer_scaled.head())</span><br></pre></td></tr></table></figure></p><p><img src="/image/pca_2.JPG" width="1300" height="700"></p><p>이제 PCA를 통해 3차원으로 축소 후 결과를 살펴본다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">3</span>)</span><br><span class="line">cancer_pca = pca.fit_transform(cancer_scaled)</span><br><span class="line"></span><br><span class="line">print(cancer_pca[:<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p><p><img src="/image/pca_3.JPG" width="350" height="700"></p><p>데이터가 numpy array 형태로 3개의 차원으로 축소가 된 것을 확인할 수 있다. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;많은 경우 머신러닝 문제는 훈련 샘플이 수천 심지어 수백만 개의 특성을 가지고 있다. 이는 모델의 학습을
      
    
    </summary>
    
    
      <category term="pca" scheme="https://jaehyeongan.github.io/tags/pca/"/>
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="dimensionality" scheme="https://jaehyeongan.github.io/tags/dimensionality/"/>
    
      <category term="manifold" scheme="https://jaehyeongan.github.io/tags/manifold/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우(Tensorflow 2.0) GPU버전 사용하기</title>
    <link href="https://jaehyeongan.github.io/2019/05/01/tensorflow%20GPU%EB%B2%84%EC%A0%84%20%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/"/>
    <id>https://jaehyeongan.github.io/2019/05/01/tensorflow GPU버전 사용하기/</id>
    <published>2019-05-01T09:29:10.000Z</published>
    <updated>2020-12-10T14:54:57.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>머신러닝 모델을 학습할때는 크게 와닿지 않지만 복잡한 딥러닝 연산을 할 때 크게 느껴지는 것이 바로 GPU의 유무이다. 딥러닝과 같은 복잡한 matrix 연산을 하기 위해 CPU로 모델을 돌렸다가는 컴퓨터가 운명을 다 할 수 있다.<br>이전에 텍스트 처리 딥러닝 모델을 CPU와 GPU로 돌렸을 때 얼마나 차이나는지 보려고 실험을 했었는데, GPU의 경우 3시간 정도만에 학습이 끝난 반면 CPU의 경우 거의 한나절을 돌아가고도 결과가 나오지 않아 중간에 끊은 적이 있었다. </p><p>본인 컴퓨터에 외장 그래픽이 없다면 할 수 없지만 GPU가 갖춰져 있을 경우 이를 적극 활용하는 것이 정신건강에 좋을 것 같다.<br>하지만, GPU도 다 같은 GPU가 아니다.<br>현재 tensorflow에서 지원하는 GPU는 Nvidia를 기본으로 하며 AMD의 경우 아직 이용하기에 많이 불편하다. </p><hr><h2 id="tensorflow-gpu-설치"><a href="#tensorflow-gpu-설치" class="headerlink" title="tensorflow-gpu 설치"></a>tensorflow-gpu 설치</h2><h4 id="1-CUDA-설치"><a href="#1-CUDA-설치" class="headerlink" title="1. CUDA 설치"></a>1. CUDA 설치</h4><p>우선 CUDA를 설치해야 한다. 현재 CUDA의 경우 최신 버전이 10.2이지만, 확인 결과 아직까지는 공식적으로 tensorflow가 CUDA 10.0버전까지만 지원한다. </p><p><a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA Toolkit Arcive(https://developer.nvidia.com/cuda-toolkit-archive)</a>로 이동하여 아래 화면과 같이 <strong>CUDA Toolkit 10.0</strong>버전을 클릭한다. </p><p><img src="/image/cuda_toolkit.JPG" width="1000"></p><p><br><br>클릭 후 아래와 같이 자신의 운영체제 맞는 것을 선택한 후 다운로드를 실시하고 다운로드 된 설치파일을 다른 조건 변경없이 그대로 설치하면 된다. </p><p><img src="/image/cuda_toolkit2.JPG" width="1000"></p><h4 id="2-cuDNN-다운로드"><a href="#2-cuDNN-다운로드" class="headerlink" title="2. cuDNN 다운로드"></a>2. cuDNN 다운로드</h4><p>CUDA 설치를 완료하였다면 이제 <a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">cuDNN(https://developer.nvidia.com/rdp/cudnn-download)</a>을 다운로드하여 CUDA 디렉토리에 넣어줘야 한다.<br>cuDNN을 설치하기 위해서는 nvidia에 로그인을 해야하므로 가입이 안되어있다면 가입을 한 후 접속하면 된다. </p><p>주의할 점은 위에서 설치한 CUDA버전에 호환되는 cuDNN을 다운로드 해야 한다는 것이다. 위에서 CUDA 10.0버전을 설치해주었기 때문에 cuDNN도 CUDA 10.0에 호환되는 버전(for CUDA 10.0)으로 다운받는다.</p><p><img src="/image/cudnn.JPG" width="1000"></p><p>위 파일을 다운로드 하면 <strong>cudnn-10.0-windows10-x64-v7.5.1.10</strong> 라는 압축파일이 다운로드 되는데, 압축파일을 풀게 되면 그 안에 아래와 같은 파일이 들어있다.</p><p><img src="/image/cudnn2.JPG" width="800"><br><br></p><h4 id="3-cuDNN파일-CUDA-폴더로-복사"><a href="#3-cuDNN파일-CUDA-폴더로-복사" class="headerlink" title="3. cuDNN파일 CUDA 폴더로 복사"></a>3. cuDNN파일 CUDA 폴더로 복사</h4><p>이제부터가 중요한데,<br>방금 전 압축해제 한 폴더의 파일을 모두 복사하여 그대로 처음 설치한 CUDA 폴더로 전부 복사해주어야 한다.<br>우선 압축해제 한 파일들을 전부 복사한 후, <strong>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</strong> 이 경로로 가서 복사한 파일을 그대로 붙여 넣기 해준다.(안에 동일한 파일이 있는데 그냥 덮어씌워주는 것이다.)</p><p><img src="/image/cudnn3.JPG" width="800"><br>(위 경로에 그대로 복사한 파일을 덮어씌운다.)<br><br></p><h4 id="4-환경변수-지정"><a href="#4-환경변수-지정" class="headerlink" title="4. 환경변수 지정"></a>4. 환경변수 지정</h4><p>보통 다른 설정을 건드리지 않고 진행하였을 경우, 환경변수에 아래와 같은 CUDA 경로가 들어있을 것이다. 없다면 아래와 같은 경로를 그대로 환경변수에 지정해준다.<br><img src="/image/path.JPG" width="500"><br><br></p><h4 id="5-tensorflow-gpu-버전-설치"><a href="#5-tensorflow-gpu-버전-설치" class="headerlink" title="5. tensorflow-gpu 버전 설치"></a>5. tensorflow-gpu 버전 설치</h4><p>이후 Anacoda prompt 혹은 CMD 창을 열어 아래와 같은 명령어로 tensorflow-gpu버전을 설치한다.</p><p><strong>&gt; pip install tensorflow-gpu</strong><br>혹은<br><strong>&gt; conda install tensorflow-gpu</strong></p><p><img src="/image/install_tensorflow_gpu.JPG" width="700"><br>(이미 설치되어 있어서 위와 같이 나옴.)<br><br></p><h4 id="6-tensorflow-실행-및-확인"><a href="#6-tensorflow-실행-및-확인" class="headerlink" title="6. tensorflow 실행 및 확인"></a>6. tensorflow 실행 및 확인</h4><p>promt창을 열어 아래와 같이 tensorflow를 import하였을 때  error가 나지 않는다면 우선 tensorflow 설치에 성공한 것이다.<br>설치 된 tensorflow 버전을 확인하고 싶을 때는 tf._<em>version_</em> 을 통해 확인할 수 있다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line">tf.__version__</span><br></pre></td></tr></table></figure></p><p><img src="/image/tensorflow-version.JPG" width="900"></p><p>tensorflow가 GPU버전으로 잘 설치되었고, 나의 GPU를 잘 인식하고 있는지 확인하고 싶다면 아래와 같은 코드를 통해 확인할 수 있다. tensorflow가 인식하는 로컬 device 목록을 보여주게 된다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.client <span class="keyword">import</span> device_lib</span><br><span class="line">device_lib.list_local_devices()</span><br></pre></td></tr></table></figure></p><p><img src="/image/check-tensorflow-gpu.JPG" width="1100"></p><p>내 컴퓨터의 GPU의 경우 GeForce GTX 1050 with MAX-Q인 것을 확인할 수 있다. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;머신러닝 모델을 학습할때는 크게 와닿지 않지만 복잡한 딥러닝 연산을 할 때 크게 느껴지는 것이 바로 GP
      
    
    </summary>
    
    
      <category term="keras" scheme="https://jaehyeongan.github.io/tags/keras/"/>
    
      <category term="tensorflow" scheme="https://jaehyeongan.github.io/tags/tensorflow/"/>
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="nvidia" scheme="https://jaehyeongan.github.io/tags/nvidia/"/>
    
      <category term="cuda" scheme="https://jaehyeongan.github.io/tags/cuda/"/>
    
      <category term="cudnn" scheme="https://jaehyeongan.github.io/tags/cudnn/"/>
    
  </entry>
  
  <entry>
    <title>로지스틱 회귀(logistic regression)</title>
    <link href="https://jaehyeongan.github.io/2019/04/27/logistic-regression/"/>
    <id>https://jaehyeongan.github.io/2019/04/27/logistic-regression/</id>
    <published>2019-04-27T05:54:01.000Z</published>
    <updated>2020-12-10T14:53:15.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>이름은 regression이나 분류 알고리즘으로 주로 사용되는 알고리즘이 있다. 바로 로지스틱 회귀(Logistic Regression)이다. 로지스틱 회귀는 샘플이 특정 클래스에 속할 확률을 추정하는 방식으로 동작하는 이진 분류(Binary Classification) 모델이다.</p><hr><h2 id="Logistic-Regression-로지스틱-회귀"><a href="#Logistic-Regression-로지스틱-회귀" class="headerlink" title="Logistic Regression(로지스틱 회귀)"></a>Logistic Regression(로지스틱 회귀)</h2><p>로지스틱 회귀(logistic regression)는 샘플이 특정 클래스에 속할 확률을 추정하는 데 널리 사용된다.(예를 들어 해당 이메일이 spam일 확률과 spam이 아닐 확률)<br>추정 확률이 50% 이상이면 모델은 그 샘플을 해당 클래스(label: 1)에 속한다고 예측하고 50%이하이면 클래스에 속하지 않는다고(label: 0) 예측한다. </p><h4 id="확률-추정"><a href="#확률-추정" class="headerlink" title="확률 추정"></a>확률 추정</h4><p>기존 Regresion으로 분류문제를 해결하고자 할 경우 가장 큰 문제점은 바로 1이상 또는 0이하의 수로 나오는 예측값을 해석하는 일이다. 따라서 0과 1사이의 확률로 표현하여 0.5보다 크면 positive, 0.5보다 작으면 negative로 직관적으로 표현하고자 하는 것이 확률 추정이다.<br>어떤 사건이 일어날 확률은 아래와 같이 표현된다. </p><p><img src="/image/probability.JPG" width="300"></p><p>선형 회귀 모델과 같이 로지스틱 회귀 모델은 입력 특성의 가중치 합을 계산하고 편향을 더한다. 대신 선형 회귀처럼 바로 결과를 출력하지 않고 결괏값의 로지스틱(logistic)을 아래의 식을 통해 출력한다. </p><p><img src="/image/logistic_p.JPG" width="300"><br><br> </p><h4 id="Logit-Function"><a href="#Logit-Function" class="headerlink" title="Logit Function"></a>Logit Function</h4><p>로짓 함수는 X의 값이 주어졌을 때 Y의 확률을 이용한 log odds이며 아래와 같이 나타낸다.<br><img src="/image/logitfunction.JPG" width="400"></p><h4 id="Sigmoid-logistic-Fuction"><a href="#Sigmoid-logistic-Fuction" class="headerlink" title="Sigmoid(=logistic) Fuction"></a>Sigmoid(=logistic) Fuction</h4><p>로지스틱(또는 로짓)은 0과 1사이의 값을 출력하는 시그모이드 함수(Sigmoid Function)이다.(즉, S자 형태)<br>로지스틱 함수는 logit 함수의 역함수 형태로 z에 관환 확률을 산출하며 아래와 같은 식으로 표현된다.</p><p><img src="/image/sigmoid_function.JPG" width="250"></p><p><img src="/image/sigmoid_function.png" width="600"></p><p>위 그래프와 같이 sigmoid function은 S자 형태로 이루어져 있으며 각 클래스에 속할 확률을 0.5를 기준으로 0.5이상이면 양성 클래스(1)로 예측하고, 0.5이하이면 음성 클래스(0)으로 예측한다.<br><img src="/image/logistic_predict.JPG" width="250"><br><br> </p><h4 id="로지스틱-회귀의-비용-함수-Cost-Function"><a href="#로지스틱-회귀의-비용-함수-Cost-Function" class="headerlink" title="로지스틱 회귀의 비용 함수(Cost Function)"></a>로지스틱 회귀의 비용 함수(Cost Function)</h4><p>로지스틱 회귀 모델의 훈련 목적은 양성 샘플(y=1)에 대해서는 높은 확률을 추정하고 음생 샘플(y=0)에 대해서는 낮은 확률을 추정하는 모델의 파라미터 벡터 theta를 찾는 것이다. </p><p>전체 훈련 세트에 대한 비용 함수는 모든 훈련 샘플의 비용을 평균한 것이다. 이를 로그 손실(log loss)라고 부르며 아래와 같은 식으로 표현된다.<br><img src="/image/logistic_loss.JPG" width="600"><br><br> </p><h2 id="로지스틱-회귀-적용"><a href="#로지스틱-회귀-적용" class="headerlink" title="로지스틱 회귀 적용 "></a>로지스틱 회귀 적용 </h2><p>breast cancer 데이터셋에 로지스틱 회귀를 적용해본다.<br>우선 breast cancer 데이터 셋은 총 30개의 features와 암 여부에 해당하는 1개의 y label값을 가지고 있다.<br>scikit-learn의 데이터 셋을 활용하였는데 이 데이터의 경우 이미 z-score 정규화가 되어있는 데이터 셋이다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">breast_cancer = load_breast_cancer()</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">print(X_train.shape)<span class="comment"># (426, 30)</span></span><br><span class="line">print(y_train.shape)<span class="comment"># (426, )</span></span><br></pre></td></tr></table></figure></p><p>훈련 셋과 테스트 셋을 나눈 데이터에 scikit-learn에서 제공하는 로지스틱 회귀 모델을 적용한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">logreg = LogisticRegression(C=<span class="number">0.01</span>).fit(X_train, y_train)</span><br><span class="line">print(<span class="string">"train set score : "</span>, logreg.score(X_train, y_train))  <span class="comment"># 0.934</span></span><br><span class="line">print(<span class="string">"test set score : "</span>, logreg.score(X_test, y_test))   <span class="comment"># 0.930</span></span><br></pre></td></tr></table></figure></p><p>결과를 보았을 때 모델이 train set과 test set에 모두 93%의 정확도로 암을 분류하였는데, 실제로 잘 분류되었는지 test data 중 앞 10개만 실제 값과 비교해보았다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pred_10 = logreg.predict(X_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'실제 값: '</span>,y_test[:<span class="number">10</span>])<span class="comment"># 실제 값:  [1 0 1 1 0 0 0 0 0 1]</span></span><br><span class="line">print(<span class="string">'예측 값: '</span>,pred_10[:<span class="number">10</span>])<span class="comment"># 예측 값:  [1 0 1 1 1 0 1 0 0 1]</span></span><br></pre></td></tr></table></figure></p><p>두 개의 예측값만 빼고(암 아님을 암이라고 예측) 실제 값과 같은 예측결과를 보여준다.<br><br></p><h2 id="Softmax-Regression-소프트맥스-회귀"><a href="#Softmax-Regression-소프트맥스-회귀" class="headerlink" title="Softmax Regression(소프트맥스 회귀)"></a>Softmax Regression(소프트맥스 회귀)</h2><p>로지스틱 회귀 모델은 여러 개의 이진 분류기를 훈련시켜 연결하지 않고도 직접 다중 클래스를 예측하도록 할 수 있다.<br>이를 소프트맥스 회귀(Softmax Regression) 또는 다항 로지스틱 회귀(Multinomial Logistic Regression)라고 한다.</p><p> — 샘플 x가 주어지면 소프트맥스 회귀 모델이 각 클래스 k에 대한 점수를 계산<br> — 그 점수에 소프트맥스 함수(softmax function)을 적용하여 각 클래스의 확률을 추정<br> — 로지스틱 회귀와 마찬가지로 추정 확률이 가장 큰 클래스를 선택<br> — 각 클래스가 될 확률 값을 모두 더하면 1이 됨 </p><ul><li><p>소프트맥스 함수<br><img src="/image/softmax_function.JPG" width="400"><br>— k는 클래스의 수이며, s(x)는 샘플 x에 대한 각 클래스의 점수를 담고 있는 벡터<br><br></p></li><li><p>소프트맥스 회귀 분류기의 예측<br><img src="/image/softmax_predict.JPG" width="700"><br><br></p></li></ul><h4 id="크로스-엔트로피-cross-entropy-비용-함수"><a href="#크로스-엔트로피-cross-entropy-비용-함수" class="headerlink" title="크로스 엔트로피(cross-entropy) 비용 함수"></a>크로스 엔트로피(cross-entropy) 비용 함수</h4><p> — 크로스 엔트로피는 추정된 클래스의 확률이 타깃 클래스에 얼마나 잘 맞는지 측정하는 용도로 사용<br><br></p><h4 id="Softmax-Regression-적용"><a href="#Softmax-Regression-적용" class="headerlink" title="Softmax Regression 적용"></a>Softmax Regression 적용</h4><p>scikit-learn의 LogisticRegression() 클래스에 multi_class 매개변수를 “multinomial”로 바꾸면 소프트맥스 회귀를 사용<br> — 소프트맥스 회귀 사용 시 solver 매개변수를 “lbfgs” 지정<br> — C를 사용하여 l2규제 적용</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">softmax_reg = LogisticRegression(multi_class=<span class="string">'multinomial'</span>, solver=<span class="string">'lbfgs'</span>, C=<span class="number">10</span>)</span><br><span class="line">spftmax_reg.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;이름은 regression이나 분류 알고리즘으로 주로 사용되는 알고리즘이 있다. 바로 로지스틱 회귀(Lo
      
    
    </summary>
    
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="classification" scheme="https://jaehyeongan.github.io/tags/classification/"/>
    
      <category term="regression" scheme="https://jaehyeongan.github.io/tags/regression/"/>
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="logistic" scheme="https://jaehyeongan.github.io/tags/logistic/"/>
    
      <category term="scikitlearn" scheme="https://jaehyeongan.github.io/tags/scikitlearn/"/>
    
  </entry>
  
  <entry>
    <title>선형 모델(Linear Model)</title>
    <link href="https://jaehyeongan.github.io/2019/04/25/Linear-Regression/"/>
    <id>https://jaehyeongan.github.io/2019/04/25/Linear-Regression/</id>
    <published>2019-04-25T06:27:13.000Z</published>
    <updated>2020-12-10T14:52:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>머신러닝을 원리를 이해하기 위해 가장 먼저 배우게 되는 선형 모델(linear models)에 대한 글이다. 선형 모델은 100여 년 전게 개발되었고, 지난 몇십 년 동안 폭넓게 연구되고 현재도 널리 쓰이고 있다. 기본적으로 선형 모델은 입력 특성에 대한 선형 함수를 만들어 예측을 수행한다.</p><hr><h2 id="Linear-Regression-선형-회귀"><a href="#Linear-Regression-선형-회귀" class="headerlink" title="Linear Regression(선형 회귀)"></a>Linear Regression(선형 회귀)</h2><p>회귀의 경우 선형 모델을 위한 일반화된 예측 함수는 아래와 같다. </p><p><img src="/image/linear_.JPG" width="500"></p><p>위 식에서 x[0]부터 x[n]까지는 하나의 데이터 포인트에 대한 특성을 나타내며(특성의 개수는 n+1), w와 b는 모델이 학습할 파라미터이다.그리고 y^은 모델이 만들어낸 예측값이다.<br>위 식은 특성이 하나인 데이터 셋이라면 아래와 같이 1차 방정식으로 단순하게 나타낼 수 있다. </p><p><img src="/image/linear_2.JPG" width="130"></p><p>w[0]는 기울기이고, b는 y축과 만나는 절편(또는 편향)이다. 특성이 많아지면 w는 각 특성에 해당하는 기울기를 모두 가진다. </p><p><img src="/image/linear_regression.png" width="400"><br>[선형 회귀]</p><p></p><p></p><br>선형 회귀는 가장 간단하고 오래된 회귀용 선형 알고리즘이다. 선형 회귀는 예측 값 y^과 실제 값 y 사이의 평균제곱오차(mean squared error)를 최소화 하는 파라미터 w와 b를 찾는다. 평균제곱 오차는 예측값(y^)과 실제값(y)의 차이를 제곱하여 더한 후에 샘플 개수로 나눈 값이다.<p></p><p><img src="/image/mse.JPG" width="350"></p><p></p><p></p><br>아래는 scikit-learn의 LinearRegression을 통해 boston house price를 통한 집 값 예측을 수행하는 코드이다.<p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset</span></span><br><span class="line">X, y = load_boston(<span class="keyword">True</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">####### Linear Regression #######</span></span><br><span class="line">lin_reg = LinearRegression().fit(X_train, y_train)</span><br><span class="line">train_pred = lin_reg.predict(X_train)</span><br><span class="line">test_pred = lin_reg.predict(X_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'MSE of train set: '</span>, mean_squared_error(y_train, train_pred)) <span class="comment"># 19.640</span></span><br><span class="line">print(<span class="string">'MSE of test set: '</span>, mean_squared_error(y_test, test_pred))    <span class="comment"># 29.782</span></span><br></pre></td></tr></table></figure><p>training set과 test set에 대한 MSE가 각각 19.6, 29.7로 나타났다. 이는 모델이 training set에 과대적합(Overfitting)되었다는 이야기다. 하지만 선형회귀에서는 이런 과대적합을 방지할 규제(regularization)방안이 없다. 때문에 규제 방안이 포함되어 있는 알고리즘(Ridge, Lasso, ElasticNet 등)을 이용하는 것이 효율적일 수 있다. 이는 좀 더 아래에서 살펴볼 것이다.<br><br> </p><h2 id="Polynomial-Regression-다항-회귀"><a href="#Polynomial-Regression-다항-회귀" class="headerlink" title="Polynomial Regression(다항 회귀)"></a>Polynomial Regression(다항 회귀)</h2><p>가지고 있는 데이터가 단순한 직선보다 복잡한 형태라면 어떻게 선형회귀를 적용해야 할까? 신기하게도 비선형(Non-lieaner) 데이터를 학습하는 데 선형 모델을 사용할 수 있다. 바로 각 특성의 거듭제곱을 새로운 특성으로 추가하고, 이 확장된 특성을 포함한 데이터셋에 선형 모델을 훈련시키는 것이다. 이런 기법을 다항 회귀(Polynomial Regression)이라고 한다.</p><p>만약 아래와 같이 임의로 만든 2차 방정식의 비선형 데이터가 있다고 해보자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = <span class="number">100</span></span><br><span class="line">X = <span class="number">6</span> * np.random.rand(m,<span class="number">1</span>)<span class="number">-3</span></span><br><span class="line">y = <span class="number">0.5</span>*X**<span class="number">2</span>+X+<span class="number">2</span>+np.random.randn(m,<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/image/polynomial_data.png" width="400"></p><p>위와 같은 데이터가 non-linear 데이터인데 선형회귀 모델을 위 데이터에 적용해보면,<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X, y)</span><br><span class="line">pred = lin_reg.predict(X)</span><br></pre></td></tr></table></figure></p><p><img src="/image/predict_poly.JPG" width="400"></p><p>위 그림과 같이 데이터의 비선형적 패턴을 전혀 파악하지 못한 채 1차 직선으로만 예측을 하게 된다.<br>이제 이러한 비선형 데이터를 선형 예측하기 위해 위 데이터에 각 특성을 제곱하여 새로운 특성을 추가한다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line">poly_features = PolynomialFeatures(degree=<span class="number">2</span>, include_bias=<span class="keyword">False</span>)</span><br><span class="line">X_poly = poly_features.fit_transform(X)</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X_poly, y)</span><br><span class="line">pred = lin_reg.predict(X_poly)</span><br></pre></td></tr></table></figure><p><img src="/image/poly_predict.png" width="400"><br>데이터에 새로운 다항 특성을 추가하였을 때 선형 모델이 데이터의 패턴을 파악하여 예측하는 특성을 보여주고 있다.<br>위 데이터의 실제 함수는,<br><img src="/image/p_li_1.JPG" width="230"><br>이고, 예측 모델의 함수는,<br><img src="/image/p_li_2.JPG" width="250"><br>이므로 실제 값과 예측 값의 차이가 많지 않음을 알 수 있다.<br><br> </p><h2 id="Regularized-Linear-Regression-규제가-있는-선형-모델"><a href="#Regularized-Linear-Regression-규제가-있는-선형-모델" class="headerlink" title="Regularized Linear Regression(규제가 있는 선형 모델)"></a>Regularized Linear Regression(규제가 있는 선형 모델)</h2><p>위에서 살펴보았듯 이 선형 모델의 경우 모델이 훈련 데이터 셋에 과대적합(overfitting)되더라도 모델을 규제할 방안이 없다. 따라서, 과대적합을 감소시키기 위해서는 모델의 가중치(weight)를 규제(제한)함으로써 과대적합되기 어렵게 만들어야 한다.</p><p>이렇게 가중치를 제한하는 알고리즘으로 릿지(Ridge), 라쏘(Lasso), 엘라스팃넷(ElasticNet) 회귀에 대해 살펴보려고 한다. </p><h4 id="1-Ridge-Regression-릿지-회귀"><a href="#1-Ridge-Regression-릿지-회귀" class="headerlink" title="1. Ridge Regression(릿지 회귀)"></a>1. Ridge Regression(릿지 회귀)</h4><p>선형 회귀에 규제가 추가된 회귀 모델이다. 규제항이 비용함수에 추가 되며 이는 학습 알고리즘을 데이터에 맞추는 것뿐만 아니라 모델의 가중치가 가능한 한 작게 유지되도록 한다. 규제항은 훈련하는 동안에만 비용함수에 추가되고, 훈련이 끝나면 모델의 성능을 규제가 없는 성능 지표로 평가한다.</p><ul><li>선형회귀에 규제(L2: 가중치들의 제곱합을 최소화)를 걸어 과대적합을 방지</li><li>하이퍼파라미터 a(alpha)는 모델을 얼마나 규제할지 조절 </li><li>a = 0 이면, 릿지 회쉬는 선형회귀와 같음</li><li><p>a 가 아주 크면 모든 가중치가 거의 0에 가까워지고 결국 데이터의 평균을 지나는 수평선이 됨<br><br><br>릿지 회귀의 비용함수는 아래 수식과 같다.<br><img src="/image/ridge_mse.JPG" width="350"></p><p>위에서 보았던 boston house price 예측에 ridge 회귀를 적용할 경우 선형 회귀보다 더 나은 성능을 얻을 수 있다.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####### Ridge Regression ####### </span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"></span><br><span class="line">ridge = Ridge(alpha=<span class="number">0.1</span>).fit(X_train, y_train)</span><br><span class="line">train_pred = ridge.predict(X_train)</span><br><span class="line">test_pred = ridge.predict(X_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'MSE of train set: '</span>, mean_squared_error(y_train, train_pred)) <span class="comment"># 19.645</span></span><br><span class="line">print(<span class="string">'MSE of test set: '</span>, mean_squared_error(y_test, test_pred))    <span class="comment"># 29.878</span></span><br></pre></td></tr></table></figure><p><br> </p><h4 id="2-Lasso-Regression-라쏘-회귀"><a href="#2-Lasso-Regression-라쏘-회귀" class="headerlink" title="2. Lasso Regression(라쏘 회귀)"></a>2. Lasso Regression(라쏘 회귀)</h4><p>라쏘 회귀 역시 선형 회귀에 규제가 추가된 모델이며, 릿지 회귀에서 사용된 L2 규제가 아닌 가중치 벡터의 L1 노름을 사용한다. 라쏘 회귀의 가장 중효한 특징은 덜 중요한 특성의 가중치를 완전히 제거하려고 한다는 것이다. </p><ul><li>자동으로 덜 중요한 특성을 제거하는 특성 선택(feature selection)을 수행하고 희소 모델(spare model)을 만듬(즉, 0이아닌 특성의 가중치가 작음)</li><li><p>이를 통해 모델을 이해하기 쉬워지고 모델의 가장 중요한 특성이 무엇인지 파악 가능<br></p><p></p><br>라쏘 회귀의 비용함수는 아래 수식과 같다.<br><img src="/image/lasso_mse.JPG" width="350"><p></p><p>마찬가지로 boston house에 Lasso 모델을 적용한다.  lasso모델의 coef_ 파라미터를 이용하면 몇 개의 특성이 제외되고 사용되었는지 알 수 있다.</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####### Lasso Regression #######</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"></span><br><span class="line">lasso = Lasso(alpha=<span class="number">0.01</span>, max_iter=<span class="number">100000</span>).fit(X_train, y_train)</span><br><span class="line">train_pred = lasso.predict(X_train)</span><br><span class="line">test_pred = lasso.predict(X_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'MSE of train set: '</span>, mean_squared_error(y_train, train_pred)) <span class="comment"># 19.678</span></span><br><span class="line">print(<span class="string">'MSE of test set: '</span>, mean_squared_error(y_test, test_pred))    <span class="comment"># 30.091</span></span><br><span class="line">print(<span class="string">'사용한 특성의 수 : '</span>,np.sum(lasso.coef_ != <span class="number">0</span>)) <span class="comment"># 13</span></span><br></pre></td></tr></table></figure><p><br> </p><h4 id="3-Elastic-Net-엘라스틱넷"><a href="#3-Elastic-Net-엘라스틱넷" class="headerlink" title="3. Elastic Net(엘라스틱넷)"></a>3. Elastic Net(엘라스틱넷)</h4><p>엘라스틱넷은 릿지 회귀와 라쏘 회귀를 절충한 모델이다. 규제항은 릿지와 회귀의 규제항을 단순히 더해서 사용하며, 혼합 정도는 혼합 비율 r을 사용해 조절한다. </p><ul><li>r = 0이면, 엘라스틱넷은 릿지 회귀와 같고,</li><li><p>r = 1이면, 라쏘 회귀와 같아짐</p><p></p><p></p><br>엘라스틱넷의 비용함수는 아래 수식과 같다.<br><img src="/image/elasticnet_mse.JPG" width="350"><p></p><p>elastic net도 boston house price에 적용.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####### ElasticNet #######</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> ElasticNet</span><br><span class="line"></span><br><span class="line">elastic = ElasticNet(alpha=<span class="number">0.001</span>, max_iter=<span class="number">10000000</span>).fit(X_train, y_train)</span><br><span class="line">train_pred = elastic.predict(X_train)</span><br><span class="line">test_pred = elastic.predict(X_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'MSE of train set: '</span>, mean_squared_error(y_train, train_pred)) <span class="comment"># 19.657</span></span><br><span class="line">print(<span class="string">'MSE of test set: '</span>, mean_squared_error(y_test, test_pred))    <span class="comment"># 29.974</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>그렇다면 선형회귀, 릿지, 라쏘, 엘라스틱넷을 각각 언제, 어떤 상황에 사용해야 좋을까?<br>적어도 규제가 있는 모델이 대부분의 상황에서 좋으므로 일반적으로 선형회귀 모델을 사용하는 것은 피하는 것이 좋다.</p><ul><li>기본적으로 ridge 회귀가 기본이 되어 사용 됨</li><li>하지만, 특성이 많고 그 중 일부분만 중요하다면 lasso나 elastic net이 더 좋은 선택일 수 있음</li><li>또한, 특성 수가 훈련 샘플 수보다 많거나 특성 몇 개가 강하게 연관되어 있을 때는 lasso보다는 elastic net이 선호 됨</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;머신러닝을 원리를 이해하기 위해 가장 먼저 배우게 되는 선형 모델(linear models)에 대한 글이
      
    
    </summary>
    
    
      <category term="regression" scheme="https://jaehyeongan.github.io/tags/regression/"/>
    
      <category term="linear" scheme="https://jaehyeongan.github.io/tags/linear/"/>
    
      <category term="ridge" scheme="https://jaehyeongan.github.io/tags/ridge/"/>
    
      <category term="lasso" scheme="https://jaehyeongan.github.io/tags/lasso/"/>
    
      <category term="elsasticnet" scheme="https://jaehyeongan.github.io/tags/elsasticnet/"/>
    
  </entry>
  
  <entry>
    <title>경사하강법(Gradient Descent)</title>
    <link href="https://jaehyeongan.github.io/2019/04/23/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95-Gradient-Descent/"/>
    <id>https://jaehyeongan.github.io/2019/04/23/경사하강법-Gradient-Descent/</id>
    <published>2019-04-23T12:52:20.000Z</published>
    <updated>2020-12-10T14:55:24.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>최적의 예측 모델을 만들기 위해서는 실제값(true)과 예측값(predict)과의 Error(cost function)가 최소가 되는 모델을 찾는 것이다. 하지만 분석자가 직접 모델의 Cost function을 최소화시키는 파라미터 값을 찾기 위해서는 수십 번의 파라미터 변경이 필요하기 때문에 모델이 학습과정에서 스스로 cost function이 최소가 되도록 파라미터를 조정해나가는 경사하강법(Gradient Decent)이 사용된다.  </p><hr><h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><h4 id="경사하강법-Gradient-Descent"><a href="#경사하강법-Gradient-Descent" class="headerlink" title="경사하강법(Gradient Descent)"></a>경사하강법(Gradient Descent)</h4><p><img src="/image/gradient_descent.png" width="500"></p><p>경사하강법이란 비용함수(Cost Function)을 최소화하기 위하여 반복적해서 파라미터를 조정해나가는 것을 말한다.<br>만약 한 밤 중에 산에서 길을 잃었을 때, 산 밑으로 내려가는 가장 좋은 방법은 무엇일까? 바로 가장 가파른 길을 따라 산 아래로 내려가는 것이다. 이와 같이 최적의 값에 도달하기 위해 가장 빠른 길을 찾는 과정을 경사 하강법의 기본원리라고 할 수 있다.<br>— 파라미터 벡터 theta()에 대해 cost function의 현재 gradient를 계산<br>— theta()의 경우 임의의 값으로 시작해서(random initialization) 조금씩 cost function이 감소되는 방향으로 진행 </p><h4 id="학습률-learning-rate"><a href="#학습률-learning-rate" class="headerlink" title="학습률(learning rate)"></a>학습률(learning rate)</h4><p>경사 하강법에서 중요한 파라미터로서 학습 시 스템(step)의 크기</p><ul><li><p>학습률이 너무 작을 경우<br>— 알고리즘이 수렴하기 위해 반복을 많이 진행해야 하므로 학습 시간이 오래걸림<br>— 지역 최솟값(local minimum)에 수렴할 수 있음 </p></li><li><p>학습률이 너무 클 경우<br>— 학습 시간이 적게 걸리나<br>— 스텝이 너무 커 전역 최솟값(global minimum)을 가로질러 반대편으로 건너뛰어 최솟값에서 멀어질 수 있음</p></li></ul><p><img src="/image/learning_rate_sl.png" width="500"></p><h4 id="경사하강법의-문제점"><a href="#경사하강법의-문제점" class="headerlink" title="경사하강법의 문제점"></a>경사하강법의 문제점</h4><p>— 무작위 초기화(random initialization)으로 인해 알고리즘이 전역 최솟값이 아닌 지역 최솟값에 수렴할 수 있음<br>— 평탄한 지역을 지나기 위해선 시간이 오래 걸리고 일찍 멈추게 되어 전역 최솟값에 도달하지 못할 수 있음<br>— 하지만 선형 회귀(Linear Regression)를 위한 MSE(Mean Squared Error) cost function은 어떤 두점을 선택해 어디에서 선을 그어도 곡선을 가로지르지 않는 볼록 함수(convex function)임<br>— 이는 지역 최솟값이 없고 하나의 전역 최솟값만을 가지는 것을 뜻하며, 연속된 함수이고 기울기가 갑자기 변하지 않음<br><img src="/image/convex_nonconvex.jpg" width="500"></p><p></p><p></p><h2 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h2><p>— 경사하강법을 구현하려면 각 모델 파라미터 theta()에 대해 비용 함수의 그래디언트를 계산해야 함.<br>— 즉, theta()가 조금 변경될 때 비용함수가 얼마나 변하는지 계산해야 하는데 이를 편도 함수(partial derivative)라고 함.<br><img src="/image/partial_derivative.JPG" width="400"><br>— 매 gradient descent step에서 훈련 데이터 전체를 사용<br>— 그렇기 때문에 매우 큰 training set에서는 학습이 매우 느림 </p><p></p><p></p><h2 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent(SGD)"></a>Stochastic Gradient Descent(SGD)</h2><p><img src="/image/sgd.png" width="550"></p><p>— 매 step에서 딱 한 개의 샘플을 무작위로 선택하고 그 하나의 샘플에 대한 gradient를 계산<br>— 매우 적은 데이터를 처리 하기 때문에 학습 속도가 빠르고, 하나의 샘풀만 메모리에 있으면 되므로 매우 큰 training set도 훈련이 가능<br>— cost function이 매우 불규칙할 경우 알고리즘이 local minimum을 건너뛰도록 도와주므로 global minimum을 찾을 가능성이 높음<br>— 하지만 샘플 선택이 확률적(Stochastic)이기 때문에 배치 경사 하강법에 비해 불안정<br>— cost function이 local minimum에 다다를 때까지 부드럽게 감소하지 않고  위아래로 요동치면서 평균적으로 감소</p><p></p><p></p><h2 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h2><p>— mini-batch라 불리는 임의의 작은 샘플 세트에 대해 gradient를 계산<br>— SGD에 비해 matrix 연산에 최적화되어 있으며, 파라미터 공간에서 덜 불규칙하게 학습<br>— 하지만, local minimum에 빠지면 빠져나오기 힘듬</p><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>아래는 batch, mini-bath, stochastic gradient descent의 경사 하강법 진로를 살펴본 그림이다.<br><img src="/image/sgd_mini_batch.png" width="550"><br>(출처 : 핸즈온 머신러닝)</p><p>모두 최솟값 근처에 도달했지만 배치 경사 하강법의 경로가 실제로 최솟값에서 멈춘 반면 확률적 경사 하강법 및 미니배치 경사하강법은 근처에서 맴돌고 있다. 그렇지만 배치 경사 하강법에는 매 스텝에서 많은 시간이 소요되고, 확률적 경사 하강법과 미니배치 경사 하강법도 적절한 학습 스케쥴(learning schedule)을 사용하면 최솟값에 도달할 수 있다.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;최적의 예측 모델을 만들기 위해서는 실제값(true)과 예측값(predict)과의 Error(cost f
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="learningrate" scheme="https://jaehyeongan.github.io/tags/learningrate/"/>
    
      <category term="gradientdescent" scheme="https://jaehyeongan.github.io/tags/gradientdescent/"/>
    
      <category term="batchgd" scheme="https://jaehyeongan.github.io/tags/batchgd/"/>
    
      <category term="minibatchgd" scheme="https://jaehyeongan.github.io/tags/minibatchgd/"/>
    
      <category term="sgd" scheme="https://jaehyeongan.github.io/tags/sgd/"/>
    
      <category term="meansquarederror" scheme="https://jaehyeongan.github.io/tags/meansquarederror/"/>
    
  </entry>
  
  <entry>
    <title>머신러닝을 위한 아나콘다(Anaconda) 개발환경 구축</title>
    <link href="https://jaehyeongan.github.io/2019/04/09/machine-learning-%EA%B0%9C%EB%B0%9C%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/"/>
    <id>https://jaehyeongan.github.io/2019/04/09/machine-learning-개발환경-구축하기/</id>
    <published>2019-04-09T13:06:02.000Z</published>
    <updated>2020-12-10T14:54:03.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>대부분 처음 머신러닝를 하고자 마음먹고 시도하는 것이 개발환경을 만드는 것 입니다.<br>물론 데이터 사이언스에 대한 기본적 이해가 먼저 뒷받침이 되어 있어야 하겠지만 처음부터 너무 어렵게 시작하면 재미없자나요? 먼저 python의 세계에서 hello world 부터 찍어봐야져.</p><p>오늘은 Machine learning, data science 뭐 등등을 하기 위해 가장 많이 사용되고 있는 언어인 Python 개발환경을 구축하는 방법을 소개합니다.(내 개발환경 기준으로)<br>(JDK는 설치되어있어야 합니다.)</p><hr><p>굳이 python을 설치할 필요 없이, data science 패키지 모음인 Anaconda를 설치할 것입니다.<br>Anaconda는 수학 및 과학 관련 numpy, scipy, pandas, matplotlib과 같은 유용한 python package를 모아놓은 배포판입니다. 분명히 장점이긴 하지만 잘 사용하지 않는 패키지까지 모두 포함하고 있어 무겁다는 단점이 있습니다.</p><p>따라서, 저는 Anaconda의 축소판인 Miniconda를 깔도록 하겠습니다.<br>Miniconda는 Anaconda와 다르게 사용하고자 하는 패키지를 스스로 설치해야하는 번거로움이 있지만 가볍다는 장점이 있습니다.</p><h5 id="Anaconda-vs-Miniconda"><a href="#Anaconda-vs-Miniconda" class="headerlink" title="Anaconda vs Miniconda"></a>Anaconda vs Miniconda</h5><p>Anaconda<br>— python이나 conda를 처음 접하는 경우 좋음<br>— python과 150개 이상의 과학 패키지를 한 번에 자동 설치하여 편리<br>— 강력한 script editor인 Jupyter notebook이 포함되어 있음<br>— 3gb의 여유 용량이 필요 </p><p>Miniconda<br>— 적은 용량(100mb 이하)<br>— 스스로 원하는 패키지를 설치하고자 할 경우 좋음(좋은 습관)</p><p></p><h2 id="Install-Miniconda-python"><a href="#Install-Miniconda-python" class="headerlink" title="Install Miniconda(+python)"></a>Install Miniconda(+python)</h2><p>우선 Miniconda 홈페이지를 가면 설치가 가능합니다.<br><img src="/image/miniconda-ori.PNG" width="1000"></p><p><del>위 링크에서는 현재 python 2.7버전과 3.7버전을 제공하고 있습니다. 최신버전이므로 다운받으셔도 무방하지만 한 가지 고려할 것이 있습니다. 만약 추후 deep learning을 하고자 한다면 3.7버전 보다 아래 버전을 사용하시는 것이 좋습니다. tensorflow가 아직 3.7버전에 호환되지 않거든여ㅜㅜ</del><br><del>그래서 <a href="https://repo.continuum.io/miniconda/" target="_blank" rel="noopener">Miniconda installer archive</a>에서 python3.6버전으로 되어있는 것을 찾으시면 됩니다.저는 안정성 문제를 고려하여 <a href="https://repo.continuum.io/miniconda/Miniconda2-4.5.4-Windows-x86_64.exe" target="_blank" rel="noopener">Miniconda2-4.5.4-Windows-x86_64.exe</a>을 이용하고 있습니다.</del></p><p>(수정)다시 알아보니 이제 python 3.7버전도 tensorflow와 호환이 된다네요! 그냥 <a href="https://docs.conda.io/en/latest/miniconda.html" target="_blank" rel="noopener">Miniconda 홈페이지</a>에서 최신버전을 다운받으셔도 무방할 것 같습니다.</p><p>다운받은 후 설치파일을 더블클릭하면 아래와 같은 화면이 나타납니다.<br><img src="/image/miniconda-install.PNG" width="600"></p><p>이후, next버튼을 눌러 설치를 진행하시면 됩니다. </p><p>설치가 완료되면 설치된 경로에 아래와 같이 miniconda가 깔립니다.(동시에 python도 같은 경로에 설치가 됩니다.)<br><img src="/image/miniconda-path.PNG" width="600"></p><p></p><h2 id="Enroll-System-path"><a href="#Enroll-System-path" class="headerlink" title="Enroll System path"></a>Enroll System path</h2><p>자, 이제 miniconda 및 python을 설치하였으니 환경변수에 등록해줘야 합니다. java jdk 등록하는거와 같습니다.<br>우선 환경변수에 등록해야 하는 path는 아래와 같습니다.(본인이 설치한 path에 맞게 넣어주시면 됩니다.)<br><img src="/image/miniconda-syspath.PNG" width="500"></p><ul><li>C:\Users\nonam\Miniconda3</li><li>C:\Users\nonam\Miniconda3\python.exe</li><li>C:\Users\nonam\Miniconda3\Scripts</li><li>C:\Users\nonam\Miniconda3\Library\bin</li></ul><p>anaconda 및 miniconda를 설치하게 되면 anaconda prompt와 같은 콘솔창이 함께 설치됩니다.<br>검색창에서 anaconda prompt를 실행하여 아래와 같이 python이 실행된다면 설치가 완료된 것입니다.<br><img src="/image/anaconda-prompt.PNG" width="800"></p><p></p><h2 id="Install-Jupyter-lab"><a href="#Install-Jupyter-lab" class="headerlink" title="Install Jupyter lab"></a>Install Jupyter lab</h2><p>이제 강력한 data science 에디터인 jupyter lab을 설치해보겠습니다.(jupyter lab은 jupyter notebook보다 다양한 기능을 가지고 있고 파일 관리가 쉬워 애용합니다.)<br>anaconda prompt를 열어 아래와 같이 명령어(jupyter lab 및 해당 kernel을 설치)를 실행합니다.<br><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> conda install -c conda-forge jupyterlab</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> python -m ipykernel install --user</span></span><br></pre></td></tr></table></figure></p><p>실행이 되면 <a href="http://localhost:8888/" target="_blank" rel="noopener">http://localhost:8888/</a> 주소로 jupyter lab이 실행되며 아래와 같은 화면이 나타납니다.<br><img src="/image/jupyter.PNG" width="900"></p><p></p><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>jupyter notebook은 communication computing shell이라고 할 수 있습니다. python의 결과를 바로바로 확인가능하기 때문에 데이터 분석 및 시각화에서 아주 강력한 툴이지요.<br>하지만, 대용량 데이터를 처리해야 하고 loop및 조건문이 자주 코드에 포함된다면 조금 다를 수 있습니다.<br>jupyter notebook은 변수에 메모리를 적재 후 지속적으로 메모리를 차지하기 때문에 대용량 데이터와 같은 고성능 데이터 처리에는 그다지 추천드리지 않습니다. </p><p>따라서 저는 간단히 데이터의 분포 및 분석을 위해서만 jupyter를 사용하는 편입니다. 그 외 전체적인 코딩은 <a href="https://www.sublimetext.com/3" target="_blank" rel="noopener">sublime text3</a>라는 editor를 사용하고 있습니다.<br>추후 python 코딩을 위한 강력한 또다른 editor인 sublime text3에 대해 소개해드리도록 하겠습니다. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;대부분 처음 머신러닝를 하고자 마음먹고 시도하는 것이 개발환경을 만드는 것 입니다.&lt;br&gt;물론 데이터 사
      
    
    </summary>
    
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="anaconda" scheme="https://jaehyeongan.github.io/tags/anaconda/"/>
    
      <category term="miniconda" scheme="https://jaehyeongan.github.io/tags/miniconda/"/>
    
      <category term="jupyter" scheme="https://jaehyeongan.github.io/tags/jupyter/"/>
    
      <category term="sublimetext3" scheme="https://jaehyeongan.github.io/tags/sublimetext3/"/>
    
      <category term="datascience" scheme="https://jaehyeongan.github.io/tags/datascience/"/>
    
  </entry>
  
  <entry>
    <title>Keras functional api - Multi-input 모델 구축하기</title>
    <link href="https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%B6%95%ED%95%98%EA%B8%B0/"/>
    <id>https://jaehyeongan.github.io/2019/03/26/KERAS-FUNCTIONAL-API-MULTI-INPUT-모델-구축하기/</id>
    <published>2019-03-25T15:40:27.000Z</published>
    <updated>2020-12-10T14:52:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>지난 한달간 회사 프로젝트를 위해 공부한 내용을 정리할 겸 오늘은 keras functional api(함수형 api)에 대한 소개와 이것을 어떻게 적용하는지를 LSTM모델과 embedding모델을 통해 간단히 소개하려고 한다.</p><hr><p>그동안 keras를 통해 딥러닝 모델을 구축하기 위해서는 Sequential 모델을 이용하였을 것이다.<br>Sequential 모델은 네트워크의 입력과 출력이 하나라고 가정하고 층을 차레대로 쌓아 구성한다. </p><p><img src="/image/sequential.PNG" width="300"></p><p>따라서 위와 같은 Sequential 모델에 데이터를 학습하기 위해서는 모든 데이터를 같은 방식으로 전처리하여 모델에 맞게 shape을 구성해주어야 한다.<br>하지만, 위와 같은 구성이 맞지 않는 경우도 존재한다. 예를 들어, 중고 의류 시장 가격을 예측하는 딥러닝 모델을 만든다고 가정해보겠다.</p><p>이 모델은 시장 가격 예측을 위해 의류 브랜드, 제작 연도와 같은 정보(메타 데이터), 사용자가 제공한 제품 리뷰(텍스트 데이터), 해당 의류 사진(이미지 데이터)과 같은 데이터를 받는다.<br><img src="/image/cloth_example.PNG" width="400"></p><p>모델은 데이터의 특성에 맞게 적절히 사용되어야 하는데, 해당 데이터가 text인지, image인지, time-series인지에 따라 학습하는 모델도 달라진다.<br>위와 같은 경우,<br><img src="/image/cloth_model.PNG" width="400"><br>메타 데이터만 있다면 이를 one-hot encoding하여 단순한 DenseNet모델을 구현할 수 있을 것이고,<br>텍스트 데이터의 경우 이를 word2vec 같은 기법을 통해 벡터로 변환하여 Embedding 모델이나 혹은 RNN모델을 구현할 수 있을 것이고,<br>이미지 데이터의 경우 CNN과 같은 ConveNet 모듈을 이용하여 데이터를 학습할 수 있을 것이다.</p><h2 id="keras-functional-api"><a href="#keras-functional-api" class="headerlink" title="keras functional api"></a>keras functional api</h2><p>하지만 방금 살펴본 것과 같이 예측에 사용되는 데이터가 여러 형태로 존재한다면 어떤 모델을 사용해야 할까?<br>단순히 텍스트와 이미지를 vectorize하여 예측 변수로 추가하여 사용해야 할까?<br>데이터 특성에 따라 각각 모델을 학습시킬 순 없을까?</p><p>이러한 의문을 해결해줄 것이 바로 오늘 살펴볼 <strong>Keras Functional API</strong>이다<br>함수형 api라고 불리며, 말 그대로 모델을 함수처럼 필요할 때 호출하여 사용할 수 있도록 한다. 즉, 모델을 함수로 구현하여 모듈식으로 이용한다는 말이다.</p><p>다시 위의 예로 돌아가 함수형 API를 활용하면 아래 그림과 같이 모델별 학습 및 예측이 가능해진다.<br><img src="/image/cloth_model_concat.PNG" width="500"></p><p>위 그림과 같은 모델을 다중입력모델(multi-input model)이라고 하며 이 외에도 다중출력모델(multi-output model)이 존재합니다. </p><ul><li>다중입력모델: 데이터 특성에 따른 서로 다른 여러개의 모델이 input으로 사용되어 하나의 output을 내는 네트워크<br><img src="/image/multi_input.PNG" width="400"></li><li>다중출력모델: 하나의 output이 아닌 데이터에 있는 여러 속성을 동시에 예측하는 네트워크<br><img src="/image/multi_output.PNG" width="400"></li></ul><hr><p>함수형 API는 기존 구현방법과 구조적으로 차이가 있다.<br>보통 모델을 구현할 때 Sequential()객체를 생성 후 시퀀스 형태로 순차적으로 layer를 쌓아가지만 함수형 api는 Model()객체를 통해 모델을 구현한다. </p><ul><li><p>기존 Sequential() 사용 시 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.fit(data, labels)  <span class="comment"># starts training</span></span><br></pre></td></tr></table></figure></li><li><p>funciontal api() 사용 시</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Dense</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="comment"># This returns a tensor</span></span><br><span class="line">inputs = Input(shape=(<span class="number">784</span>,))</span><br><span class="line"></span><br><span class="line"><span class="comment"># a layer instance is callable on a tensor, and returns a tensor</span></span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(inputs)</span><br><span class="line">x = Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">outputs = Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This creates a model that includes</span></span><br><span class="line"><span class="comment"># the Input layer and three Dense layers</span></span><br><span class="line">model = Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure></li></ul><p>위와 같이 Sequential()객체는 input부터 output까지 순차적으로 이루어지지만, 함수형 api는 각각의 변수에 layer를 받아 모듈별로 구성할 수 있으며, 마지막에는 Model()객체에 input과 output텐서를 지정하여 모델을 생성한다.</p><h2 id="적용"><a href="#적용" class="headerlink" title="적용"></a>적용</h2><p>그렇다면 직접 keras를 이용하여 적용하는 과정을 소개하려고 한다.<br>데이터 셋과 전처리 과정은 공개할 순 없으나 해당 데이터는 일반 Sequence 데이터 및 Text 데이터로 이루어져 있고, 고장발생에 대한 여부를 예측하는 문제이다. </p><p>functional api를 적용하기 위하여 두개의 모델을 구축하였다.</p><ul><li>Sequence 데이터를 위해서는 시간 및 순서가 있는 데이터에 효율적인 LSTM(Long Short Term Memory Network)를 이용하였고, </li><li>text 데이터는 vectorize 후 Embedding 모델을 이용하였다.</li></ul><p>개략적인 모델 구성도는 대략 아래 그림과 같다.<br><img src="/image/model_structure_0.PNG" width="400"></p><p></p><p></p><br><strong>1. LSTM 모델 적용을 위한 Sequence 데이터 처리</strong><br>우선 LSTM과 같은 Recurrent 모델은 크기가 (timesteps, input_features)인 2D 텐서로 인코딩된 벡터의 시퀀스를 입력받기 때문에 shape을 맞추어 준다.<br>shape을 맞춰주기 전에 우선 text변수와 target 값을 제외해준 후, 데이터를 normalize해주었다.<p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## preprocessing for lstm </span></span><br><span class="line">sequence_train = df[:train_size].drop([<span class="string">'text_data'</span>,<span class="string">'target'</span>], axis=<span class="number">1</span>)</span><br><span class="line">sequence_test = df[train_size:].drop([<span class="string">'text_data'</span>,<span class="string">'target'</span>], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># normalize</span></span><br><span class="line">scaler = StandardScaler().fit(sequence_train)</span><br><span class="line">sequence_train_scale = scaler.transform(sequence_train)</span><br><span class="line">sequence_test_scale = scaler.transform(sequence_test)</span><br><span class="line"></span><br><span class="line">timesteps = <span class="number">1</span></span><br><span class="line">columns_size = len(sequence_train.columns)</span><br><span class="line">sequence_train = sequence_train_scale.reshape((sequence_train_scale.shape[<span class="number">0</span>], timesteps, columns_size))</span><br><span class="line">sequence_test = sequence_test_scale.reshape((sequence_test_scale.shape[<span class="number">0</span>], timesteps, columns_size))</span><br></pre></td></tr></table></figure><p></p><p></p><br><strong>2. Embedding 모델 적용을 위한 text 데이터 처리</strong><br>Embedding 모델을 구현하기 위하여 먼저 데이터를 3D 텐서로 변환시켜주어야 한다. 이를 위해 keras의 Tokenizer()객체를 이용하였다. 과정은 아래와 같다.<p></p><ul><li>fit_on_texts(): 텍스트 데이터를 통해 word index를 구축</li><li>texts_to_sequences(): word index를 통해 해당 텍스트를 시퀀스 형태로 변환</li><li>pad_sequences(): 3D 텐서로 변환하기 위해 padding을 추가</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## preprocessing for embedding</span></span><br><span class="line">text_embed = df.loc[:, [<span class="string">'text_data'</span>]]</span><br><span class="line">text_embed_train = text_embed[:train_size]</span><br><span class="line">text_embed_test = text_embed[train_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># tokenize</span></span><br><span class="line">max_words = <span class="number">1000</span><span class="comment"># 사용할 최대 단어 수 </span></span><br><span class="line">max_len = <span class="number">50</span><span class="comment"># 단어의 길이</span></span><br><span class="line">tokenizer = text.Tokenizer(num_words=max_words) <span class="comment"># top 1,000 words</span></span><br><span class="line">tokenizer.fit_on_texts(text_embed_train)<span class="comment"># word_index 구축</span></span><br><span class="line">sequences_text_train = tokenizer.texts_to_sequences(text_embed_train)<span class="comment"># return sequence</span></span><br><span class="line">sequences_text_test = tokenizer.texts_to_sequences(text_embed_test)</span><br><span class="line"><span class="comment"># add padding </span></span><br><span class="line">pad_train = sequence.pad_sequences(sequences_text_train, maxlen=max_len)<span class="comment"># return 3D tensor</span></span><br><span class="line">pad_test = sequence.pad_sequences(sequences_text_test, maxlen=max_len)<span class="comment"># return 3D tensor</span></span><br></pre></td></tr></table></figure><p></p><p></p><br><strong>3. multi-input model 구축</strong><br>우선 LSTM모델과 Embedding모델을 만든 후 concatenate(model1, model2)함수를 이용하여 서로 다른 두 개의 모델의 output을 하나의 모델로 통합할 수 있다. <p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_input_lstm_embedding_model</span><span class="params">(timesteps, columns_size, max_words, max_len)</span>:</span></span><br><span class="line"><span class="comment"># lstm model</span></span><br><span class="line">lstm_input = layers.Input(shape=(timesteps, columns_size))</span><br><span class="line">lstm_out = layers.LSTM(<span class="number">64</span>, dropout=<span class="number">0.3</span>, recurrent_dropout=<span class="number">0.3</span>)(lstm_input)</span><br><span class="line"></span><br><span class="line">lstm_model = Model(inputs=lstm_input, outputs=lstm_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># embedding model </span></span><br><span class="line">embed_input = layers.Input(shape=(<span class="keyword">None</span>,))</span><br><span class="line">embed_out = layers.Embedding(max_words, <span class="number">8</span>, input_length=max_len)(embed_input)</span><br><span class="line">embed_out = layers.Bidirectional(layers.LSTM(<span class="number">64</span>, dropout=<span class="number">0.3</span>, recurrent_dropout=<span class="number">0.3</span>))(embed_out)</span><br><span class="line"></span><br><span class="line">embed_model = Model(inputs=embed_input, outputs=embed_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># concatenate</span></span><br><span class="line">concatenated = layers.concatenate([lstm_model.output, embed_model.output])</span><br><span class="line">concatenated = layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>)(concatenated)</span><br><span class="line">concatenated = layers.BatchNormalization()(concatenated)</span><br><span class="line">concat_out = layers.Dense(<span class="number">2</span>, activation=<span class="string">'sigmoid'</span>)(concatenated)</span><br><span class="line"></span><br><span class="line">concat_model = models.Model([lstm_input, embed_input], concat_out)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> concat_model</span><br><span class="line"></span><br><span class="line"><span class="comment">## model define</span></span><br><span class="line">concat_model = multi_input_lstm_embedding_model(timesteps, columns_size, max_words, max_len)</span><br><span class="line">concat_model.compile(optimizer=<span class="string">'adam'</span>, loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># model fit</span></span><br><span class="line">concat_model.fit([df_label_train, pad_train], target_train</span><br><span class="line">epochs=<span class="number">7</span>, batch_size=<span class="number">32</span>,</span><br><span class="line">callbacks=callbacks_list,</span><br><span class="line">validation_data=([sequence_test, pad_test], target_test),</span><br><span class="line">shuffle=<span class="keyword">False</span>)<span class="comment"># because of time-series</span></span><br></pre></td></tr></table></figure><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>keras functional api를 이용한다면 좀 더 데이터 특성에 유연하게 모델을 학습시킬 수 있다는 것이 큰 장점인 것 같다. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;지난 한달간 회사 프로젝트를 위해 공부한 내용을 정리할 겸 오늘은 keras functional api(
      
    
    </summary>
    
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="keras" scheme="https://jaehyeongan.github.io/tags/keras/"/>
    
      <category term="rnn" scheme="https://jaehyeongan.github.io/tags/rnn/"/>
    
      <category term="lstm" scheme="https://jaehyeongan.github.io/tags/lstm/"/>
    
      <category term="machinelearning" scheme="https://jaehyeongan.github.io/tags/machinelearning/"/>
    
      <category term="tensorflow" scheme="https://jaehyeongan.github.io/tags/tensorflow/"/>
    
      <category term="functionalapi" scheme="https://jaehyeongan.github.io/tags/functionalapi/"/>
    
      <category term="embedding" scheme="https://jaehyeongan.github.io/tags/embedding/"/>
    
  </entry>
  
  <entry>
    <title>CNN 모델을 통한 자동차 사고 이미지 분류</title>
    <link href="https://jaehyeongan.github.io/2018/07/01/CNN-%EB%AA%A8%EB%8D%B8%EC%9D%84-%ED%86%B5%ED%95%9C-%EC%9E%90%EB%8F%99%EC%B0%A8-%EC%82%AC%EA%B3%A0-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%B6%84%EB%A5%98/"/>
    <id>https://jaehyeongan.github.io/2018/07/01/CNN-모델을-통한-자동차-사고-이미지-분류/</id>
    <published>2018-07-01T03:50:26.000Z</published>
    <updated>2020-10-28T15:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>회사 프로젝트에서 <strong>자동차 사고 이미지 분류 모델</strong>을 만들 일이 생겨 CNN 모델을 적용한 과정을 정리해 보고자 합니다.<br>전체적으로 크롤링(crawling)을 통해 사고 이미지를 수집하였으며, 수집한 데이터를 바탕으 아래 7개의 사고를 분류하는 <strong>다중(multi class) 분류 모델</strong>을 생성하였습니다.</p><ol><li>전방 추돌(Car front crash)</li><li>측면 추돌(Car side crash)</li><li>후방 추돌(Rear and crash)</li><li>유리창 깨짐(Car broken windshield)</li><li>차 스크래치Car scratch)</li><li>타이어 펑크(Flat tire)</li><li>전복 (Overturned vehicle)</li></ol><h2 id="사고-이미지-데이터-수집"><a href="#사고-이미지-데이터-수집" class="headerlink" title="사고 이미지 데이터 수집"></a>사고 이미지 데이터 수집</h2><p>그 동안 크롤링을 할때 python의 <strong>lxml의 parse 함수</strong>를 이용하여 html 태그 기반으로 데이터를 수집하였는데, 정말 간딴하게! 구글에서 이미지를 수집할 수 있는 라이브러리인 <strong><a href="https://icrawler.readthedocs.io/en/latest/builtin.html" target="_blank" rel="noopener">icrawler</a></strong>를 알게 되어 쉽게 이미지를 수집할 수 있었습니다.</p><p>아래와 같이 icrawler의 GoogleImageCrawler()를 이용하였습니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> icrawler.builtin <span class="keyword">import</span> GoogleImageCrawler</span><br><span class="line">google_crawler = GoogleImageCrawler(parser_threads=<span class="number">2</span>, downloader_threads=<span class="number">4</span>,</span><br><span class="line">                                    storage=&#123;<span class="string">'root_dir'</span>: <span class="string">'../data'</span>&#125;)</span><br><span class="line"></span><br><span class="line">google_crawler.crawl(keyword=<span class="string">'car crash'</span>, max_num=<span class="number">500</span>,</span><br><span class="line">                     date_min=<span class="keyword">None</span>, date_max=<span class="keyword">None</span>,</span><br><span class="line">                     min_size=(<span class="number">200</span>,<span class="number">200</span>), max_size=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure></p><ul><li>keyward: 수집하고자 하는 이미지</li><li>max_num: 수집할 이미지 수</li><li>date_min/date_max: 수집할 기간</li><li>min_size/max_size: 이미지 크기 </li></ul><p>이후, 수집한 데이터를 이미지 처리 및 train/test set으로 나누었습니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">rom PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os, glob</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 분류 대상 카테고리 선택하기 </span></span><br><span class="line">accident_dir = <span class="string">"./image"</span></span><br><span class="line">categories = [<span class="string">"Car front crash"</span>,<span class="string">"Car side crash"</span>,<span class="string">"Rear and crash"</span>,<span class="string">"Car broken windshield"</span>,<span class="string">"Car scratch"</span>,<span class="string">"Flat tire"</span>,<span class="string">"Overturned vehicle"</span>]</span><br><span class="line">nb_classes = len(categories)</span><br><span class="line"><span class="comment"># 이미지 크기 지정 </span></span><br><span class="line">image_w = <span class="number">64</span> </span><br><span class="line">image_h = <span class="number">64</span></span><br><span class="line">pixels = image_w * image_h * <span class="number">3</span></span><br><span class="line"><span class="comment"># 이미지 데이터 읽어 들이기 </span></span><br><span class="line">X = []</span><br><span class="line">Y = []</span><br><span class="line"><span class="keyword">for</span> idx, cat <span class="keyword">in</span> enumerate(categories):</span><br><span class="line">    <span class="comment"># 레이블 지정 </span></span><br><span class="line">    label = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(nb_classes)]</span><br><span class="line">    label[idx] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 이미지 </span></span><br><span class="line">    image_dir = accident_dir + <span class="string">"/"</span> + cat</span><br><span class="line">    files = glob.glob(image_dir+<span class="string">"/*.jpg"</span>)</span><br><span class="line">    <span class="keyword">for</span> i, f <span class="keyword">in</span> enumerate(files):</span><br><span class="line">        img = Image.open(f) </span><br><span class="line">        img = img.convert(<span class="string">"RGB"</span>)</span><br><span class="line">        img = img.resize((image_w, image_h))</span><br><span class="line">        data = np.asarray(img)      <span class="comment"># numpy 배열로 변환</span></span><br><span class="line">        X.append(data)</span><br><span class="line">        Y.append(label)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            print(i, <span class="string">"\n"</span>, data)</span><br><span class="line">X = np.array(X)</span><br><span class="line">Y = np.array(Y)</span><br><span class="line"><span class="comment"># 학습 전용 데이터와 테스트 전용 데이터 구분 </span></span><br><span class="line">X_train, X_test, y_train, y_test = \</span><br><span class="line">    train_test_split(X, Y)</span><br><span class="line">xy = (X_train, X_test, y_train, y_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'&gt;&gt;&gt; data 저장중 ...'</span>)</span><br><span class="line">np.save(<span class="string">"./image/7obj.npy"</span>, xy)</span><br><span class="line">print(<span class="string">"ok,"</span>, len(Y))</span><br></pre></td></tr></table></figure></p><p>이미지를 RGB로 변환 후,  64x64 크기로 resize해주었습니다.</p><h2 id="CNN-모델-생성"><a href="#CNN-모델-생성" class="headerlink" title="CNN 모델 생성"></a>CNN 모델 생성</h2><p>모델은 이미지 분류의 정석으로 불리는 <strong>CNN(Convolution Neural Network)</strong> 모델을 활용하였습니다.<br>총 3개의 층으로 구성하였고, 활성화 함수로는 relu 및 softmax 함수를 적용하였습니다. dropout도 적용하여 과적합을 방지하였습니다.<br><img src="/image/car_cnn.png" alt="car_cnn"></p><p>모델 학습 후 <strong>.hdf5</strong> 파일로 저장합니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Activation, Dropout, Flatten, Dense</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 카테고리 지정하기</span></span><br><span class="line">categories = [<span class="string">"Car front crash"</span>,<span class="string">"Car side crash"</span>,<span class="string">"Rear and crash"</span>,<span class="string">"Car broken windshield"</span>,<span class="string">"Car scratch"</span>,<span class="string">"Flat tire"</span>,<span class="string">"Overturned vehicle"</span>]</span><br><span class="line">nb_classes = len(categories)</span><br><span class="line"><span class="comment"># 이미지 크기 지정하기</span></span><br><span class="line">image_w = <span class="number">64</span></span><br><span class="line">image_h = <span class="number">64</span></span><br><span class="line"><span class="comment"># 데이터 열기 </span></span><br><span class="line">X_train, X_test, y_train, y_test = np.load(<span class="string">"./image/7obj.npy"</span>)</span><br><span class="line"><span class="comment"># 데이터 정규화하기(0~1사이로)</span></span><br><span class="line">X_train = X_train.astype(<span class="string">"float"</span>) / <span class="number">256</span></span><br><span class="line">X_test  = X_test.astype(<span class="string">"float"</span>)  / <span class="number">256</span></span><br><span class="line">print(<span class="string">'X_train shape:'</span>, X_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 구조 정의 </span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), input_shape=X_train.shape[<span class="number">1</span>:], padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'same'</span>))</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 전결합층</span></span><br><span class="line">model.add(Flatten())    <span class="comment"># 벡터형태로 reshape</span></span><br><span class="line">model.add(Dense(<span class="number">512</span>))   <span class="comment"># 출력</span></span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line">model.add(Dense(nb_classes))</span><br><span class="line">model.add(Activation(<span class="string">'softmax'</span>))</span><br><span class="line"><span class="comment"># 모델 구축하기</span></span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,   <span class="comment"># 최적화 함수 지정</span></span><br><span class="line">    optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"><span class="comment"># 모델 확인</span></span><br><span class="line"><span class="comment">#print(model.summary())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 학습 완료된 모델 저장</span></span><br><span class="line">hdf5_file = <span class="string">"./image/7obj-model.hdf5"</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(hdf5_file):</span><br><span class="line">    <span class="comment"># 기존에 학습된 모델 불러들이기</span></span><br><span class="line">    model.load_weights(hdf5_file)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 학습한 모델이 없으면 파일로 저장</span></span><br><span class="line">    model.fit(X_train, y_train, batch_size=<span class="number">32</span>, nb_epoch=<span class="number">10</span>)</span><br><span class="line">    model.save_weights(hdf5_file)</span><br></pre></td></tr></table></figure></p><p>모델의 오차와 정확도를 살펴보겠습니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 평가하기 </span></span><br><span class="line">score = model.evaluate(X_test, y_test)</span><br><span class="line">print(<span class="string">'loss='</span>, score[<span class="number">0</span>])        <span class="comment"># loss</span></span><br><span class="line">print(<span class="string">'accuracy='</span>, score[<span class="number">1</span>])    <span class="comment"># acc</span></span><br></pre></td></tr></table></figure></p><p><img src="/image/cnn_score.jpg" alt="image"><br><strong>오차는 0.03, 정확도는 98%</strong> 정도의 성능을 나타냅니다. 확실히 데이터를 많이 학습시키니 성능이 좋은 것 같습니다.</p><h2 id="신규-데이터-예측"><a href="#신규-데이터-예측" class="headerlink" title="신규 데이터 예측"></a>신규 데이터 예측</h2><p><strong>학습된 모델(7obj-model.hdf5)</strong>에 신규 이미지를 적용하여 이미지의 클래스를 예측해보도록 하겠습니다. </p><p>적용할 이미지는 아래의 <strong>차 전복(Overturned vehicle)</strong> 이미지 입니다.<br><img src="/image/overturned.jpg" alt="overturned"></p><p>모델에 적용해봅니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 적용해볼 이미지 </span></span><br><span class="line">test_image = <span class="string">'./image/test_overturned.jpg'</span></span><br><span class="line"><span class="comment"># 이미지 resize</span></span><br><span class="line">img = Image.open(test_image)</span><br><span class="line">img = img.convert(<span class="string">"RGB"</span>)</span><br><span class="line">img = img.resize((<span class="number">64</span>,<span class="number">64</span>))</span><br><span class="line">data = np.asarray(img)</span><br><span class="line">X = np.array(data)</span><br><span class="line">X = X.astype(<span class="string">"float"</span>) / <span class="number">256</span></span><br><span class="line">X = X.reshape(<span class="number">-1</span>, <span class="number">64</span>, <span class="number">64</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 예측</span></span><br><span class="line">pred = model.predict(X)  </span><br><span class="line">result = [np.argmax(value) <span class="keyword">for</span> value <span class="keyword">in</span> pred]   <span class="comment"># 예측 값중 가장 높은 클래스 반환</span></span><br><span class="line">print(<span class="string">'New data category : '</span>,categories[result[<span class="number">0</span>]])</span><br></pre></td></tr></table></figure></p><p>학습할때와 똑같이 이미지를 처리해 주고 저장된 모델을 통해 이미지를 예측합니다. </p><ul><li>예측결과<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">New data category : Overturned vehicle</span><br></pre></td></tr></table></figure></li></ul><p>Overturned Vehicle(차 전복) 클래스로 이미지가 모델에 의해 예측되었습니다! 모델이 잘 학습된 것 같습니다.<br>각 클래스별로 500개 총 3500개의 이미지를 통해 학습한 CNN 다중 분류 모델의 성능이 생각보다 괜찮은 것 같습니다. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;회사 프로젝트에서 &lt;strong&gt;자동차 사고 이미지 분류 모델&lt;/strong&gt;을 만들 일이 생겨 CNN 
      
    
    </summary>
    
    
      <category term="cnn" scheme="https://jaehyeongan.github.io/tags/cnn/"/>
    
      <category term="deeplearning" scheme="https://jaehyeongan.github.io/tags/deeplearning/"/>
    
      <category term="keras" scheme="https://jaehyeongan.github.io/tags/keras/"/>
    
      <category term="crawling" scheme="https://jaehyeongan.github.io/tags/crawling/"/>
    
  </entry>
  
  <entry>
    <title>이상탐지 알고리즘을 통한 이상거래탐지(FDS)</title>
    <link href="https://jaehyeongan.github.io/2018/06/30/%EC%9D%B4%EC%83%81%ED%83%90%EC%A7%80-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%84-%ED%86%B5%ED%95%9C-%EC%9D%B4%EC%83%81%EA%B1%B0%EB%9E%98%ED%83%90%EC%A7%80-FDS/"/>
    <id>https://jaehyeongan.github.io/2018/06/30/이상탐지-알고리즘을-통한-이상거래탐지-FDS/</id>
    <published>2018-06-30T09:47:01.000Z</published>
    <updated>2020-12-10T14:56:23.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>금융거래 중 부정하게 사용되는 거래를 부정 거래라고 합니다. 그 중 신용카드 위변조, 도용, 부정거래에 대한 비율은 해마다 증가하고 있는 추세입니다. 아래 표는 연도별 신용카드 부정사용 금액.<br><img src="/image/creditcard_main.jpg" width="550"></p><p>따라서, 최근에는 국내 주요 은행들은 <strong>FDS(Fraud Detection System)</strong>을 도입하여 이러한 부정거래를 막기위해 노력하고 있지만 주로 룰(Rule) 기반으로 사람에 의해 이루어지기 때문에 실시간으로 정확한 탐지가 어려운 상황이라고 합니다. </p><hr><h2 id="목표"><a href="#목표" class="headerlink" title="목표"></a>목표</h2><p>여기서는 머신러닝을 이용하여, 이러한 부정거래를 탐지해 보고자 합니다. 하지만, 지도학습이 아닌 <strong>비지도 학습</strong>을 이용합니다.  그 중 <strong>이상 탐지(Outlier Detection)</strong> 알고리즘을 이용하여 라벨을 통한 학습이 아닌 이상치 데이터 집단을 찾아 그 이상치 집단이 부정거래 데이터와 일치 및 유사한지 알아볼 것입니다.<br><br></p><h2 id="1-신용카드-데이터-셋"><a href="#1-신용카드-데이터-셋" class="headerlink" title="1. 신용카드 데이터 셋"></a>1. 신용카드 데이터 셋</h2><p>데이터 셋의 경우 kaggle에서 제공하는 <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud" target="_blank" rel="noopener">Credit Card Fraud Detection Dataset</a>을 이용하였습니다.<br>위 데이터 셋은 2013년 9월 유럽의 실제 신용 카드 거래 데이터를 담고 있습니다. 데이터는 총 284,807건이며 그 중 492건만이 부정 거래 데이터 입니다.<br>즉, 데이터가 매우 <strong>불균형(imbalanced)</strong> 합니다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'./input/creditcard.csv'</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/image/creditcard_load.JPG" width="1000"><br>위 데이터 셋은 개인정보 비식별화처리로 인해 칼럼정보를 알 수 없으며, 데이터 또한 스케일(scale) 및 PCA(principal component analysis) 처리 되어있습니다.<br>총 31개의 칼럼으로 이루어져 있고, <strong>Time, Amount, Class</strong>를 제외한 모든 칼럼은 <strong>비식별화</strong>처리 되어있습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.info()</span><br></pre></td></tr></table></figure><p><img src="/image/creditcard_info.JPG" width="300"><br>데이터는 총 284,807건이며 null값은 존재하지 않는 정형 데이터 입니다.<br><br></p><h2 id="2-데이터-탐색-EDA"><a href="#2-데이터-탐색-EDA" class="headerlink" title="2. 데이터 탐색(EDA)"></a>2. 데이터 탐색(EDA)</h2><ul><li><p>시간(Time)대별 정상/부정 거래 비율 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 시간대별 트랜잭션 양</span></span><br><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>,<span class="number">1</span>, sharex=<span class="keyword">True</span>, figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">ax1.hist(df.Time[df.Class==<span class="number">1</span>], bins=<span class="number">50</span>)</span><br><span class="line">ax2.hist(df.Time[df.Class==<span class="number">0</span>], bins=<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_title(<span class="string">'Fraud'</span>)</span><br><span class="line">ax2.set_title(<span class="string">'Normal'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Time(in Seconds)'</span>); plt.ylabel(<span class="string">'Number of Transactions'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/time.png" width="800"><br>음.. 대체적으로 정상 거래의 경우 시간에 따라 주기적인 반면 부정 거래의 경우 불규칙한 특성을 보입니다.<br><br></p></li></ul><ul><li><p>금액(Amount)대별 정상/부정 거래 비율</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 금액대별 트랜잭션 양</span></span><br><span class="line">f, (ax1, ax2) = plt.subplots(<span class="number">2</span>,<span class="number">1</span>, sharex=<span class="keyword">True</span>, figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">ax1.hist(df.Amount[df.Class==<span class="number">1</span>], bins=<span class="number">30</span>)</span><br><span class="line">ax2.hist(df.Amount[df.Class==<span class="number">0</span>], bins=<span class="number">30</span>)</span><br><span class="line">ax1.set_title(<span class="string">'Fraud'</span>)</span><br><span class="line">ax2.set_title(<span class="string">'Normal'</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">'Amount ($)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Number of Transactions'</span>)</span><br><span class="line">plt.yscale(<span class="string">'log'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/amount.png" width="750"><br>정상 거래의 경우 다양한 금액대에서 발생되지만, 부정 거래의 경우 적은 금액에서 주로 발생하는 것 같습니다.<br><br></p></li><li><p>비식별칼럼 정상/부정거래 비율<br>특성 차이가 심한 일부 변수만 표시하였습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 정상/비정산 럼간 값 분포</span></span><br><span class="line">v_features = df.ix[:,<span class="number">1</span>:<span class="number">29</span>].columns</span><br><span class="line"><span class="keyword">for</span> cnt, col <span class="keyword">in</span> enumerate(df[v_features]):</span><br><span class="line">    sns.distplot(df[col][df.Class==<span class="number">1</span>], bins=<span class="number">50</span>)</span><br><span class="line">    sns.distplot(df[col][df.Class==<span class="number">0</span>], bins=<span class="number">50</span>)</span><br><span class="line">    plt.legend([<span class="string">'Y'</span>,<span class="string">'N'</span>], loc=<span class="string">'best'</span>)</span><br><span class="line">    plt.title(<span class="string">'histogram of feature '</span>+str(col))</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="/image/col.png" width="750"><br><br></p></li></ul><h2 id="3-Isolation-Forest"><a href="#3-Isolation-Forest" class="headerlink" title="3. Isolation Forest"></a>3. Isolation Forest</h2><p>이상탐지 알고리즘으로는 <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" target="_blank" rel="noopener"><strong>Isolation Forest</strong></a> 알고리즘을 이용하였습니다. Isolation Forest 는 Tree 기반으로 데이터를 나누어 데이터의 관측치를 고립시키는 알고리즘입니다. 이상 데이터의 경우 root node와 가까운 depth를 가지고, 정상 데이터의 경우 tree의 말단 노드에 가까운 depth를 가집니다.<br><img src="/image/isolation.jpg" width="650"><br><br></p><h2 id="4-이상-탐지-알고리즘-적용"><a href="#4-이상-탐지-알고리즘-적용" class="headerlink" title="4. 이상 탐지 알고리즘 적용"></a>4. 이상 탐지 알고리즘 적용</h2><p>Isolation Forest 알고리즘은 현재 scikit-learn에서 제공되고 있으며, <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" target="_blank" rel="noopener">링크</a>를 통해 다큐먼트를 확인하실 수 있습니다.<br>Isolation Forest는 이상치 점수(outlier score)를 제공합니다. 정상 거래/ 부정 거래에 대한 이상치 점수는 아래와 같습니다.<br><img src="/image/outlierscore.png" width="800"><br>위의 분포를 보았을 때, 정상 / 부정 거래 간 비율이 다르게 나타나는 것을 확인할 수 있습니다.<br><br></p><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>우선 적용하기에 앞서, 데이터 불균형(Data Imbalance)를 해결하기 위하여, 정상 거래건에 대해 Down sampling을 70% 비율로 진행하였습니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> imblearn.under_sampling <span class="keyword">import</span> RandomUnderSampler</span><br><span class="line"></span><br><span class="line">credit_data = pd.read_csv(<span class="string">'./data/creditcard.csv'</span>)</span><br><span class="line">X = credit_data.drop([<span class="string">'Class'</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = credit_data[<span class="string">'Class'</span>]</span><br><span class="line">print(Counter(y))<span class="comment"># &#123;0: 284315, 1: 492&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Under Sampling</span></span><br><span class="line">sampler = RandomUnderSampler(ratio=<span class="number">0.70</span>, random_state=<span class="number">0</span>)</span><br><span class="line">X, y = sampler.fit_sample(X, y)</span><br><span class="line">print(<span class="string">'Class : '</span>,Counter(y))<span class="comment"># &#123;0: 702, 1: 492&#125;</span></span><br></pre></td></tr></table></figure></p><p><br><br>이후, Isolation Forest를 아래와 같은 파라미터를 통해 적용하였습니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> IsolationForest</span><br><span class="line"></span><br><span class="line">clf = IsolationForest(n_estimators=<span class="number">300</span>, contamination=<span class="number">0.40</span>, random_state=<span class="number">42</span>)</span><br><span class="line">clf.fit(X)</span><br><span class="line">pred_outlier = clf.predict(X)</span><br><span class="line">pred_outlier = pd.DataFrame(pred_outlier).replace(&#123;<span class="number">1</span>:<span class="number">0</span>, <span class="number">-1</span>:<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure></p><ul><li>n_estimators : 노드 수</li><li>contamination : 이상치 비율</li></ul><p>이상탐지 예측값은 1이 정상, -1이 이상으로 분류됩니다. 이를 Class 라벨과의 오차를 계산하여야 하기 때문에, 같은 범위로 바꿔주었습니다.<br><br></p><h3 id="시각화"><a href="#시각화" class="headerlink" title="시각화"></a>시각화</h3><p>이상탐지 결과를 2d 및 3d로 시각화한 결과 입니다. ( 시각화를 위해 차원을 축소하였습니다.)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot 2d</span></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=pred_outlier, cmap=<span class="string">'Paired'</span>, s=<span class="number">40</span>, edgecolors=<span class="string">'white'</span>)</span><br><span class="line">plt.title(<span class="string">"Isolation Forest"</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot 3d</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">'3d'</span>)</span><br><span class="line">ax.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], X[:,<span class="number">2</span>], c=pred_outlier)</span><br><span class="line">ax.set_xlabel(<span class="string">'pcomp 1'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'pcomp 2'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'pcomp 3'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><ul><li>2차원 시각화<br><img src="/image/2d.png" width="650"></li><li>3차원 시각화<br><img src="/image/3d.png" width="650"><br><br></li></ul><h2 id="예측-성능"><a href="#예측-성능" class="headerlink" title="예측 성능"></a>예측 성능</h2><p>예측값을 실제 부정거래여부 칼럼인 Class와 비교하여 성능을 살펴보겠습니다.<br>측정 지표로는 Accuracy(정확도), Recall(재현율), Precision(정밀도), F1-score 입니다.  </p><p>금융 거래에서는 정확도도 물론 중요하지만, 실제 부정거래를 부정거래로 예측하는 비율인 <strong>Recall(재현율)</strong> 값이 중요하게 여겨집니다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, classification_report, accuracy_score</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line">class_name = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span><span class="params">(classes, pred, y_test, </span></span></span><br><span class="line"><span class="function"><span class="params">                          normalize=False, title=<span class="string">'Confusion matrix'</span>, cmap=plt.cm.Blues)</span>:</span></span><br><span class="line">    </span><br><span class="line">    cm = confusion_matrix(y_test, pred)</span><br><span class="line">    plt.imshow(cm, interpolation=<span class="string">'nearest'</span>, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(len(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes, rotation=<span class="number">0</span>)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> normalize:</span><br><span class="line">        cm = cm.astype(<span class="string">'float'</span>) / cm.sum(axis=<span class="number">1</span>)[:, np.newaxis]</span><br><span class="line">    thresh = cm.max() / <span class="number">2.</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> itertools.product(range(cm.shape[<span class="number">0</span>]), range(cm.shape[<span class="number">1</span>])):</span><br><span class="line">        plt.text(j, i, cm[i, j],</span><br><span class="line">                 horizontalalignment=<span class="string">"center"</span>,</span><br><span class="line">                 color=<span class="string">"white"</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">"black"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 평가</span></span><br><span class="line">print(<span class="string">'confusion matrix\n'</span>, confusion_matrix(pred_outlier, y))</span><br><span class="line">print(<span class="string">'Accuracy: '</span>,accuracy_score(pred_outlier, y))</span><br><span class="line">print(<span class="string">'classification_report\n'</span>, classification_report(pred_outlier, y))</span><br><span class="line">plot_confusion_matrix(class_name, pred_outlier, y, title=<span class="string">'Isolation Forest'</span>)</span><br></pre></td></tr></table></figure></p><ul><li><p>Confusion Matrix 결과<br><img src="/image/cm.png" alt="cm"></p></li><li><p>Classification report 결과</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Accuracy:  0.8442211055276382</span><br><span class="line">classification_report</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">          0       0.88      0.86      0.87       716</span><br><span class="line">          1       0.80      0.82      0.81       478</span><br><span class="line"></span><br><span class="line">avg / total       0.85      0.84      0.84      1194</span><br></pre></td></tr></table></figure></li></ul><p>위 결과를 보았을 때,  Accuracy 무려 <strong>84%</strong> 입니다.<br>Recall 값 또한 <strong>82%</strong> 로 높은 부정 거래 탐지 정확도를 나타냅니다.</p><hr><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>데이터를 목표 변수를 통해 학습하는 지도학습 알고리즘에 비하면 적은 정확도이겠지만,<br>데이터를 전혀 학습하지 않고, 데이터의 특성만을 고려하여 이상치를 찾아내는 비지도 학습으로도 충분히 부정 거래를 탐지할 수 있다는 것을 확인하였습니다. </p><p>최근에는 딥러닝 기법을 이용하여 <strong>오토인코더(Auto-encoder)</strong>나 <strong>GAN 알고리즘</strong>을 이용하여 이상탐지에 활용되고 있습니다. </p><p>저도 더 공부해서 한번 적용해봐야겠습니다ㅠㅠㅠ </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;금융거래 중 부정하게 사용되는 거래를 부정 거래라고 합니다. 그 중 신용카드 위변조, 도용, 부정거래에 
      
    
    </summary>
    
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="outlier detection" scheme="https://jaehyeongan.github.io/tags/outlier-detection/"/>
    
      <category term="isolation forest" scheme="https://jaehyeongan.github.io/tags/isolation-forest/"/>
    
      <category term="unsupervised learning" scheme="https://jaehyeongan.github.io/tags/unsupervised-learning/"/>
    
      <category term="scikit-learn" scheme="https://jaehyeongan.github.io/tags/scikit-learn/"/>
    
      <category term="fraud detection system" scheme="https://jaehyeongan.github.io/tags/fraud-detection-system/"/>
    
  </entry>
  
  <entry>
    <title>파이썬 소켓(socket) 프로그래밍</title>
    <link href="https://jaehyeongan.github.io/2018/06/29/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EC%86%8C%EC%BC%93-socket-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"/>
    <id>https://jaehyeongan.github.io/2018/06/29/파이썬-소켓-socket-프로그래밍/</id>
    <published>2018-06-29T08:22:55.000Z</published>
    <updated>2020-10-28T15:14:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="파이썬-소켓-socket-프로그래밍"><a href="#파이썬-소켓-socket-프로그래밍" class="headerlink" title="파이썬 소켓(socket) 프로그래밍"></a>파이썬 소켓(socket) 프로그래밍</h1><hr><p>소켓(socket)을 통해 서버(server)와 클라이언트(client)간 어떻게 기본적인 네트워크 통신이 이루어지는지 알아보려고 합니다.<br><img src="https://www.tutorialspoint.com/perl/images/perl_socket.jpg" alt="check"><br>먼저 통신을 위해 두개의 파일은 준비합니다. 파일은 각각 서버와 클라이언트에 해당합니다.</p><ul><li>server.py</li><li>client.py</li></ul><p>우선 <strong>server.py</strong> 작성</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> select <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">''</span></span><br><span class="line">PORT = <span class="number">10000</span></span><br><span class="line">BUFSIZE = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 소켓 생성</span></span><br><span class="line">serverSocket = socket(AF_INET, SOCK_STREAM)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 소켓 주소 정보 할당 </span></span><br><span class="line">serverSocket.bind(ADDR)</span><br><span class="line">print(<span class="string">'bind'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 연결 수신 대기 상태</span></span><br><span class="line">serverSocket.listen(<span class="number">100</span>)</span><br><span class="line">print(<span class="string">'listen'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 연결 수락</span></span><br><span class="line">clientSocekt, addr_info = serverSocket.accept()</span><br><span class="line">print(<span class="string">'accept'</span>)</span><br><span class="line">print(<span class="string">'--client information--'</span>)</span><br><span class="line">print(clientSocekt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 클라이언트로부터 메시지를 가져옴</span></span><br><span class="line">data = clientSocekt.recv(<span class="number">65535</span>)</span><br><span class="line">print(<span class="string">'recieve data : '</span>,data.decode())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 소켓 종료 </span></span><br><span class="line">clientSocekt.close()</span><br><span class="line">serverSocket.close()</span><br><span class="line">print(<span class="string">'close'</span>)</span><br></pre></td></tr></table></figure><ol><li>우선 소켓을 설정하고, bind()함수를 통해 주소 정보를 할당한다.</li><li>이후, listen()함수를 통해 연결 수신 대기 상태로 전환 후 </li><li>client가 연결할 시 accpet() 함수를 이용하여 연결을 수락한다.</li><li>만약 client가 보낸 메시지가 있을 경우, recv(byte크기)를 이용하여 메시지를 가져온다.</li></ol><p>이제 <strong>client.py</strong>를 작성</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> select <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'127.0.0.1'</span></span><br><span class="line">PORT = <span class="number">10000</span></span><br><span class="line">BUFSIZE = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST,PORT)</span><br><span class="line"></span><br><span class="line">clientSocket = socket(AF_INET, SOCK_STREAM)<span class="comment"># 서버에 접속하기 위한 소켓을 생성한다.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">clientSocket.connect(ADDR)<span class="comment"># 서버에 접속을 시도한다.</span></span><br><span class="line">clientSocket.send(<span class="string">'Hello!'</span>.encode())<span class="comment"># 서버에 메시지 전달</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span>  Exception <span class="keyword">as</span> e:</span><br><span class="line">    print(<span class="string">'%s:%s'</span>%ADDR)</span><br><span class="line">    sys.exit()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'connect is success'</span>)</span><br></pre></td></tr></table></figure><ol><li>주소와 포트번호를 설정</li><li>server에 접속하기 위한 client socket을 생성하고</li><li>connect()함수를 이용하여 서버에 접속을 시도</li><li>send()함수를 이용해 메시지를 server에 전달</li></ol><hr><p>이제 위의 코드를 실행해보도록 하겠습니다. </p><p>server.py를 실행 후 client.py를 통해 server에 접속하는 과정입니다.</p><ol><li><p>먼저 server.py를 실행하여, client의 접속을 기다립니다.</p><p><img src="/image/server.png" alt="server.py"></p></li></ol><ol><li><p>이후,  client.py를 실행하여 server에 접속을 시도합니다.</p><p><img src="/image/client.png" alt="client.py"></p></li></ol><ol><li><p>server에서 client의 접속정보와 메시지를 확인합니다.</p><p><img src="/image/check.png" alt="check"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;파이썬-소켓-socket-프로그래밍&quot;&gt;&lt;a href=&quot;#파이썬-소켓-socket-프로그래밍&quot; class=&quot;headerlink&quot; title=&quot;파이썬 소켓(socket) 프로그래밍&quot;&gt;&lt;/a&gt;파이썬 소켓(socket) 프로그래밍&lt;/h1&gt;&lt;hr
      
    
    </summary>
    
    
      <category term="python" scheme="https://jaehyeongan.github.io/tags/python/"/>
    
      <category term="network" scheme="https://jaehyeongan.github.io/tags/network/"/>
    
      <category term="server" scheme="https://jaehyeongan.github.io/tags/server/"/>
    
      <category term="client" scheme="https://jaehyeongan.github.io/tags/client/"/>
    
      <category term="socket" scheme="https://jaehyeongan.github.io/tags/socket/"/>
    
  </entry>
  
</feed>
